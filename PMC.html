
<!DOCTYPE html>

<html lang="fr">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Perceptrons multicouches &#8212; Apprentissage profond</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Recherche" href="search.html" />
    <link rel="prev" title="Introduction aux réseaux de neurones" href="NN.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="fr">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Apprentissage profond</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="NN.html">
   Introduction aux réseaux de neurones
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Perceptrons multicouches
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fonctions-d-activation">
   Fonctions d’activation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#entrainement-des-reseaux-multicouches">
   Entraînement des réseaux multicouches
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#strategies-d-entrainement">
   Stratégies d’entraînement
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimisation-des-parametres">
   Optimisation des paramètres
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialisation-des-poids">
   Initialisation des poids
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#retropropagation-de-l-erreur">
   Rétropropagation de l’erreur
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#criteres-d-arret">
   Critères d’arrêt
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#propriete-fondamentale">
   Propriété fondamentale
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularisation">
   Régularisation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exemple">
   Exemple
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reseau">
     Réseau
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#phase-d-apprentissage">
     Phase d’apprentissage
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#couche-de-sortie">
       Couche de sortie
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#couche-cachee">
       Couche cachée
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#initialisation-des-poids-initialisation-des-poids">
       Initialisation des poids {#initialisation-des-poids}
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Perceptrons multicouches</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fonctions-d-activation">
   Fonctions d’activation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#entrainement-des-reseaux-multicouches">
   Entraînement des réseaux multicouches
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#strategies-d-entrainement">
   Stratégies d’entraînement
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimisation-des-parametres">
   Optimisation des paramètres
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialisation-des-poids">
   Initialisation des poids
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#retropropagation-de-l-erreur">
   Rétropropagation de l’erreur
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#criteres-d-arret">
   Critères d’arrêt
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#propriete-fondamentale">
   Propriété fondamentale
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularisation">
   Régularisation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exemple">
   Exemple
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reseau">
     Réseau
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#phase-d-apprentissage">
     Phase d’apprentissage
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#couche-de-sortie">
       Couche de sortie
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#couche-cachee">
       Couche cachée
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#initialisation-des-poids-initialisation-des-poids">
       Initialisation des poids {#initialisation-des-poids}
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="perceptrons-multicouches">
<h1>Perceptrons multicouches<a class="headerlink" href="#perceptrons-multicouches" title="Lien permanent vers ce titre">#</a></h1>
<div class="proof definition admonition" id="definition-0">
<p class="admonition-title"><span class="caption-number">Definition 4 </span> (Perceptron multicouches)</p>
<div class="definition-content section" id="proof-content">
<p>Un perceptron à <span class="math notranslate nohighlight">\((L+1)\)</span> couches (<a class="reference internal" href="#mlp"><span class="std std-numref">Fig. 2</span></a>) est un réseau constitué d’une
rétine à <span class="math notranslate nohighlight">\(D\)</span> neurones (auxquels on rajoute l’entrée <span class="math notranslate nohighlight">\(x_0\)</span>), <span class="math notranslate nohighlight">\(C\)</span> neurones
de sortie, et des neurones dits <strong>cachés</strong>, organisés dans <span class="math notranslate nohighlight">\(L\)</span> couches
cachées intermédiaires. De fait, un tel réseau comporte <span class="math notranslate nohighlight">\((L+2)\)</span> couches
mais on compte rarement la rétine, puisque cette dernière n’effectue pas
de calculs. Le <span class="math notranslate nohighlight">\(i^{\text{e}}\)</span> neurone dans la couche cachée <span class="math notranslate nohighlight">\(l\)</span> calcule
la sortie</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    y_i^{(l)} &amp;= f\left(z_i^{(l)}\right) \quad\text{ avec }\quad z_i^{(l)} = \sum _{k = 1} ^{m^{(l-1)}} w_{i,k}^{(l)} y_k^{(l-1)} + w_{i,0}^{(l)}
\end{aligned}\]</div>
<p>où <span class="math notranslate nohighlight">\(w_{i,k}^{(l)}\)</span> est le poids de la connexion entre le
<span class="math notranslate nohighlight">\(k^{\text{e}}\)</span> neurone de la couche <span class="math notranslate nohighlight">\((l-1)\)</span> et le <span class="math notranslate nohighlight">\(i^{\text{e}}\)</span> neurone
de la couche <span class="math notranslate nohighlight">\(l\)</span>, et <span class="math notranslate nohighlight">\(w_{i,0}^{(l)}\)</span> est le biais. De plus, <span class="math notranslate nohighlight">\(m^{(l)}\)</span>
est le nombre de neurones de la couche <span class="math notranslate nohighlight">\(l\)</span>, de sorte que <span class="math notranslate nohighlight">\(D = m^{(0)}\)</span>
et <span class="math notranslate nohighlight">\(C = m^{(L+1)}\)</span>. Enfin, <span class="math notranslate nohighlight">\(f\)</span> est la fonction d’activation du neurone
(supposée identique pour tous les neurones).</p>
</div>
</div><p>En introduisant dans chaque couche un neurone supplémentaire
<span class="math notranslate nohighlight">\(y_0^{(l)} = 1\)</span> pour gérer le biais, on a :</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    {\mathbf z_i^{(l)}} = \displaystyle\sum _{k = 0} ^{m^{(l-1)}} {\mathbf w_{i,k}^{(l)}} {\mathbf y_k^{(l-1)}}\quad \text{ où }\quad {\mathbf z^{(l)}} = {\mathbf w^{(l)} y^{(l-1)}}
\end{aligned}\]</div>
<p>avec <span class="math notranslate nohighlight">\({\mathbf z^{(l)}}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{w^{(l)}}\)</span> et <span class="math notranslate nohighlight">\(\mathbf{y^{(l-1)}}\)</span> les
représentations vectorielle et matricielle des entrées <span class="math notranslate nohighlight">\(z_i^{(l)}\)</span>, des
poids <span class="math notranslate nohighlight">\(w_{i,k}^{(l)}\)</span> et des sorties <span class="math notranslate nohighlight">\(y_k^{(l-1)}\)</span>.</p>
<div class="figure align-default" id="mlp">
<img alt="_images/mlp.png" src="_images/mlp.png" />
<p class="caption"><span class="caption-number">Fig. 2 </span><span class="caption-text">Perceptron multicouches à <span class="math notranslate nohighlight">\((L + 1)\)</span> couches, <span class="math notranslate nohighlight">\(D\)</span> entrées et <span class="math notranslate nohighlight">\(C\)</span> sorties.</span><a class="headerlink" href="#mlp" title="Lien permanent vers cette image">#</a></p>
</div>
<p>Un tel réseau représente une fonction</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    {\mathbf y}(\cdot,{\mathbf w}) &amp;:&amp; \mathbb{R}^D \rightarrow \mathbb{R}^C\\
    {\mathbf x} &amp;\mapsto&amp; {\mathbf y(x,w)}
\end{aligned}\end{split}\]</div>
<p>où <span class="math notranslate nohighlight">\({\mathbf y(x,w)}\)</span> est tel que <span class="math notranslate nohighlight">\({\mathbf y_i}({\mathbf x},{\mathbf w}) = {\mathbf y_i^{(L+1)}}\)</span> et <span class="math notranslate nohighlight">\({\mathbf w}\)</span>
est la matrice de tous les poids du réseau.</p>
<p>On parlera de <strong>réseau profond (Deep network)</strong> lorsque le nombre de
couches cachées est « suffisamment important » (supérieur à 3 par exemple).</p>
<div class="section" id="fonctions-d-activation">
<h2>Fonctions d’activation<a class="headerlink" href="#fonctions-d-activation" title="Lien permanent vers ce titre">#</a></h2>
<p>Trois grandes classes de fonction d’activation <span class="math notranslate nohighlight">\(f\)</span> sont généralement
utilisées : les fonctions de seuils (comme dans le perceptron linéaire à
seuil), les fonctions linéaires par morceau et les fonctions de type
sigmoïde. Dans les deux premiers cas, de nombreux problèmes se
présentent, notamment en raison de la non différentiabilité de ces
fonctions (qui est nécessaire dans les algorithmes d’apprentissage du
type descente de gradient), ou encore en raison de la faiblesse de leur
pouvoir d’expression. Ainsi, il est préférable d’utiliser des fonctions
de type sigmoïde, et par exemple la sigmoïde logistique est donnée par :</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    \sigma(z) = \frac{1}{1 + \exp(-z)}.
\end{aligned}\]</div>
<p>La tangente hyperbolique <span class="math notranslate nohighlight">\(\tanh(z)\)</span>, également utilisée pour ses bonnes
propriétés de dérivabilité (<span class="math notranslate nohighlight">\((\tanh)'=1-\tanh^2\)</span>), peut être vue comme
une transformation linéaire de la sigmoïde dans l’intervalle <span class="math notranslate nohighlight">\([-1,1]\)</span>.</p>
<p>Ces réseaux peuvent être utilisés en régression (sortie à valeurs dans
<span class="math notranslate nohighlight">\(\mathbb{R}^C\)</span>) ou en classification. Dans ce dernier cas, la fonction
d’activation softmax est utilisée à la sortie du réseau pour interpréter
les sorties comme des valeurs de probabilité a posteriori. S’il s’agit
de classer un exemple <span class="math notranslate nohighlight">\(x\)</span> à la classe <span class="math notranslate nohighlight">\(c\)</span>, la probabilité conditionnelle
<span class="math notranslate nohighlight">\(p(c|x)\)</span> peut être calculée en utilisant la règle de Bayes :</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
p(c|x) = \frac{p(x|c)p(c)}{p(x)}
\end{aligned}\]</div>
<p><span class="math notranslate nohighlight">\(p(c|x)\)</span> est alors interprétée comme une probabilité a
posteriori. Disposant de ces probabilités pour tout <span class="math notranslate nohighlight">\(c=1,\ldots,C\)</span>, la
règle de décision de Bayes donne :</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
c: \mathbb{R}^D \rightarrow \{1,\ldots,C\}, x \mapsto  argmax_{c}\left(p(c|x)\right).
\end{aligned}\]</div>
<p>L’utilisation de la fonction d’activation softmax en
sortie permet d’interpréter les sorties du réseau comme de telles
probabilités :la sortie du <span class="math notranslate nohighlight">\(i^{\text{e}}\)</span> neurone de la couche de sortie
est</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    \sigma(z^{(L+1)},i) = \frac{\exp(z_i^{(L+1)})}{\displaystyle\sum_{k = 1} ^C \exp(z_k^{(L+1)})}.
\end{aligned}\]</div>
<p>En apprentissage profond, il a été reporté que la sigmoïde et la
tangente hyperbolique avaient des performances moindres que la fonction
d’activation softsign :</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    s(z) = \frac{1}{1+ |z|}.
\end{aligned}\]</div>
<p>En effet, les valeurs de <span class="math notranslate nohighlight">\(z\)</span> arrivant près des paliers
de saturation de ces fonctions donnent des gradients faibles, qui ont
tendance à s’annuler lors de la phase d’apprentissage détaillée plus
loin (rétropropagation du gradient). Une autre fonction, non saturante
elle, peut être utilisée :</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    r(z) = \max (0,z).
\end{aligned}\]</div>
<p>Les neurones cachés utilisant la fonction décrite dans
l’équation précédente sont appelés neurones linéaires rectifiés
(<strong>Rectified Linear Units, ReLUs</strong>), et sont en pratique très utilisés.</p>
<p>Quelques fonctions d’activation sont présentées dans la (<a class="reference internal" href="#tabact"><span class="std std-numref">Fig. 3</span></a>).</p>
<div class="figure align-default" id="tabact">
<img alt="_images/tabactivation.pdf" src="_images/tabactivation.pdf" />
<p class="caption"><span class="caption-number">Fig. 3 </span><span class="caption-text">Quelques fonctions d’activation</span><a class="headerlink" href="#tabact" title="Lien permanent vers cette image">#</a></p>
</div>
<p>Les fonctions d’activation sous Pytorch sont résumées <a class="reference external" href="https://pytorch.org/docs/stable/nn.functional.html">ici</a>.</p>
</div>
<div class="section" id="entrainement-des-reseaux-multicouches">
<h2>Entraînement des réseaux multicouches<a class="headerlink" href="#entrainement-des-reseaux-multicouches" title="Lien permanent vers ce titre">#</a></h2>
<p>Pour pouvoir utiliser les réseaux multicouches en apprentissage, deux
ingrédients sont indispensables :</p>
<ul class="simple">
<li><p>une méthode indiquant comment choisir une architecture de réseau
pour résoudre un problème donné. C’est-à-dire, pouvoir répondre aux
questions suivantes : combien de couches cachées ? combien de
neurones par couche cachée ?</p></li>
<li><p>une fois l’architecture choisie, un algorithme d’apprentissage qui
calcule, à partir d’un l’échantillon d’apprentissage
<span class="math notranslate nohighlight">\({\cal E}_a = \left \{({\mathbf x_n}, \mathbf t_n),n\in[\![1,N]\!] \right \}\)</span> , les
valeurs des poids synaptiques pour construire un réseau adapté au
problème (c’est à dire approchant une fonction <span class="math notranslate nohighlight">\(g\)</span> désirée mais
inconnue, telle qu’en particulier <span class="math notranslate nohighlight">\(\mathbf t_n \approx {\mathbf g(x_n)}\)</span>) .</p></li>
</ul>
<p>Sur le premier point, quelques algorithmes d’apprentissage
auto-constructifs ont été proposés. Leur rôle est double :</p>
<ul class="simple">
<li><p>apprentissage de l’échantillon avec un réseau courant,</p></li>
<li><p>modification du réseau courant, en ajoutant de nouvelles cellules ou
une nouvelle couche, en cas d’échec de l’apprentissage.</p></li>
</ul>
<p>Il semble assez facile de concevoir des algorithmes auto-constructifs
qui classent correctement l’échantillon, mais beaucoup plus difficile
d’en obtenir qui aient un bon pouvoir de généralisation.<br />
Il a fallu attendre le milieu des années 1980 pour que le deuxième
problème trouve une solution : l’algorithme de <strong>rétropropagation du
gradient</strong>.</p>
<p>L’entraînement, comme dans le cas de l’algorithme
de descentre de gradient, consiste à trouver les poids qui minimisent une
fonction d’erreur, mesurant l’écart entre la sortie du réseau <span class="math notranslate nohighlight">\(y({\mathbf x_n})\)</span>
et <span class="math notranslate nohighlight">\(\mathbf t_n\)</span>, pour tous les exemples de <span class="math notranslate nohighlight">\({\cal E}_a\)</span>. Les fonctions
couramment choisies sont les sommes des fonctions de perte sur chaque
exemple, et incluent l’erreur quadratique</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    E(\mathbf w) = \displaystyle\sum_{n = 1}^N E_n(\mathbf w) = \displaystyle\sum_{n = 1}^N \sum_{i = 1}^C (y_i(\mathbf x_n,\mathbf w) - t^i_{n})^2
\end{aligned}\]</div>
<p>ou l’erreur d’entropie croisée</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    E(\mathbf w) = \displaystyle\sum_{n = 1}^N E_n(\mathbf w) = \displaystyle\sum_{n = 1}^N \sum_{i = 1}^C t^i_{n} \log(y_i(\mathbf x_n,\mathbf w)),
\end{aligned}\]</div>
<p>où <span class="math notranslate nohighlight">\(t^i_{n}\)</span> est la <span class="math notranslate nohighlight">\(i^{\text{e}}\)</span> composante de <span class="math notranslate nohighlight">\(\mathbf t_n\)</span>.</p>
</div>
<div class="section" id="strategies-d-entrainement">
<h2>Stratégies d’entraînement<a class="headerlink" href="#strategies-d-entrainement" title="Lien permanent vers ce titre">#</a></h2>
<p>Parmi les stratégies d’entraînement qui peuvent être retenues, trois
sont classiquement utilisées</p>
<ul class="simple">
<li><p>entraînement sur <span class="math notranslate nohighlight">\({\cal E}_a\)</span>, les poids étant mis à jour après
présentation, en fonction de l’erreur totale
<span class="math notranslate nohighlight">\(E(\mathbf w) = \displaystyle\sum_{n=1}^N E_n(\mathbf w)\)</span>.</p></li>
<li><p>entraînement stochastique : un exemple est présenté et les poids
sont mis à jour sur l’erreur <span class="math notranslate nohighlight">\(E_n(\mathbf w)\)</span> calculée sur cet exemple
(règle Adaline)</p></li>
<li><p>entraînement par batch sur un sous-ensemble
<span class="math notranslate nohighlight">\(M \subseteq \{1,\ldots,N\}\)</span> de <span class="math notranslate nohighlight">\({\cal E}_a\)</span>, les poids étant mis à
jour en fonction de l’erreur cumulée
<span class="math notranslate nohighlight">\(E_M(\mathbf w) = \displaystyle\sum_{n \in M} E_n(\mathbf w)\)</span>.</p></li>
</ul>
</div>
<div class="section" id="optimisation-des-parametres">
<h2>Optimisation des paramètres<a class="headerlink" href="#optimisation-des-parametres" title="Lien permanent vers ce titre">#</a></h2>
<p>Considérons le cas de l’entraînement stochastique. La condition
nécessaire d’optimalité d’ordre 1 donne</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    \frac{\partial E_n}{\partial \mathbf w} = \nabla E_n(\mathbf w) = 0
\end{aligned}\]</div>
<p>Une méthode itérative est utilisée pour trouver une solution approchée.
Si <span class="math notranslate nohighlight">\(\mathbf w[t]\)</span> est le vecteur de poids à la <span class="math notranslate nohighlight">\(t^{\text{e}}\)</span> itération, une
mise à jour des poids <span class="math notranslate nohighlight">\(\Delta \mathbf w[t]\)</span> est calculée et propagée à
l’itération suivante : <span class="math notranslate nohighlight">\(\mathbf w[t+1] = \mathbf w[t] + \Delta \mathbf w[t]\)</span>. Comme dans le cas du perceptron, on peut utiliser une méthode de type descente de gradient
(ordre 1), ou une méthode type Newton (ordre 2, qui nécessite alors le
calcul ou l’estimation du Hessien <span class="math notranslate nohighlight">\(H_n\)</span> de <span class="math notranslate nohighlight">\(E_n\)</span> à chaque itération).</p>
<ul>
<li><p>pour la méthode de descente du gradient, la mise à jour est effectuée
par</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
                \Delta \mathbf w[t] = - \gamma \frac{\partial E_n}{\partial \mathbf w[t]} = - \gamma \nabla E_n (\mathbf w[t])
            
    \end{aligned}\]</div>
<p>où <span class="math notranslate nohighlight">\(\gamma\)</span> est le taux d’apprentissage.</p>
</li>
<li><p>pour les méthodes d’ordre 2, type Newton, la mise à jour s’effectue
selon le schéma</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
            \Delta \mathbf w[t] = - \gamma \left(\frac{\partial^2 E_n}{\partial \mathbf w[t]^2}\right)^{-1} \frac{\partial E_n}{\partial \mathbf w[t]} = - \gamma \left(\mathbf H_n\mathbf (\mathbf w[t])\right)^{-1} \nabla E_n(\mathbf w[t])  
    \end{aligned}\]</div>
<p>où <span class="math notranslate nohighlight">\(\gamma\)</span> est le taux d’apprentissage. L’ordre 2 assure une convergence plus rapide, mais requiert le calcul et l’inversion du Hessien <span class="math notranslate nohighlight">\(\mathbf H_n(\mathbf w[t])\)</span> de <span class="math notranslate nohighlight">\(E_n\)</span>, ce qui est coûteux.</p>
</li>
</ul>
</div>
<div class="section" id="initialisation-des-poids">
<h2>Initialisation des poids<a class="headerlink" href="#initialisation-des-poids" title="Lien permanent vers ce titre">#</a></h2>
<p>Une méthode itérative d’optimisation étant utilisée, l’initialisation
des poids requiert une attention toute particulière.</p>
<p>Une première idée est d’initialiser les poids selon une loi normale : <span class="math notranslate nohighlight">\(\forall i\; w_{ij} \rightsquigarrow 10^{-m}\mathcal{N}(0,1)\ m&gt;0 \)</span>. Cependant, cela amène naturellement rapidement à une évolution des poids vers des valeurs nulles (<a class="reference internal" href="#vanishing"><span class="std std-numref">Fig. 4</span></a>) (phénomène de disparition du gradient).</p>
<div class="figure align-default" id="vanishing">
<img alt="_images/vanishing.png" src="_images/vanishing.png" />
<p class="caption"><span class="caption-number">Fig. 4 </span><span class="caption-text">Quelques fonctions d’activation</span><a class="headerlink" href="#vanishing" title="Lien permanent vers cette image">#</a></p>
</div>
<p>En faisant l’hypothèse que les entrées de chaque cellule de la rétine sont
distribuées selon une loi gaussienne, il est alors courant de choisir les
poids aléatoirement dans</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    - \frac{1}{\sqrt{m^{(l-1)}}} &lt; w_{i,j}^{(l)} &lt; \frac{1}{\sqrt{m^{(l-1)}}}.
\end{aligned}\]</div>
<p>En utilisant des fonctions d’activation sigmoïde, il a été prouvé que
l’apprentissage était alors optimal, en le sens que l’apprentissage est
rapide et que les poids atteignent une valeur stable quasiment tous en
même temps.</p>
<p>Un autre schéma d’initialisation est possible (initialisation
normalisée, ou initialisation de Xavier) en choisissant</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    - \frac{\sqrt{6}}{\sqrt{m^{(l-1)} + m^{(l)}}} &lt; w_{i,j}^{(l)} &lt; \frac{\sqrt{6}}{\sqrt{m^{(l-1)} + m^{(l)}}}.
\end{aligned}\]</div>
</div>
<div class="section" id="retropropagation-de-l-erreur">
<h2>Rétropropagation de l’erreur<a class="headerlink" href="#retropropagation-de-l-erreur" title="Lien permanent vers ce titre">#</a></h2>
<p>L’algorithme
<a class="reference external" href="#alg:error-backpropagation">[alg:error-backpropagation]</a>{reference-type= »ref »
reference= »alg:error-backpropagation »}, dit algorithme de
rétropropagation du gradient, est utilisé pour évaluer le gradient
<span class="math notranslate nohighlight">\(\nabla E_n (w[t])\)</span> de l’erreur <span class="math notranslate nohighlight">\(E_n\)</span> à chaque itération, ceci pour tous
les poids</p>
<div class="highlight-algorithm notranslate"><div class="highlight"><pre><span></span>1.  Propager un exemple $x_n$ dans le réseau.

2.  Calculer les erreurs $\delta_i^{(L+1)}$ des neurones de sortie :
    $$\begin{aligned}
                (\forall i\in\{1\cdots C\})\quad\delta_i^{(L+1)} = \frac{\partial E_n}{\partial y_i^{(L+1)}} f&#39;(z_i^{(L+1)}).
            
    \end{aligned}$$

3.  Déterminer $\delta _i ^{(l)}$ pour toutes les couches cachées :
    $$\begin{aligned}
                (\forall l\in\{1\cdots L\})(\forall i\in\{1\cdots m^l\})\quad\delta _i ^{(l)} = f&#39; (z_i^{(l)}) \sum _{k = 1} ^{m^{(l+1)}} w_{i,k}^{(l+1)} \delta _k ^{(l+1)}.
            
    \end{aligned}$$

4.  Calculer les composantes du gradient : $$\begin{aligned}
                \label{eq:backprop-derivative}
                \frac{\partial E_n}{\partial w_{j,i}^{(l)}} = \delta _j ^{(l)} y_i^{(l-1)}.
            
    \end{aligned}$$

[]{#alg:error-backpropagation label=&quot;alg:error-backpropagation&quot;}
</pre></div>
</div>
<p>Dans le cas d’un apprentissage stochastique, cet algorithme est appliqué
jusqu’à convergence, pour estimer les poids du réseau de neurones.</p>
</div>
<div class="section" id="criteres-d-arret">
<h2>Critères d’arrêt<a class="headerlink" href="#criteres-d-arret" title="Lien permanent vers ce titre">#</a></h2>
<p>Plusieurs critères d’arrêt peuvent être utilisés avec l’algorithme de
rétropropagation du gradient. Le plus commun consiste à fixer un nombre
maximum de périodes d’entraînement (sur <span class="math notranslate nohighlight">\({\cal E}_a\)</span>), ce qui fixe
effectivement une limite supérieure sur la durée de l’apprentissage. Ce
critère est important car la rétropropagation n’offre aucune garantie
quant à la convergence de l’algorithme. Il peut arriver, par exemple,
que le processus d’optimisation reste pris dans un minimum local. Sans
un tel critère, l’algorithme pourrait ne jamais se terminer. Un deuxième
critère commun consiste à fixer une borne inférieure sur l’erreur
quadratique moyenne. Dépendant de l’application, il est parfois possible
de fixer <em>a priori</em> un objectif à atteindre. Lorsque l’indice de
performance choisi diminue en dessous de cet objectif, on considère
simplement que le réseau a suffisamment bien appris ses données et on
arrête l’apprentissage.<br />
Les deux critères précédents sont utiles mais ils comportent aussi des
limitations. Le critère relatif au nombre maximum de périodes
d’entraînement n’est aucunement lié à la performance du réseau. Le
critère relatif à l’erreur minimale obtenue mesure quant à lui un indice
de performance mais ce dernier peut engendrer un phénomène dit de
sur-apprentissage qui n’est pas désirable dans la pratique, surtout si
l’on ne possède pas une grande quantité de données d’apprentissage, ou
si ces dernières ne sont pas de bonne qualité.<br />
Un processus d’apprentissage comme celui de la rétropropagation, vise à
réduire autant que possible l’erreur que commet le réseau. Mais cette
erreur est mesurée sur un ensemble de données d’apprentissage
<span class="math notranslate nohighlight">\({\cal E}_a\)</span>. Si les données sont bonnes, c’est-à-dire quelles
représentent bien le processus physique sous-jacent que l’on tente
d’apprendre ou de modéliser, et que l’algorithme a convergé sur un
optimum global, alors il devrait bien se comporter sur d’autres données
issues du même processus physique. Cependant, si les données
d’apprentissage sont partiellement corrompues par du bruit ou par des
erreurs de mesure, alors il n’est pas évident que la performance
optimale du réseau soit atteinte en minimisant l’erreur, lorsqu’on la
testera sur un jeu de données différent de celui qui a servi à
l’entraînement. On parle alors de la capacité de généralisation du
réseau, c’est-à-dire sa capacité à bien se comporter avec des données
qu’il n’a jamais vu auparavant.</p>
<p>Une solution à ce problème consiste à faire appel à un autre critère
d’arrêt basé sur une technique de validation croisée. Cette technique
consiste à utiliser deux ensembles indépendants de données. En pratique,
il s’agit de partitionner <span class="math notranslate nohighlight">\({\cal E}_a\)</span> pour entraîner le réseau en un
ensemble d’apprentissage (ajustement des poids) un ensemble de
validation (calcul d’un indice de performance). Le critère d’arrêt
consiste alors à stopper l’apprentissage lorsque l’indice de performance
calculé sur les données de validation cesse de s’améliorer pendant
plusieurs périodes d’entraînement. Lors de deux périodes successives
d’entraînement, des exemples peuvent être échangés entre ensembles
d’apprentissage et de validation.</p>
</div>
<div class="section" id="propriete-fondamentale">
<h2>Propriété fondamentale<a class="headerlink" href="#propriete-fondamentale" title="Lien permanent vers ce titre">#</a></h2>
<p>Terminons par une dernière remarque sur la puissance de représentation
des réseaux multicouches. La plupart des fonctions numériques peuvent
être approximées avec une précision arbitraire par des réseaux à une
seule couche cachée. Mais cette couche cachée peut être démesurément
grande et le théorème de Hornik, qui affirme cette propriété
d’approximateurs universels des réseaux multicouches, est
essentiellement un résultat théorique sur l’expressivité des réseaux.</p>
<p>Plus formellement, la propriété fondamentale des réseaux de neurones est
l’approximation parcimonieuse, qui traduit deux propriétés distinctes :
d’une part les réseaux de neurones sont des approximateurs universels,
et d’autre part, une approximation à l’aide d’un réseau de neurones
nécessite, en général, moins de paramètres ajustables que les
approximateurs usuels.</p>
<ul class="simple">
<li><p>Approximateurs universels : Cybenko a énoncé en 1989 la propriété
suivante : toute fonction bornée, suffisamment régulière, peut être
approchée uniformément, avec une précision arbitraire, dans un
domaine fini de l’espace de ses variables, par un réseau de neurones
comportant une couche de neurones cachés en nombre fini, possédant
tous la même fonction d’activation, et un neurone de sortie
linéaire.\</p></li>
<li><p>Parcimonie : Hornik a montré en 1994 que si la sortie d’un réseau de
neurones est une fonction non linéaire des paramètres ajustables,
elle est plus parcimonieuse que si elle était une fonction linéaire
de ces paramètres. De plus, pour les réseaux dont la fonction
d’activation des neurones est une sigmoïde, l’erreur commise dans
l’approximation varie comme l’inverse du nombre de neurones cachés,
et elle est indépendante du nombre de variables de la fonction à
approcher. Ainsi, pour une précision donnée (<em>i.e.</em> étant donné un
nombre de neurones cachés) le nombre de paramètres du réseau est
proportionnel au nombre de variables de la fonction à approcher.\</p></li>
</ul>
<p>Dans la plupart des cas d’utilisation des réseaux de neurones, il va
s’agir d’établir un modèle d’une fonction inconnue à partir de mesures
bruitées de l’ensemble d’apprentissage, permettant de reproduire les
sorties à partir des entrées, et de proposer une généralisation à des
données test. On cherche alors la <strong>fonction de régression</strong> du
processus considéré, <em>i.e.</em> la fonction obtenue en calculant la moyenne
d’une infinité de mesures effectuées en chaque point du domaine de
validité du modèle. Le nombre de points de ce domaine étant lui-même
infini, la connaissance de la fonction de régression nécessiterait donc
une infinité de mesures en un nombre infini de points.<br />
Les réseaux de neurones, en raison de leur propriété fondamentale, sont
de bons candidats pour réaliser une approximation de la fonction de
régression à partir d’un nombre fini de mesures. Ils entrent donc dans
le cadre des méthodes statistiques d’apprentissage, et élargissent ce
domaine déjà bien exploré pour des fonctions de régression linéaire au
cas non linéaire.\</p>
</div>
<div class="section" id="regularisation">
<h2>Régularisation<a class="headerlink" href="#regularisation" title="Lien permanent vers ce titre">#</a></h2>
<p>La notion d’approximateur universel peut induire également un problème
de surapprentissage (overfitting) de <span class="math notranslate nohighlight">\({\cal E}_a\)</span>. Les techniques de
régularisation permettent d’éviter ce problème, et permettent aux
réseaux de neurones (et à d’autres algorithmes d’ailleurs, comme les
autoencodeurs ou les SVM par exemple) d’avoir une bonne capacité de
généralisation.<br />
Il existe plusieurs techniques permettant d’introduire de la
régularisation dans les réseaux. Parmi elles, on note :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\({\cal E}_a\)</span> est enrichi pour introduire certaines invariances que
le réseau est supposé apprendre.</p></li>
<li><p>à chaque exemple présenté, chaque neurone caché est supprimé du
calcul de la sortie avec probabilité <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span>. Cette technique
peut être vue comme la construction d’un modèle moyen
d’apprentissage de plusieurs réseaux distincts.</p></li>
<li><p>lorsque <span class="math notranslate nohighlight">\({\cal E}_a\)</span> est séparé en un ensemble d’apprentissage
<span class="math notranslate nohighlight">\({\cal E}^1_a\)</span> et un ensemble de validation <span class="math notranslate nohighlight">\({\cal E}^2_a\)</span>, il est
courant de voir que l’erreur baisse sur <span class="math notranslate nohighlight">\({\cal E}^1_a\)</span> au fil des
itérations, alors que l’erreur sur <span class="math notranslate nohighlight">\({\cal E}^2_a\)</span> tend à augmenter
lorsque le réseau commence à sur-apprendre sur <span class="math notranslate nohighlight">\({\cal E}^1_a\)</span>.
L’entraînement est alors stoppé dès que l’erreur sur <span class="math notranslate nohighlight">\({\cal E}^2_a\)</span>
atteint un minimum. Cette technique est appelée early stopping
(arrêt précoce).</p></li>
<li><p>le partage de poids : plusieurs neurones d’une même couche partagent
des mêmes valeurs de poids. La complexité du réseau est réduite et
des informations <em>a priori</em> peuvent être introduites par ce biais
dans l’architecture du réseau. L’algorithme de rétropropagation du
gradient s’en trouve modifié et l’équation
<a class="reference external" href="#eq:backprop-derivative">[eq:backprop-derivative]</a>{reference-type= »eqref »
reference= »eq:backprop-derivative »} devient $<span class="math notranslate nohighlight">\(\begin{aligned}
    \frac{\partial E_n}{\partial w_{j,i}^{(l)}} = \sum _{k = 1} ^{m^{(l)}} \delta_k^{(l)} y_i^{(l-1)}
\end{aligned}\)</span><span class="math notranslate nohighlight">\( en supposant que tous les neurones de la couche \)</span>l<span class="math notranslate nohighlight">\(
sont tels que \)</span>w_{j,i}^{(l)} = w_{k,i}^{(l)}<span class="math notranslate nohighlight">\( pour
\)</span>1 \leq j,k \leq m^{(l)}$</p></li>
<li><p>un terme de régularisation est ajouté à la fonctionnelle à minimiser
pour contrôler la complexité et le forme de la solution et, par
exemple $<span class="math notranslate nohighlight">\(\begin{aligned}
    \hat{E}_n (w) = E_n (w) + \eta P(w)
\end{aligned}\)</span><span class="math notranslate nohighlight">\( où \)</span>P(w)<span class="math notranslate nohighlight">\( influence la forme de la solution et
\)</span>\eta<span class="math notranslate nohighlight">\( contrôle l'influence du terme de régularisation. \)</span>P(w)<span class="math notranslate nohighlight">\( peut
prendre la forme d'une fonction de la norme \)</span>L_p<span class="math notranslate nohighlight">\( de \)</span>w$. Deux
exemples classiques sont :</p>
<ul>
<li><p>la régularisation <span class="math notranslate nohighlight">\(L_2\)</span> : $<span class="math notranslate nohighlight">\(\begin{aligned}
    P(w) = \|w\|_2^2 = w^Tw.
\end{aligned}\)</span>$ où le principe est de pénaliser les poids de
fortes valeurs, qui tendent à amplifier le problème de
surapprentissage.</p></li>
<li><p>la régularisation <span class="math notranslate nohighlight">\(L_1\)</span> : $<span class="math notranslate nohighlight">\(\begin{aligned}
    P(w) = \|w\|_1 = \displaystyle\sum_{k = 1} ^W |w_k|.
\end{aligned}\)</span><span class="math notranslate nohighlight">\( où \)</span>W<span class="math notranslate nohighlight">\( est la dimension de \)</span>w$, qui tend à
rendre épars le vecteur de poids (beaucoup de valeurs de poids
deviennent nulles).</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="exemple">
<h2>Exemple<a class="headerlink" href="#exemple" title="Lien permanent vers ce titre">#</a></h2>
<p>On va considérer le réseau décrit sur la figure
<a class="reference external" href="#F:XOR_BackPropagation">1.5</a>{reference-type= »ref »
reference= »F:XOR_BackPropagation »} pour apprendre la fonction du OU
exclusif (aussi appelé XOR). L’opérateur XOR est défini par sa table de
vérité donnée par le tableau <a class="reference external" href="#T:XOR">1.2</a>{reference-type= »ref »
reference= »T:XOR »}.\</p>
<div class="section" id="reseau">
<h3>Réseau<a class="headerlink" href="#reseau" title="Lien permanent vers ce titre">#</a></h3>
<p>Sur le réseau de la figure
<a class="reference external" href="#F:XOR_BackPropagation">1.5</a>{reference-type= »ref »
reference= »F:XOR_BackPropagation »} les différentes relations sont
données par l’équation <a class="reference external" href="#E:XOR">[E:XOR]</a>{reference-type= »ref »
reference= »E:XOR »} où les paramètres en rouge correspondent aux poids à
calculer durant la phase d’apprentissage.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\left\{
        \begin{array}{r c l}
            z_1 &amp;=&amp; {\color{red}w_1}~x_1+{\color{red}w_2}~x_2+{\color{red}b_1}\\
            z_2 &amp;=&amp; {\color{red}w_3}~x_1+{\color{red}w_4}~x_2+{\color{red}b_2}\\
            z_3 &amp;=&amp; {\color{red}w_5}~x_1+{\color{red}w_6}~x_2+{\color{red}b_3}\\
            z_4 &amp;=&amp; {\color{red}w_7}~h_1\left(z_1\right)+{\color{red}w_8}~h_2\left(z_2\right)+{\color{red}w_9}~h_3\left(z_3\right)+{\color{red}b_4}\\
            y &amp;=&amp; h_4\left(z_4\right) \\
            h_i\left(z_i\right) &amp;=&amp; \frac{1}{1+e^{-z_i}} \ \ \ \ (sigmoide)
        \end{array}
    \right.
    \label{E:XOR}\end{split}\]</div>
<figure id="F:XOR_BackPropagation">
<figcaption>Exemple d’un réseau pour apprendre la relation
XOR.</figcaption>
</figure>
</div>
<div class="section" id="phase-d-apprentissage">
<h3>Phase d’apprentissage<a class="headerlink" href="#phase-d-apprentissage" title="Lien permanent vers ce titre">#</a></h3>
<p>Durant la phase d’apprentissage, on minimise un risque empirique par une
fonction de coût. Dans cet exemple, nous allons choisir la minimisation
de l’écart quadratique avec la base d’apprentissage labelisée
<span class="math notranslate nohighlight">\({\cal E}_a =\left( \textbf{x}, \textbf{y}_{lab} \right)\)</span> ou une partie
de cette base d’apprentissage <span class="math notranslate nohighlight">\(\mathcal{E}_a^\prime\)</span> :
$<span class="math notranslate nohighlight">\(E\left({\cal E}_a\right)=E_{tot}=\displaystyle\frac{1}{2}\sum_k \left(y[k]_{lab} - y \right)^2 = \displaystyle\frac{1}{2}\sum_k\left(y[k]_{lab} - h_4\left(z_4\right)  \right)^2.\)</span><span class="math notranslate nohighlight">\(
On peut utiliser qu'une partie de la base, voire que le \)</span>k^{ieme}$
échantillon de la base (cf. gradient stochastique) :</p>
<div class="math notranslate nohighlight">
\[E\left(x_k\right)=E_{k}=\displaystyle\frac{1}{2}\left(y[k]_{lab} - y \right)^2 = \displaystyle\frac{1}{2}\left(y[k]_{lab} - h_4\left(z_4\right)  \right)^2 .
    \]</div>
<p>L’objectif de la phase d’apprentissage est de mettre à jour les poids du
réseau par une approche de descente du gradient. Si l’on considère un
poids quelconque du réseau que l’on note <span class="math notranslate nohighlight">\(\theta\)</span>, sa mise à jour durant
l’itération <span class="math notranslate nohighlight">\(n+1\)</span> se fait pas l’équation suivante:
$<span class="math notranslate nohighlight">\(\theta^{\left(n+1\right)} = \theta^{\left(n\right)} + \gamma_n\times \Delta \theta\)</span><span class="math notranslate nohighlight">\(
où \)</span><span class="math notranslate nohighlight">\(\Delta \theta = -\nabla_\theta E.\)</span><span class="math notranslate nohighlight">\( On peut choisir \)</span>E=E_{tot}<span class="math notranslate nohighlight">\( ou
\)</span>E=E_k$ et pour cet exemple nous choisirons le deuxième cas.</p>
<div class="section" id="couche-de-sortie">
<h4>Couche de sortie<a class="headerlink" href="#couche-de-sortie" title="Lien permanent vers ce titre">#</a></h4>
<p>Pour la couche de sortie, prenons par exemple le paramètre <span class="math notranslate nohighlight">\(w_7\)</span>, sa
mise à jour est donnée par la relation suivante :
$<span class="math notranslate nohighlight">\(w_7^{\left(n+1\right)} = w_7^{\left(n\right)} - \eta \times \frac{\partial E_k}{\partial w_7}.\)</span>$</p>
<p>Le problème consiste à calculer <span class="math notranslate nohighlight">\(\frac{\partial E_k}{\partial w_7}\)</span>,
pour cela nous allons utiliser le théorème de dérivation des fonctions
composées, d’où:</p>
<div class="math notranslate nohighlight">
\[\frac{\partial E_k}{\partial w_7} = \frac{\partial E_k}{\partial h_4} \times  \frac{\partial h_4}{\partial z_4} \times  \frac{\partial z_4}{\partial w_7}\]</div>
<p>Cette relation est représentée graphiquement sur la figure
<a class="reference external" href="#F:CoucheSortie">1.6</a>{reference-type= »ref »
reference= »F:CoucheSortie »}.<br />
Utilisant l’expression de A <span class="math notranslate nohighlight">\(E_k\)</span> on a alors :
$<span class="math notranslate nohighlight">\(\left\{
        \begin{array}{r c l}
            \displaystyle\frac{\partial E_k}{\partial h_4} &amp;=&amp; \frac{\partial }{\partial h_4}\left( \frac{1}{2}\left(y[k]_{lab} - h_4\left(z_4\right)  \right)^2 \right) = -\left(y[k]_{lab} - h_4\left(z_4\right)  \right)\\
            \displaystyle\frac{\partial h_4}{\partial z_4}  &amp;=&amp; \frac{\partial }{\partial z_4}\left( \frac{1}{1+e^{-z_4}}\right) = \frac{e^{-z_4}}{\left(1+e^{-z_4}\right)^2} = h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) \\
            \displaystyle\frac{\partial z_4}{\partial w_7} &amp;=&amp; h_1\left(z_1\right)
        \end{array}
    \right.
    \)</span>$</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>d&#39;où
</pre></div>
</div>
<div class="math notranslate nohighlight">
\[w_7^{(n+1)} = w_7^{(n) }+ (y[k]_{lab} - h_4(z_4)) h_4(z_4)( 1 - h_4(z_4))
h_1(z_1)\]</div>
<p>On peut réaliser la même démarche pour les poids <span class="math notranslate nohighlight">\(w_8\)</span>, <span class="math notranslate nohighlight">\(w_9\)</span> et <span class="math notranslate nohighlight">\(b_4\)</span>,
pour obtenir les relations suivantes :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\left\{
        \begin{array}{r c l}
            w_8^{\left(n+1\right)} &amp;=&amp; w_8^{\left(n\right)} + \eta \times \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_2\left(z_2\right) \\
            w_9^{\left(n+1\right)} &amp;=&amp; w_9^{\left(n\right)} + \eta \times \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_3\left(z_3\right) \\
            b_4^{\left(n+1\right)} &amp;=&amp; b_4^{\left(n\right)} + \eta \times \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) 
        \end{array}
    \right.
    \end{split}\]</div>
<figure id="F:CoucheSortie">
<figcaption>Rétropropagation du gradient sur la couche de
sortie.</figcaption>
</figure>
</div>
<div class="section" id="couche-cachee">
<h4>Couche cachée<a class="headerlink" href="#couche-cachee" title="Lien permanent vers ce titre">#</a></h4>
<p>Pour la couche cachée du réseau, c’est exactement le même raisonnement.
Prenons par exemple, le paramètre <span class="math notranslate nohighlight">\(w_1\)</span> pour le calcul :
$<span class="math notranslate nohighlight">\(w_1^{\left(n+1\right)} = w_1^{\left(n\right)} - \eta \times \frac{\partial E_k}{\partial w_1}.\)</span><span class="math notranslate nohighlight">\(
Le problème maintenant consiste à calculer
\)</span>\frac{\partial E_k}{\partial w_1}<span class="math notranslate nohighlight">\(, pour cela nous allons utiliser le
théorème de dérivation des fonctions composées, d'où:
\)</span><span class="math notranslate nohighlight">\(\frac{\partial E_k}{\partial w_1} = \frac{\partial E_k}{\partial z_4} \times  \frac{\partial z_4}{\partial h_1}  \times  \frac{\partial h_1}{\partial z_1} \times  \frac{\partial z_1}{\partial w_1}\)</span>$
Cette relation est représentée graphiquement sur la figure
<a class="reference external" href="#F:CoucheCachee">1.7</a>{reference-type= »ref »
reference= »F:CoucheCachee »}.<br />
A l’aide de l’équation <a class="reference external" href="#E:XOR">[E:XOR]</a>{reference-type= »ref »
reference= »E:XOR »}, de l’équation <a class="reference external" href="#E:Ek">[E:Ek]</a>{reference-type= »ref »
reference= »E:Ek »} et de l’équation
<a class="reference external" href="#E:CompOutLayer">[E:CompOutLayer]</a>{reference-type= »ref »
reference= »E:CompOutLayer »} on obtient:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\left\{
        \begin{array}{r c l}
            \displaystyle\frac{\partial E_k}{\partial z_4} &amp;=&amp; -\left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right)\\
            \displaystyle\frac{\partial z_4}{\partial h_1}  &amp;=&amp; w_7 \\
            \displaystyle\frac{\partial h_1}{\partial z_1} &amp;=&amp; h_1\left(z_1\right)\left( 1 - h_1\left(z_1\right)\right)\\
            \displaystyle\frac{\partial z_1}{\partial w_1} &amp;=&amp; x_1
        \end{array}
    \right.
    \end{split}\]</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>d&#39;où
</pre></div>
</div>
<div class="math notranslate nohighlight">
\[
w_1^{(n+1)} = w_1^{(n)} + (y[k]{_lab} - h_4(z_4)) h_4(z_4)( 1 - h_4(z_4))h_1(z_1)( 1 - h_1(z_1)) w_7 x_1
\]</div>
<p>On peut réaliser la même démarche pour les poids <span class="math notranslate nohighlight">\(w_2\)</span> et <span class="math notranslate nohighlight">\(b_1\)</span>, pour
obtenir les relations suivantes :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\left\{
        \begin{array}{r c l}
            w_2^{\left(n+1\right)} &amp;=&amp; w_2^{\left(n\right)} + \eta \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_1\left(z_1\right)\left( 1 - h_1\left(z_1\right)\right) w_7 x_2\\
            b_1^{\left(n+1\right)} &amp;=&amp; b_1^{\left(n\right)} + \eta \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_1\left(z_1\right)\left( 1 - h_1\left(z_1\right)\right) w_7
        \end{array}
    \right.
    \end{split}\]</div>
<figure id="F:CoucheCachee">
<figcaption>Rétropropagation du gradient sur la couche
cachée.</figcaption>
</figure>
<p>Il suffit de réaliser des calculs identiques pour les autres neurones et
on obtient les relations suivantes : $<span class="math notranslate nohighlight">\(\left\{
            \begin{array}{r c l}
                w_3^{\left(n+1\right)} &amp;=&amp; w_3^{\left(n\right)} + \eta \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_2\left(z_2\right)\left( 1 - h_2\left(z_2\right)\right) w_8 x_1\\                
                w_4^{\left(n+1\right)} &amp;=&amp; w_4^{\left(n\right)} + \eta \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_2\left(z_2\right)\left( 1 - h_2\left(z_2\right)\right) w_8 x_2\\
                w_5^{\left(n+1\right)} &amp;=&amp; w_5^{\left(n\right)} + \eta \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_3\left(z_3\right)\left( 1 - h_3\left(z_3\right)\right) w_9 x_1\\                
                w_6^{\left(n+1\right)} &amp;=&amp; w_6^{\left(n\right)} + \eta \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_3\left(z_3\right)\left( 1 - h_3\left(z_3\right)\right) w_9 x_2\\
                b_2^{\left(n+1\right)} &amp;=&amp; b_2^{\left(n\right)} + \eta \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_2\left(z_2\right)\left( 1 - h_2\left(z_2\right)\right) w_8 \\
                b_3^{\left(n+1\right)} &amp;=&amp; b_3^{\left(n\right)} + \eta \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_3\left(z_3\right)\left( 1 - h_3\left(z_3\right)\right) w_9               
            \end{array}
        \right.\)</span>$</p>
</div>
<div class="section" id="initialisation-des-poids-initialisation-des-poids">
<h4>Initialisation des poids {#initialisation-des-poids}<a class="headerlink" href="#initialisation-des-poids-initialisation-des-poids" title="Lien permanent vers ce titre">#</a></h4>
<ul class="simple">
<li><p>les biais sont initialisés à zéro
<span class="math notranslate nohighlight">\(( b_1, b_2, b_3, b_4 ) = \mathbf{0}_4\)</span> ;</p></li>
<li><p>pour les poids <span class="math notranslate nohighlight">\(w_i\)</span>, ils sont initialisées de façon aléatoire
dépendant de la taille de la couche d’avant <span class="math notranslate nohighlight">\(m^{(l-1)}\)</span> et d’après
<span class="math notranslate nohighlight">\(m^{(l)}\)</span>.<br />
L’initialisation de Xavier propose un tirage uniforme dans
<span class="math notranslate nohighlight">\(\left[-\sqrt{\frac{6}{m^{(l-1)}+m^{(l)}}} ;\sqrt{\frac{6}{m^{(l-1)}+m^{(l)}}} \right]\)</span>.</p></li>
</ul>
<p>Pour notre exemple, on obtient l’initialisation suivante : $<span class="math notranslate nohighlight">\(\left\{
        \begin{array}{r c l}
            w_1 \ ...\ w_6 &amp;=&amp; UD \ dans \ \left[-\sqrt{\frac{6}{2+3}} ;\sqrt{\frac{6}{2+3}} \right] = \left[-1,09;1,09 \right]\\
            w_7 \ ... \ w_9 &amp;=&amp; UD \ dans \ \left[-\sqrt{\frac{6}{3+1}} ;\sqrt{\frac{6}{3+1}} \right] = \left[-1,23;1,23 \right]
        \end{array}
    \right.\)</span>$</p>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="NN.html" title="précédent page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">précédent</p>
            <p class="prev-next-title">Introduction aux réseaux de neurones</p>
        </div>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Vincent BARRA<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>