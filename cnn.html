
<!DOCTYPE html>


<html lang="fr" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Réseaux convolutifs &#8212; Apprentissage profond</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="_static/documentation_options.js?v=72dce1d2"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="_static/translations.js?v=bf059b8c"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'cnn';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Recherche" href="search.html" />
    <link rel="next" title="Auto-encodeurs" href="ae.html" />
    <link rel="prev" title="Perceptrons multicouches" href="PMC.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="fr"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Passer au contenu principal</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Haut de page
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Apprentissage profond - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Apprentissage profond - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Recherche" aria-label="Recherche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Recherche</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="NN.html">Introduction aux réseaux de neurones</a></li>
<li class="toctree-l1"><a class="reference internal" href="PMC.html">Perceptrons multicouches</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Réseaux convolutifs</a></li>
<li class="toctree-l1"><a class="reference internal" href="ae.html">Auto-encodeurs</a></li>
<li class="toctree-l1"><a class="reference internal" href="rnn.html">Réseaux récurrents</a></li>
<li class="toctree-l1"><a class="reference internal" href="transferLearning.html">Utilisation de réseaux existants</a></li>
<li class="toctree-l1"><a class="reference internal" href="transformers.html">Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="gnn.html">Graph Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="gan.html">Réseaux antagonistes générateurs</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Mode plein écran"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="clair/sombre" aria-label="clair/sombre" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Recherche" aria-label="Recherche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Réseaux convolutifs</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contenu </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inspiration-biologique">Inspiration biologique</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convolution-discrete">Convolution discrète</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#definition-des-couches">Définition des couches</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#couche-de-convolution">Couche de convolution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#couche-non-lineaire">Couche non linéaire</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#couches-de-normalisation">Couches de normalisation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#couche-d-agregation-et-de-sous-echantillonnage">Couche d’agrégation et de sous-échantillonnage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#couche-completement-connectee">Couche complètement connectée</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regularisation">Régularisation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regularisation-de-la-fonction-de-cout">Régularisation de la fonction de coût</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dropout">Dropout</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#partage-de-parametres">Partage de paramètres</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#initialisation">Initialisation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apprentissage">Apprentissage</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#le-probleme-de-l-entrainement">Le problème de l’entraînement</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisation-du-mecanisme-des-reseaux-convolutifs">Visualisation du mécanisme des réseaux convolutifs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#methodes-de-visualisation-de-base">Méthodes de visualisation de base</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#methodes-fondees-sur-les-activations">Méthodes fondées sur les activations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#methodes-fondees-sur-le-gradient">Méthodes fondées sur le gradient</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implémentation</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="reseaux-convolutifs">
<h1>Réseaux convolutifs<a class="headerlink" href="#reseaux-convolutifs" title="Lien vers cette rubrique">#</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Lien vers cette rubrique">#</a></h2>
<section id="inspiration-biologique">
<h3>Inspiration biologique<a class="headerlink" href="#inspiration-biologique" title="Lien vers cette rubrique">#</a></h3>
<p>Un réseau de neurones convolutif (CNN, <em>Convolutional Neural Network</em>) est un type de réseau de neurones artificiels acyclique à
propagation avant, dans lequel le motif de connexion entre les neurones
est inspiré par le cortex visuel des animaux. Les neurones de cette
région du cerveau sont arrangés de sorte à ce qu’ils correspondent à des
régions (appelés champs réceptifs) qui se chevauchent lors du pavage du
champ visuel. Ils sont de plus organisés de manière hiérarchique, en
couches (aire visuelle primaire V1, secondaire V2, puis aires V3, V4, V5
et V6, gyrus temporal inférieur), chacune des couches étant spécialisée
dans une tâche, de plus en plus abstraite en allant de l’entrée vers la
sortie. En simplifiant à l’extrême, une fois que les signaux lumineux
sont reçus par la rétine et convertis en potentiels d’action :</p>
<ul class="simple">
<li><p>L’aire primaire V1 s’intéresse principalement à la détection de
contours, ces contours étant définis comme des zones de fort
contraste de signaux visuels reçus.</p></li>
<li><p>L’aire V2 reçoit les informations de V1 et extrait des informations
telles que la fréquence spatiale, l’orientation, ou encore la
couleur.</p></li>
<li><p>L’aire V4, qui reçoit des informations de V2, mais aussi de V1
directement, détecte des caractéristiques plus complexes et
abstraites liées par exemple à la forme.</p></li>
<li><p>Le gyrus temporal inférieur est chargé de la partie sémantique
(reconnaissance des objets), à partir des informations reçues des
aires précédentes et d’une mémoire des informations stockées sur des
objets.</p></li>
</ul>
<p>L’architecture et le fonctionnement des réseaux convolutifs sont
inspirés par ces processus biologiques. Ces réseaux consistent en un
empilage multicouche de perceptrons, dont le but est de prétraiter de
petites quantités d’informations. Les réseaux convolutifs ont de larges
applications dans la reconnaissance d’image et vidéo, les systèmes de
recommandation et le traitement du langage naturel.</p>
<p>Un réseau convolutif se compose de deux types de neurones, agencés en
couches traitant successivement l’information. Dans le cas du traitement
de données de type images, on a ainsi :</p>
<ul class="simple">
<li><p>des <em>neurones de traitement</em>, qui traitent une portion limitée de
l’image (le champ réceptif) au travers d’une fonction de
convolution;</p></li>
<li><p>des <em>neurones</em> de mise en commun des sorties dits <em>d’agrégation
totale ou partielle</em> (<em>pooling</em>).</p></li>
</ul>
<p>Un traitement correctif non linéaire est appliqué entre chaque couche
pour améliorer la pertinence du résultat. L’ensemble des sorties d’une
couche de traitement permet de reconstituer des images intermédiaires,
dite cartes de caractéristiques (feature maps), qui servent de base à la
couche suivante. Les couches et leurs connexions apprennent des niveaux
d’abstraction croissants et extraient des caractéristiques de plus en
plus haut niveau des données d’entrée.</p>
<p>Dans la suite, le propos sera illustré sur des images 2D en niveaux de
gris, de taille <span class="math notranslate nohighlight">\(n_1 \times n_2\)</span> :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \mathbf{I} : [\![1,n_1]\!]\times [\![1, n_2]\!] &amp;\rightarrow&amp;  \mathbb{R}\\
     (i,j) &amp;\mapsto&amp; I_{i,j}
\end{aligned}\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(\mathbf{I}\)</span> sera indifféremment vue comme une fonction ou une matrice.</p>
</section>
<section id="convolution-discrete">
<h3>Convolution discrète<a class="headerlink" href="#convolution-discrete" title="Lien vers cette rubrique">#</a></h3>
<p>Pour reproduire la notion de champ réceptif, et ainsi permettre aux
neurones de détecter des caractéristiques de petite taille mais porteurs
d’information, l’idée est de laisser un neurone caché voir et traiter
seulement une petite portion de l’image qu’il prend en entrée. L’outil
retenu dans les réseaux convolutifs est la convolution discrète.</p>
<div class="proof definition admonition" id="definition-0">
<p class="admonition-title"><span class="caption-number">Definition 5 </span> (Convolution discrète)</p>
<section class="definition-content" id="proof-content">
<p>Soient
<span class="math notranslate nohighlight">\(h_1,h_2\in\mathbb{N}, \mathbf{K} \in \mathbb{R}^{(2h_1+1) \times (2h_2+1)}\)</span>.
La convolution discrète de <span class="math notranslate nohighlight">\(\mathbf{I}\)</span> par le filtre <span class="math notranslate nohighlight">\(\mathbf{K}\)</span> est
donnée par :</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    \label{eq:convolution}
    \left(\mathbf{K} \ast \mathbf{I}\right)_{r,s} = \displaystyle\sum _{u = -h_1} ^{h_1} \displaystyle\sum _{v = -h_2}^{h_2} K_{u,v} I_{r+u,s+v}
\end{aligned}\]</div>
<p>où <span class="math notranslate nohighlight">\(\mathbf{K}\)</span> est donné par :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \mathbf{K} =
    \begin{pmatrix}
        K_{-h_1,-h_2} &amp; \ldots &amp; K_{-h_1,h_2}\\
        \vdots &amp; K_{0,0} &amp; \vdots\\
        K_{h_1,-h_2} &amp; \ldots &amp; K_{h_1,h_2}\\
    \end{pmatrix}.
\end{aligned}\end{split}\]</div>
</section>
</div><p>La taille du filtre <span class="math notranslate nohighlight">\((2h_1+1) \times (2h_2+1)\)</span> précise le champ visuel
capturé et traité par <span class="math notranslate nohighlight">\(\mathbf{K}\)</span>.<br />
Lorsque <span class="math notranslate nohighlight">\(\mathbf{K}\)</span> parcourt <span class="math notranslate nohighlight">\(\mathbf{I}\)</span>, le déplacement du filtre est
réglé par deux paramètres de <em>stride</em> (horizontal et vertical). Un
stride de 1 horizontal (respectivement vertical) signifie que
<span class="math notranslate nohighlight">\(\mathbf{K}\)</span> se déplace d’une position horizontale (resp. verticale) à
chaque application de l’équation précédente. Les valeurs de stride peuvent également
être supérieures et ainsi sous-échantillonner <span class="math notranslate nohighlight">\(\mathbf{I}\)</span>.</p>
<p>Le comportement du filtre sur les bords de <span class="math notranslate nohighlight">\(\mathbf{I}\)</span> doit également
être précisé, par l’intermédiaire d’un paramètre de <em>padding</em>. Si
l’image convoluée <span class="math notranslate nohighlight">\(\left(\mathbf{K} \ast \mathbf{I}\right)\)</span> doit
posséder la même taille que <span class="math notranslate nohighlight">\(\mathbf{I}\)</span>, alors <span class="math notranslate nohighlight">\(2h_1\)</span> lignes de 0
(<span class="math notranslate nohighlight">\(h_1\)</span> en haut et <span class="math notranslate nohighlight">\(h_1\)</span> en bas) et <span class="math notranslate nohighlight">\(2h_2\)</span> colonnes de 0 (<span class="math notranslate nohighlight">\(h_2\)</span> à gauche
et <span class="math notranslate nohighlight">\(h_2\)</span> à droite) doivent être ajoutées. Dans le cas où la convolution
est réalisée sans padding, l’image convoluée est de taille
<span class="math notranslate nohighlight">\((n_1-2h_1)\times (n_2-2h_2)\)</span>.</p>
</section>
</section>
<section id="definition-des-couches">
<h2>Définition des couches<a class="headerlink" href="#definition-des-couches" title="Lien vers cette rubrique">#</a></h2>
<p>Nous introduisons ici les principaux types de couches utilisées dans les
réseaux convolutifs. L’assemblage de ces couches permet de construire
des architectures complexes pour la classification ou la régression.</p>
<section id="couche-de-convolution">
<h3>Couche de convolution<a class="headerlink" href="#couche-de-convolution" title="Lien vers cette rubrique">#</a></h3>
<p>Soit <span class="math notranslate nohighlight">\(l\in\mathbb{N}\)</span> une couche de convolution. L’entrée de la couche
<span class="math notranslate nohighlight">\(l\)</span> est composée de <span class="math notranslate nohighlight">\(n^{(l-1)}\)</span> cartes provenant de la couche
précédente, de taille <span class="math notranslate nohighlight">\(n_1^{(l-1)} \times n_2^{(l-1)}\)</span>. Dans le cas de
la couche d’entrée du réseau (<span class="math notranslate nohighlight">\(l = 1\)</span>), l’entrée est l’image
<span class="math notranslate nohighlight">\(\mathbf{I}\)</span>. La sortie de la couche <span class="math notranslate nohighlight">\(l\)</span> est formée de <span class="math notranslate nohighlight">\(n^{(l)}\)</span> cartes
de taille <span class="math notranslate nohighlight">\(n_1^{(l)} \times n_2^{(l)}\)</span>. La <span class="math notranslate nohighlight">\(i^{\text{e}}\)</span> carte de la
couche <span class="math notranslate nohighlight">\(l\)</span>, notée <span class="math notranslate nohighlight">\(\mathbf{Y_i^{(l)}}\)</span>, se calcule comme :</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    \mathbf{Y_i^{(l)}} = \mathbf{B^{(l)}_{i}} + \displaystyle\sum _{j = 1}^{n^{(l-1)}} \mathbf{K^{(l)}_{i,j}} \ast \mathbf{Y_j^{(l-1)}}
\end{aligned}\]</div>
<p>où <span class="math notranslate nohighlight">\(\mathbf{B_i^{(l)}}\)</span> est une matrice de biais et
<span class="math notranslate nohighlight">\(\mathbf{K^{(l)}_{i,j}}\)</span> est le filtre de taille
<span class="math notranslate nohighlight">\((2h_1^{(l)} + 1) \times (2h_2^{(l)} + 1)\)</span> connectant la <span class="math notranslate nohighlight">\(j^{\text{e}}\)</span>
carte de la couche <span class="math notranslate nohighlight">\((l-1)\)</span> à la <span class="math notranslate nohighlight">\(i^{\text{e}}\)</span> carte de la couche <span class="math notranslate nohighlight">\(l\)</span>
(<a class="reference internal" href="#cnn1"><span class="std std-numref">Fig. 10</span></a>).</p>
<figure class="align-center" id="cnn1">
<a class="reference internal image-reference" href="_images/cnn1.png"><img alt="_images/cnn1.png" src="_images/cnn1.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 10 </span><span class="caption-text">Illustration des calculs effectués dans une opération de convolution discrète. Le pixel (2,2) de
l’image <span class="math notranslate nohighlight">\({\mathbf Y_i^{l}}\)</span> est une combinaison linéaire des pixels <span class="math notranslate nohighlight">\((i,j)\in[\![1,3]\!]^2\)</span> de <span class="math notranslate nohighlight">\({\mathbf Y_i^{l-1}}\)</span> les coefficients de la combinaison étant portés par le filtre <span class="math notranslate nohighlight">\(\mathbf K\)</span>.</span><a class="headerlink" href="#cnn1" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
<p><span class="math notranslate nohighlight">\(n_1^{(l)}\)</span> et <span class="math notranslate nohighlight">\(n_2^{(l)}\)</span> doivent prendre en compte les effets de bords
: lors du calcul de la convolution, seuls les pixels dont la somme est
définie avec des indices positifs doivent être traités. Dans le cas où
le padding n’est pas utilisé, les cartes de sortie ont donc une taille
de <span class="math notranslate nohighlight">\(n_1^{(l)} = n_1^{(l-1)} - 2h_1^{(l)}\)</span> et
<span class="math notranslate nohighlight">\(n_2^{(l)} = n_2^{(l-1)} - 2h_2^{(l)}\)</span>.</p>
<p>Souvent, les filtres utilisés pour calculer <span class="math notranslate nohighlight">\(\mathbf{Y_i^{(l)}}\)</span> sont
les mêmes, i.e. <span class="math notranslate nohighlight">\(\mathbf{K_{i,j}^{(l)}} = \mathbf{K _{i,k}^{(l)}}\)</span> pour
<span class="math notranslate nohighlight">\(j \neq k\)</span>. De plus, la somme dans l’équation
de la convolution peut être conduite sur un sous-ensemble des
cartes d’entrée.</p>
<p>Il est possible de mettre en correspondance la couche de convolution, et
l’opération qu’elle effectue, avec un perceptron
multicouche. Pour cela, il suffit de réécrire l’équation : chaque carte <span class="math notranslate nohighlight">\(\mathbf{Y_i^{(l)}}\)</span> de la
couche <span class="math notranslate nohighlight">\(l\)</span> est formée de <span class="math notranslate nohighlight">\(n_1^{(l)} \cdot n_2^{(l)}\)</span> neurones organisés
dans un tableau à deux dimensions. Le neurone en position <span class="math notranslate nohighlight">\((r,s)\)</span>
calcule :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \left(\mathbf{Y_i^{(l)}}\right)_{r,s} &amp;= \left(\mathbf{B_i^{(l)}}\right)_{r,s} + \displaystyle\sum _{j = 1}^{n^{(l-1)}} \left(\mathbf{K^{(l)}_{i,j} }\ast \mathbf{Y_j^{(l-1)}}\right)_{r,s}\\
    &amp;= \left(\mathbf{B_i^{(l)}}\right)_{r,s} + \displaystyle\sum _{j = 1}^{n^{(l-1)}} \displaystyle\sum _{u = - h_1^{(l)}} ^{h_1^{(l)}} \displaystyle\sum _{v = - h_2^{(l)}} ^{h_2^{(l)}} \left(\mathbf{K^{(l)}_{i,j}}\right)_{u,v} \left(\mathbf{Y_j^{(l-1)}}\right)_{r+u,s+v}
\end{aligned}\end{split}\]</div>
<p>Les paramètres du réseau à entraîner (poids) peuvent alors être trouvés
dans les filtres <span class="math notranslate nohighlight">\(\mathbf{K^{(l)}_{i,j}}\)</span> et les matrices de biais
<span class="math notranslate nohighlight">\(\mathbf{B_i^{(l)}}\)</span>.</p>
<p>Comme nous le verrons plus loin, un sous-échantillonnage est utilisé
pour diminuer l’influence du bruit et des distorsions dans les images.
Le sous-échantillonnage peut être également réalisé simplement avec des
paramètres de stride, en sautant un nombre fixe de pixels dans les
dimensions horizontale (saut <span class="math notranslate nohighlight">\(s_1^{(l)}\)</span>) et verticale (saut
<span class="math notranslate nohighlight">\(s_2^{(l)}\)</span>) avant d’appliquer de nouveau le filtre. La taille des
images de sortie est alors :</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    n_1^{(l)} = \frac{n_1^{(l-1)} - 2h_1^{(l)}}{s_1^{(l)} + 1}\quad \text{ et }\quad n_2^{(l)} = \frac{n_2^{(l-1)} - 2h_2^{(l)}}{s_2^{(l)} + 1}.
\end{aligned}\]</div>
<p>Un point clé des réseaux convolutifs est d’exploiter la corrélation
spatiale des données. L’utilisation des noyaux permet d’alléger le
modèle, plutôt que d’utiliser des couches complètement connectées.</p>
</section>
<section id="couche-non-lineaire">
<h3>Couche non linéaire<a class="headerlink" href="#couche-non-lineaire" title="Lien vers cette rubrique">#</a></h3>
<p>Pour augmenter le pouvoir d’expression
des réseaux profonds, on utilise des couches non linéaires. Les entrées
d’une couche non linéaire sont <span class="math notranslate nohighlight">\(n^{(l-1)}\)</span> cartes et ses sorties
<span class="math notranslate nohighlight">\(n^{(l)} = n^{(l-1)}\)</span> cartes <span class="math notranslate nohighlight">\(\mathbf{Y_i^{(l)}}\)</span>, de taille
<span class="math notranslate nohighlight">\(n_1^{(l-1)} \times n_2^{(l-1)}\)</span> telles que <span class="math notranslate nohighlight">\(n_1^{(l)} = n_1^{(l-1)}\)</span> et
<span class="math notranslate nohighlight">\(n_2^{(l)} = n_2^{(l-1)}\)</span>, données par
<span class="math notranslate nohighlight">\(\mathbf{Y_i^{(l)}}\)</span> = <span class="math notranslate nohighlight">\(f \left(\mathbf{Y_i^{(l-1)}}\right)\)</span>, où <span class="math notranslate nohighlight">\(f\)</span> est
la fonction d’activation utilisée dans la couche <span class="math notranslate nohighlight">\(l\)</span>.</p>
<p>La <a class="reference internal" href="PMC.html#tabact"><span class="std std-numref">Fig. 3</span></a> du cours sur les perceptrons multicouches présente quelques fonctions d’activation classiques.</p>
<p>En apprentissage profond, il a été reporté que la sigmoïde et la
tangente hyperbolique avaient des performances moindres que la fonction
d’activation <em>softsign</em> :</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    \mathbf{Y_i^{(l)}}  = \frac{1}{1+ \left|\mathbf{Y_i^{(l-1)}} \right |}.
\end{aligned}\]</div>
<p>En effet, les valeurs des pixels des cartes
<span class="math notranslate nohighlight">\(\mathbf{Y_i^{(l-1)}}\)</span> arrivant près des paliers de saturation de ces
fonctions donnent des gradients faibles, qui ont tendance à s’annuler
(problème du <em>gradient évanescent</em> ou <em>vanishing gradient</em>) lors de la
phase d’apprentissage par rétropropagation du gradient. Une autre
fonction, non saturante elle, est très largement utilisée. Il s’agit de
la fonction ReLU (Rectified Linear Unit) <span id="id1">[<a class="reference internal" href="transferLearning.html#id51" title="V. Nair and G. Hinton. Rectified linear units improve restricted boltzmann machines. In Johannes Fürnkranz and Thorsten Joachims, editors, ICML, 807-814. Omnipress, 2010. URL: http://dblp.uni-trier.de/db/conf/icml/icml2010.html#NairH10.">1</a>]</span> :</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
\mathbf{Y_i^{(l)}} = max\left (0,\mathbf{Y_i^{(l-1)}}\right )
\end{aligned}\]</div>
<p>Les neurones utilisant la fonction ReLU sont appelés neurones linéaires rectifiés. Glorot
et Bengio <span id="id2">[<a class="reference internal" href="transferLearning.html#id19" title="Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Deep sparse rectifier neural networks. In Geoffrey J. Gordon, David B. Dunson, and Miroslav Dudík, editors, AISTATS, volume 15 of JMLR Proceedings, 315-323. JMLR.org, 2011. URL: http://dblp.uni-trier.de/db/journals/jmlr/jmlrp15.html#GlorotBB11.">2</a>]</span> ont montré que l’utilisation d’une couche ReLU en
tant que couche non linéaire permettait un entraînement efficace de
réseaux profonds sans pré-entraînement non supervisé. Plusieurs
variantes de cette fonction existent, par exemple pour assurer une
différentiabilité en 0 ou pour proposer des valeurs non nulles pour des
valeurs négatives de l’argument.</p>
</section>
<section id="couches-de-normalisation">
<h3>Couches de normalisation<a class="headerlink" href="#couches-de-normalisation" title="Lien vers cette rubrique">#</a></h3>
<p>La normalisation prend aujourd’hui une place de plus en plus importante,
notamment depuis les travaux de Ioffe et Szegedy <span id="id3">[<a class="reference internal" href="transferLearning.html#id20" title="Sergey Ioffe and Christian Szegedy. Batch normalization: accelerating deep network training by reducing internal covariate shift. In Francis R. Bach and David M. Blei, editors, ICML, volume 37 of JMLR Workshop and Conference Proceedings, 448-456. JMLR.org, 2015. URL: http://dblp.uni-trier.de/db/conf/icml/icml2015.html#IoffeS15.">3</a>]</span>. Les auteurs
suggèrent qu’un changement dans la distribution des activations d’un
réseau profond, résultant de la présentation d’un nouveau mini batch
d’exemples, ralentit le processus d’apprentissage. Pour pallier ce
problème, chaque activation du mini batch est centrée et normée
(variance unité), la moyenne et la variance étant calculées sur le mini
batch entier, indépendamment pour chaque activation. Des paramètres
d’offset <span class="math notranslate nohighlight">\(\beta\)</span> et multiplicatif <span class="math notranslate nohighlight">\(\gamma\)</span> sont alors appliqués pour
normaliser les données d’entrée
(<a class="reference internal" href="#norm">Algorithm 5</a>).</p>
<div class="proof algorithm admonition" id="norm">
<p class="admonition-title"><span class="caption-number">Algorithm 5 </span> (Normalisation par batch sur la présentation d’un mini batch <span class="math notranslate nohighlight">\(\mathcal{B}\)</span>)</p>
<section class="algorithm-content" id="proof-content">
<p>Entrées : valeurs de l’activation <span class="math notranslate nohighlight">\(x\)</span> sur un mini batch <span class="math notranslate nohighlight">\(\mathcal{B} = \{x_1\cdots x_m\}\)</span>,  Paramètres <span class="math notranslate nohighlight">\(\beta,\gamma\)</span> à apprendre</p>
<p>Sortie : Données normalisées <span class="math notranslate nohighlight">\(\{y_1\cdots  y_m\}=BatchNorm_{\gamma,\beta}(x_1\cdots x_m)\)</span></p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\mu_\mathcal{B} = \frac{1}{m}\displaystyle\sum_{i=1}^m x_i\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma^2_\mathcal{B} = \frac{1}{m}\displaystyle\sum_{i=1}^m \left (x_i-\mu_\mathcal{B}\right )^2\)</span></p></li>
<li><p>Pour <span class="math notranslate nohighlight">\(i=1\)</span> à <span class="math notranslate nohighlight">\(m\)</span></p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(y_i = \gamma \frac{x_i-\mu_\mathcal{B}}{\sqrt{\sigma^2_\mathcal{B}+\epsilon}}+\beta\)</span></p></li>
</ol>
</li>
</ol>
</section>
</div><p>Lorsque la descente de gradient est achevée, un post apprentissage est
appliqué dans lequel la moyenne et la variance sont calculées sur
l’ensemble d’entraînement et remplacent <span class="math notranslate nohighlight">\(\mu_\mathcal{B}\)</span> et
<span class="math notranslate nohighlight">\(\sigma^2_\mathcal{B}\)</span> (<a class="reference internal" href="#norm2">Algorithm 6</a>).</p>
<div class="proof algorithm admonition" id="norm2">
<p class="admonition-title"><span class="caption-number">Algorithm 6 </span> (Normalisation par batch d’un réseau)</p>
<section class="algorithm-content" id="proof-content">
<p>{
Entrées : {un réseau <span class="math notranslate nohighlight">\(N\)</span>,  un ensemble d’activations <span class="math notranslate nohighlight">\(\{x^1\cdots x^K\}\)</span></p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(N_n=N\)</span></p></li>
<li><p>Pour <span class="math notranslate nohighlight">\(i=1\)</span> à <span class="math notranslate nohighlight">\(K\)</span></p>
<ol class="arabic simple">
<li><p>Calculer <span class="math notranslate nohighlight">\(y^i=BN_{\gamma,\beta}(x^i)\)</span> à l’aide de l”<a class="reference internal" href="#norm">Algorithm 5</a></p></li>
<li><p>Modifier chaque couche de <span class="math notranslate nohighlight">\(N_n\)</span> : l’entrée <span class="math notranslate nohighlight">\(y^i\)</span> remplace l’entrée <span class="math notranslate nohighlight">\(x^i\)</span></p></li>
</ol>
</li>
<li><p>Entraîner <span class="math notranslate nohighlight">\(N_n\)</span> pour optimiser les paramètres de <span class="math notranslate nohighlight">\(N\)</span> et <span class="math notranslate nohighlight">\((\gamma^i,\beta^i)_{i\in[\![1,K]\!]}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(N^f = N_n\)</span></p></li>
<li><p>Pour <span class="math notranslate nohighlight">\(i=1\)</span> à <span class="math notranslate nohighlight">\(K\)</span></p>
<ol class="arabic simple">
<li><p>Utiliser <span class="math notranslate nohighlight">\(N^f\)</span> sur des batchs <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> de taille <span class="math notranslate nohighlight">\(m\)</span></p></li>
<li><p>Calculer la moyenne des moyennes <span class="math notranslate nohighlight">\(\bar{x^i}\)</span> et des variances <span class="math notranslate nohighlight">\(Var(x^i)\)</span></p></li>
<li><p>Remplacer dans <span class="math notranslate nohighlight">\(N^f\)</span> la transformation <span class="math notranslate nohighlight">\(y^i=BN_{\gamma,\beta}(x^i)\)</span> par</p></li>
</ol>
</li>
</ol>
<div class="math notranslate nohighlight">
\[y^i=\frac{\gamma^i}{\sqrt{Var(x^i)+\epsilon}}x^i+\left(\beta^i -\frac{\gamma^i \bar{x^i}}{\sqrt{Var(x^i)+\epsilon}}\right)\]</div>
</section>
</div></section>
<section id="couche-d-agregation-et-de-sous-echantillonnage">
<h3>Couche d’agrégation et de sous-échantillonnage<a class="headerlink" href="#couche-d-agregation-et-de-sous-echantillonnage" title="Lien vers cette rubrique">#</a></h3>
<p>Le sous-échantillonnage (pooling) des cartes obtenues par les couches
précédentes a pour objectif d’assurer une robustesse au bruit et aux
distorsions.</p>
<p>La sortie d’une couche d’agrégation <span class="math notranslate nohighlight">\(l\)</span>
(<a class="reference internal" href="#pooling"><span class="std std-numref">Fig. 11</span></a>) est composée de <span class="math notranslate nohighlight">\(n^{(l)} = n^{(l-1)}\)</span> cartes
de taille réduite. En général, l’agrégation est effectuée en déplaçant
dans les cartes d’entrée une fenêtre de taille <span class="math notranslate nohighlight">\(2p \times 2p\)</span> toutes les
<span class="math notranslate nohighlight">\(q\)</span> positions (il y a recouvrement si <span class="math notranslate nohighlight">\(q &lt; p\)</span> et non recouvrement
sinon), et en calculant, pour chaque position de la fenêtre, une seule
valeur, affectée à la position centrale dans la carte de sortie.</p>
<figure class="align-center" id="pooling">
<a class="reference internal image-reference" href="_images/pooling.png"><img alt="_images/pooling.png" src="_images/pooling.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 11 </span><span class="caption-text">Couche d’agrégation et de sous-échantillonnage <span class="math notranslate nohighlight">\(l\)</span>. Chacune des <span class="math notranslate nohighlight">\(n^{(l−1)}\)</span> cartes de la couche <span class="math notranslate nohighlight">\(l-1\)</span> est traitée individuellement. Chaque neurone des <span class="math notranslate nohighlight">\(n^(l) = n^{(l−1)}\)</span> cartes de sortie est la moyenne (ou le maximum) des valeurs contenues dans une fenêtre de taille donnée dans la carte correspondante de la couche <span class="math notranslate nohighlight">\(l-1\)</span>.</span><a class="headerlink" href="#pooling" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
<p>On distingue généralement deux types d’agrégation :</p>
<ul>
<li><p>La moyenne : on utilise un filtre <span class="math notranslate nohighlight">\(\mathbf{K_B}\)</span> de taille
<span class="math notranslate nohighlight">\((2h_1 + 1)\times (2h_2 + 1)\)</span> défini par</p>
<div class="math notranslate nohighlight">
\[\left(\mathbf{K_B}\right)_{r,s} = \frac{1}{(2h_1 + 1)(2h_2 + 1)}\]</div>
</li>
<li><p>Le maximum : la valeur maximum dans la fenêtre est retenue.</p></li>
</ul>
<p>Le maximum est souvent utilisé pour assurer une convergence rapide
durant la phase d’entraînement. L’agrégation avec recouvrement, elle,
semble assurer une réduction du phénomène de surapprentissage</p>
</section>
<section id="couche-completement-connectee">
<h3>Couche complètement connectée<a class="headerlink" href="#couche-completement-connectee" title="Lien vers cette rubrique">#</a></h3>
<p>Si <span class="math notranslate nohighlight">\(l\)</span> et <span class="math notranslate nohighlight">\((l-1)\)</span> sont des couches complètement connectées, l’équation :</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    z_i^{(l)} = \sum _{k = 0} ^{m^{(l-1)}} w_{i,k}^{(l)} y_k^{(l-1)}\quad \text{ où }\quad \mathbf{Z^{(l)}} = \mathbf{W^{(l)}} \mathbf{Y^{(l-1)}}
\end{aligned}\]</div>
<p>avec <span class="math notranslate nohighlight">\(\mathbf{Z^{(l)}}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{W^{(l)}}\)</span> et
<span class="math notranslate nohighlight">\(\mathbf{Y^{(l-1)}}\)</span> les représentations vectorielle et matricielle des
entrées <span class="math notranslate nohighlight">\(z_i^{(l)}\)</span>, des poids <span class="math notranslate nohighlight">\(w_{i,k}^{(l)}\)</span> et des sorties
<span class="math notranslate nohighlight">\(y_k^{(l-1)}\)</span>, permet de relier ces deux couches.</p>
<p>Dans le cas contraire, la couche <span class="math notranslate nohighlight">\(l\)</span> attend <span class="math notranslate nohighlight">\(n^{(l-1)}\)</span> entrées de
taille <span class="math notranslate nohighlight">\(n_1^{(l-1)} \times n_2^{(l-1)}\)</span> et le <span class="math notranslate nohighlight">\(i^{\text{e}}\)</span> neurone de
la couche <span class="math notranslate nohighlight">\(l\)</span> calcule :</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    y_i^{(l)} = f\left(z_i^{(l)}\right)\quad\text{ avec }\quad z_i^{(l)} = \displaystyle\sum _{j = 1}^{n^{(l-1)}} \displaystyle\sum _{r = 1} ^{n_1^{(l-1)}} \displaystyle\sum _{s = 1}^{n_2^{(l-1)}} w_{i,j,r,s}^{(l)} \left(\mathbf{ Y_j^{(l-1)}} \right)_{r,s}
\end{aligned}\]</div>
<p>où <span class="math notranslate nohighlight">\(w_{i,j,r,s}^{(l)}\)</span> est le poids connectant le
neurone en position <span class="math notranslate nohighlight">\((r,s)\)</span> de la <span class="math notranslate nohighlight">\(j^{\text{e}}\)</span> carte de la couche
<span class="math notranslate nohighlight">\((l - 1)\)</span> au <span class="math notranslate nohighlight">\(i^{\text{e}}\)</span> neurone de la couche <span class="math notranslate nohighlight">\(l\)</span>.</p>
<p>En pratique, les réseaux convolutifs sont utilisés pour apprendre une
hiérarchie dans les données et la (ou les) couche(s) complètement
connectée(s) est(sont) utilisée(s) en bout de réseau pour des tâches de
classification ou de régression.</p>
<p>Une couche de classification classiquement mise en œuvre utilise le
classifieur <em>softmax</em>, qui généralise la régression logistique au cas
multiclasse (<span class="math notranslate nohighlight">\(k\)</span> classes). L’ensemble d’apprentissage
<span class="math notranslate nohighlight">\({\mathcal E}_a = \left \{(\mathbf{x^{(i)}}, y^{(i)}),i \in[\![1,m]\!]\right \}\)</span>
est donc tel que <span class="math notranslate nohighlight">\(y^{(i)}\in[\![1,k]\!]\)</span> et le classifieur estime
la probabilité <span class="math notranslate nohighlight">\(P(y^{(i)}=j |\mathbf{x^{(i)}})\)</span> pour chaque classe
<span class="math notranslate nohighlight">\(j\in [\![1,k]\!]\)</span>. Le classifieur softmax calcule cette probabilité selon
:</p>
<div class="math notranslate nohighlight">
\[\forall j\in[\![1,k]\!]\quad P(y^{(i)}=j | \mathbf{x^{(i)}},\mathbf{W}) = \frac{e^{\mathbf{W_j^\top x^{(i)}}}}{\displaystyle\sum_{l=1}^k e^{\mathbf{W_l^\top}\mathbf{x^{(i)}}}}\]</div>
<p>où <span class="math notranslate nohighlight">\(\mathbf{W}\)</span> est la matrice des paramètres du modèle (les poids). Ces
paramètres sont obtenus en minimisant une fonction de coût, qui peut par
exemple s’écrire :</p>
<div class="math notranslate nohighlight">
\[J(\mathbf{W}) =- \frac{1}{m}\displaystyle\sum_{i=1}^m \displaystyle\sum_{j=1}^k \mathbb{I}_{y^{(i)}=j}log\left ( \frac{e^{\mathbf{W_j^\top x^{(i)}}}}{\displaystyle\sum_{l=1}^k e^{\mathbf{W_l^\top x^{(i)}}}}\right ) + \frac{\lambda}{2}\displaystyle\sum_{i=1}^n \displaystyle\sum_{j=1}^k W_{ji}^2
\]</div>
<p>où <span class="math notranslate nohighlight">\(\lambda\)</span> est un paramètre de régularisation contrôlant le second terme du coût qui pénalise les grandes valeurs des poids (régularisation <span class="math notranslate nohighlight">\(\ell_2\)</span>).</p>
</section>
</section>
<section id="regularisation">
<h2>Régularisation<a class="headerlink" href="#regularisation" title="Lien vers cette rubrique">#</a></h2>
<p>Un des enjeux principaux en apprentissage automatique est de construire
des algorithmes ayant une bonne capacité de généralisation. Les
stratégies mises en œuvre pour arriver à cette fin rentrent dans la
catégorie générale de la régularisation et de nombreuses méthodes sont
aujourd’hui proposées en ce sens. La régularisation a déjà été abordée dans le chapitre consacré aux perceptrons multicouches (voir section <a class="reference internal" href="PMC.html#content-references-reg"><span class="std std-ref">Régularisation</span></a>). Nous faisons ici un focus sur trois
stratégies largement utilisées en apprentissage profond.</p>
<section id="regularisation-de-la-fonction-de-cout">
<h3>Régularisation de la fonction de coût<a class="headerlink" href="#regularisation-de-la-fonction-de-cout" title="Lien vers cette rubrique">#</a></h3>
<p>L’équation précédente est un exemple de régularisation de la
fonction de coût, utilisée lors de la phase d’entraînement. À la
fonction d’erreur est ajoutée une fonction des poids du réseau, qui peut
prendre de multiples formes. Les deux principales stratégies sont :</p>
<ul class="simple">
<li><p>La régularisation <span class="math notranslate nohighlight">\(\ell_2\)</span> (ou ridge regression), qui force les
poids à avoir une faible valeur absolue : un terme de régularisation
fonction de la norme <span class="math notranslate nohighlight">\(\ell_2\)</span> de la matrice des poids est ajouté. On parle souvent de <em>weight decay</em>.</p></li>
<li><p>La régularisation <span class="math notranslate nohighlight">\(\ell_1\)</span>, qui tend à rendre épars le réseau
profond, <em>i.e.</em> à imposer à un maximum de poids de s’annuler. Un
terme de régularisation, somme pondérée des valeurs absolues des
poids, est ajouté à la fonction objectif.</p></li>
</ul>
</section>
<section id="dropout">
<h3>Dropout<a class="headerlink" href="#dropout" title="Lien vers cette rubrique">#</a></h3>
<p>Les techniques de dropout se rapprochent des stratégies classiques de
bagging en apprentissage automatique. L’objectif est d’entraîner un
ensemble constitué de tous les sous-réseaux qui peuvent être construits
en supprimant des neurones (hors neurones d’entrée et de sortie) du
réseau initial. Si le réseau comporte <span class="math notranslate nohighlight">\(|\mathbf{W}|\)</span> neurones cachés, il
existe ainsi <span class="math notranslate nohighlight">\(2^{|\mathbf{W}|}\)</span> modèles possibles. En pratique, les
neurones cachés se voient perturbés par un bruit binomial, qui a pour
effet de les empêcher de fonctionner en groupe et de les rendre, au
contraire, plus indépendants. Le phénomène de surapprentissage est ainsi
fortement réduit sur le réseau, qui doit décomposer les entrées en
caractéristiques pertinentes, indépendamment les unes des autres. Les
réseaux construits par dropout partagent partiellement leurs paramètres,
ce qui diminue l’empreinte mémoire de la méthode.</p>
<p>Lors de la phase de prédiction, le réseau complet est utilisé, mais les
neurones cachés sont pondérés par la fraction de bruit utilisé pendant
l’apprentissage (<em>i.e.</em> pour chaque neurone le nombre de fois où il a
été supprimé d’un sous-réseau, rapporté au nombre total de réseaux),
afin de conserver la valeur moyenne des activations des neurones
identiques à celles durant l’apprentissage.</p>
<p>Notons qu’il est également possible d’éteindre non pas un neurone, mais
un poids. La stratégie correspondante est appelée DropConnect.</p>
</section>
<section id="partage-de-parametres">
<h3>Partage de paramètres<a class="headerlink" href="#partage-de-parametres" title="Lien vers cette rubrique">#</a></h3>
<p>La régularisation de la fonction de coût permet d’imposer aux poids
certaines contraintes (par exemple de rester faibles en amplitude pour
la régularisation <span class="math notranslate nohighlight">\(\ell_2\)</span>, ou de s’annuler pour la régularisation
<span class="math notranslate nohighlight">\(\ell_1\)</span>). Il peut également être intéressant d’imposer certains a
priori sur les poids, par exemple une dépendance entre les valeurs des
paramètres.</p>
<p>Une dépendance classique consiste à imposer que les valeurs de certains
poids soient proches les unes des autres (dans le cas par exemple où
deux modèles de classification <span class="math notranslate nohighlight">\(M_1\)</span> et <span class="math notranslate nohighlight">\(M_2\)</span>, de paramètres
<span class="math notranslate nohighlight">\(\mathbf{W_1}\)</span> et <span class="math notranslate nohighlight">\(\mathbf{W_2}\)</span>, opèrent sur des données similaires et
sur des classes identiques) et, là encore, une stratégie de pénalisation
de la fonction objectif peut être utilisée. Cependant, il est plus
courant dans ce cas d’imposer que les paramètres soient égaux (dans
l’exemple précédent imposer <span class="math notranslate nohighlight">\(\mathbf{W_1}=\mathbf{W_2}\)</span>) et d’arriver à
une stratégie dite de partage des paramètres. Dans le cas des réseaux
convolutifs utilisés en vision, cette régularisation est assez intuitive
puisque les entrées (images) possèdent de nombreuses propriétés
invariantes par transformations affines (une image de voiture reste une
image de voiture, même si l’image est translatée ou mise à l’échelle (<a class="reference internal" href="#partage"><span class="std std-numref">Fig. 12</span></a>)).
Le réseau exploite alors ce partage de
paramètres, en calculant une même caractéristique (un neurone et son
poids) à différentes positions dans l’image. De ce fait, le nombre de
paramètres est drastiquement réduit, ainsi que l’empreinte mémoire du
réseau appris.</p>
<figure class="align-center" id="partage">
<a class="reference internal image-reference" href="_images/partage.png"><img alt="_images/partage.png" src="_images/partage.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 12 </span><span class="caption-text">Partage de paramètres : les neurones voient des champs réceptifs distincts, mais partagent les mêmes paramètres (poids). Leur capacité de détection d’un triangle restera la même, quelle que soit la position de l’objet dans l’image.</span><a class="headerlink" href="#partage" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="initialisation">
<h2>Initialisation<a class="headerlink" href="#initialisation" title="Lien vers cette rubrique">#</a></h2>
<p>Une initialisation convenable des poids est essentielle pour assurer une
convergence de la phase d’entraînement. Un choix arbitraire des poids (à
zéro, à de petites ou grandes valeurs aléatoires) peut ralentir, voire
causer de la redondance dans le réseau (problème de la symétrie). Ces aspects ont déjà été abordés dans la section <a class="reference internal" href="PMC.html#content-references-initw"><span class="std std-ref">Initialisation des poids</span></a>), où l’initialisation de Xavier</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    - \frac{\sqrt{6}}{\sqrt{m^{(l-1)} + m^{(l)}}} &lt; w_{i,j}^{(l)} &lt; \frac{\sqrt{6}}{\sqrt{m^{(l-1)} + m^{(l)}}}.
\end{aligned}\]</div>
<p>a été notamment détaillée.</p>
</section>
<section id="apprentissage">
<h2>Apprentissage<a class="headerlink" href="#apprentissage" title="Lien vers cette rubrique">#</a></h2>
<p>La présence de nombreuses couches cachées va permettre de calculer des
caractéristiques beaucoup plus complexes et informatives des entrées.
Chaque couche calculant une transformation non linéaire de la couche
précédente, le pouvoir de représentation de ces réseaux s’en trouve
amélioré. On peut par exemple montrer qu’il existe des fonctions qu’un
réseau à <span class="math notranslate nohighlight">\(k\)</span> couches peut représenter de manière compacte (avec un
nombre de neurones cachés qui est polynomial en le nombre des entrées),
alors qu’un réseau à <span class="math notranslate nohighlight">\(k-1\)</span> couches ne peut pas le faire, à moins d’avoir
une combinatoire exponentielle sur le nombre de neurones cachés.</p>
<section id="le-probleme-de-l-entrainement">
<h3>Le problème de l’entraînement<a class="headerlink" href="#le-probleme-de-l-entrainement" title="Lien vers cette rubrique">#</a></h3>
<p>Si l’intérêt de ces réseaux est manifeste, la complexité de leur
utilisation vient de l’étape d’apprentissage. Jusqu’à récemment,
l’algorithme utilisé était classique et consistait en une initialisation
aléatoire des poids du réseau, suivie d’un entraînement sur un ensemble
d’apprentissage, en minimisant une fonction objectif. Cependant, dans le
cas des réseaux profonds, cette approche peut ne pas être adaptée :</p>
<ul class="simple">
<li><p>Les données étiquetées doivent être en nombre suffisant pour
permettre un entraînement efficace, d’autant plus que le réseau est
complexe. Dans le cas contraire, un surapprentissage peut notamment
être induit.</p></li>
<li><p>Sur un tel réseau, l’apprentissage se résume à l’optimisation d’une
fonction fortement non convexe, qui amène presque sûrement à des
minima locaux lorsque des algorithmes classiques sont utilisés.</p></li>
<li><p>Dans l’étape de rétropropagation, les gradients diminuent rapidement
à mesure que le nombre de couches cachées augmente. La dérivée de la
fonction objectif par rapport à <span class="math notranslate nohighlight">\(\mathbf{W}\)</span> devient alors très
faible à mesure que le calcul se rétropropage vers la couche
d’entrée. Les poids des premières couches changent donc très
lentement et le réseau n’est plus en capacité d’apprendre. Ce
problème est connu sous le nom de problème de gradient évanescent
(vanishing gradient).</p></li>
</ul>
<p>L’algorithme principalement utilisé pour l’apprentissage des réseaux
convolutifs reste la rétropropagation du gradient. Le choix de la
fonction objectif, de sa régularisation, de la méthode d’optimisation
(descente de gradient, méthodes à taux d’apprentissage adaptatifs telles
qu’AdaGrad, RMSProp ou Adam) et des paramètres associés, ou des
techniques de présentation des exemples (batchs, minibatchs) sont autant
de facteurs importants permettant aux modèles non seulement de converger
vers un optimum local satisfaisant, mais également de proposer un modèle
final ayant une bonne capacité de généralisation.</p>
<p>Aujourd’hui, de nombreux réseaux, déjà entraînés, sont mis à
disposition. En effet, ces entraînements nécessitent de grandes bases
d’apprentissage (type ImageNet) et une puissance de calcul assez élevée
(GPUs obligatoires). Pour le traitement de problèmes précis, des
méthodes existent, qui partent de ces réseaux préentraînés et les
modifient localement pour, par exemple, apprendre de nouvelles classes
d’images non encore vues par le réseau. L’idée sous-jacente est que les
premières couches capturent des caractéristiques bas niveau et que la
sémantique vient avec les couches profondes. Ainsi, dans un problème de
classification, où les classes n’ont pas été apprises, on peut supposer
qu’en conservant les premières couches on extraira des caractéristiques
communes des images (bords, colorimétrie,…) et qu’en changeant les
dernières couches (information sémantique et haut niveau et étage de
classification), c’est-à-dire en réapprenant les connexions, on
spécifiera le nouveau réseau pour la nouvelle tâche de classification.
Cette approche rentre dans le cadre des méthodes de <em>transfer learning</em>
et de <em>fine tuning</em>, cas particulier d’adaptation de domaine :</p>
<ul class="simple">
<li><p>Les méthodes de transfert prennent un réseau déjà entraîné, enlèvent
la dernière couche complètement connectée et traitent le réseau
restant comme un extracteur de caractéristiques. Un nouveau
classifieur, la dernière couche, est alors entraîné sur le nouveau
problème (<a class="reference internal" href="#transfer"><span class="std std-numref">Fig. 13</span></a>).</p></li>
</ul>
<figure class="align-center" id="transfer">
<img alt="_images/transferLearning.png" src="_images/transferLearning.png" />
<figcaption>
<p><span class="caption-number">Fig. 13 </span><span class="caption-text">Illustration de la technique de transfer Learning. Le réseau appris à classer des images de chat est amputé de sa partie classification. Un nouveau classifieur est mis au bout du réseau, dont les poids sont entraînés sur la nouvelle tâche de classification.</span><a class="headerlink" href="#transfer" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Les méthodes de fine tuning ré-entraînent tout ou partie d’un réseau (suivant les données disponibles) et conservent les poids non ré-entrainés.</p></li>
</ul>
<p>Plusieurs facteurs influent sur le choix de la méthode à utiliser : la
taille des données d’apprentissage du nouveau problème et la
ressemblance du nouveau jeu de données avec celui qui a servi à
entraîner le réseau initial :</p>
<ul class="simple">
<li><p>Pour un jeu de données similaire de petite taille, on utilise du
transfer learning, avec un classifieur utilisé sur les
caractéristiques calculées sur les dernières couches du réseau
initial.</p></li>
<li><p>Pour un jeu de données de petite taille et un problème différent, on
utilise du transfer learning, avec un classifieur utilisé sur les
caractéristiques calculées sur les premières couches du réseau
initial.</p></li>
<li><p>Pour un jeu de données, similaire ou non, de grande taille, on
utilise le fine tuning.</p></li>
</ul>
<p>Notons qu’il est toujours possible d’augmenter la taille du jeu de
données par des technique d’augmentation de données.</p>
<p>Dans le cas où un réseau ad hoc doit être construit et où une base
d’apprentissage suffisante est disponible, l’entraînement par
optimisation reste possible mais peut nécessiter des ressources de calcul importantes.  De plus, il a été montré que :</p>
<ul class="simple">
<li><p>le transfer Learning ou le fine tuning permettaient souvent d’aboutir à de meilleures performances que l’entraînement depuis un réseau initial aléatoire (on se sert des poids du réseau pré entraîné comme initialisation, plutôt qu’une initialisation type Xavier).</p></li>
<li><p>le fine tuning améliorait la capacité de généralisation du réseau.</p></li>
</ul>
</section>
<section id="visualisation-du-mecanisme-des-reseaux-convolutifs">
<h3>Visualisation du mécanisme des réseaux convolutifs<a class="headerlink" href="#visualisation-du-mecanisme-des-reseaux-convolutifs" title="Lien vers cette rubrique">#</a></h3>
<p>Le mécanisme interne des réseaux convolutifs est mal compris et
l’analyse des raisons qui font que leur puissance de prédiction est
importante n’est pas aisée. S’il est toujours possible de rétroprojeter
les activations depuis la première couche de convolution, les couches
d’agrégation et de rectification empêchent de comprendre le
fonctionnement des couches suivantes, ce qui peut être gênant dans la
construction et l’amélioration de ces réseaux.</p>
<p>Les méthodes de visualisation du fonctionnement des réseaux convolutifs
peuvent être rangées en trois catégories, décrites brièvement dans les paragraphes
suivants.</p>
</section>
<section id="methodes-de-visualisation-de-base">
<h3>Méthodes de visualisation de base<a class="headerlink" href="#methodes-de-visualisation-de-base" title="Lien vers cette rubrique">#</a></h3>
<p>Les méthodes les plus simples consistent à visualiser les activations
lors du passage d’une image dans le réseau. Pour des activations type
ReLU, ces activations sont ininterprétables au début de l’entraînement,
mais à mesure que ce dernier progresse, les cartes d’activation
<span class="math notranslate nohighlight">\(\mathbf{Y_i^{(l)}}\)</span> deviennent localisées et éparses.</p>
<p>Il est également possible de visualiser les filtres des différentes
couches de convolution (<a class="reference internal" href="#visufiltres"><span class="std std-numref">Fig. 14</span></a>).
Les filtres des premières couches agissent comme des détecteurs de bords
et coins et, à mesure que l’on s’enfonce dans le réseau, les filtres
capturent des concepts haut niveau comme des objets ou encore des
visages.</p>
<p>Citons encore d’autres méthodes qui proposent de visualiser les
dernières couches (les couches complètement connectées) de grande
dimension (par exemple 4096 pour AlexNet) via une méthode de réduction
de dimension.</p>
<figure class="align-center" id="visufiltres">
<a class="reference internal image-reference" href="_images/visufiltres.png"><img alt="_images/visufiltres.png" src="_images/visufiltres.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 14 </span><span class="caption-text">Visualisation des filtres de la première couche d’AlexNet (à
gauche, 64 filtres 11<span class="math notranslate nohighlight">\(\times\)</span>11) et de ResNet-18 (à droite, 64 filtres 7<span class="math notranslate nohighlight">\(\times 7\)</span>).</span><a class="headerlink" href="#visufiltres" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
</section>
<section id="methodes-fondees-sur-les-activations">
<h3>Méthodes fondées sur les activations<a class="headerlink" href="#methodes-fondees-sur-les-activations" title="Lien vers cette rubrique">#</a></h3>
<p>Plusieurs stratégies peuvent être adoptées pour sonder le fonctionnement
d’un réseau convolutif, en utilisant les informations portées par les
cartes <span class="math notranslate nohighlight">\(\mathbf{Y_i^{(l)}}\)</span>, parmi lesquelles :</p>
<ul class="simple">
<li><p>Utiliser des couches de convolution transposée (improprement
appelées parfois couches de déconvolution), ajoutées à chaque couche
de convolution du réseau. Étant données les cartes d’entrée de la
couche <span class="math notranslate nohighlight">\(l\)</span>, les cartes de sortie <span class="math notranslate nohighlight">\(\mathbf{Y_i^{(l)}}\)</span> sont envoyées
dans la couche de convolution transposée correspondante au niveau
<span class="math notranslate nohighlight">\(l\)</span>. Cette dernière reconstruit les <span class="math notranslate nohighlight">\(\mathbf{Y_i^{(l-1)}}\)</span> qui ont
permis le calcul des activations de la couche <span class="math notranslate nohighlight">\(l\)</span>. Le processus est
alors itéré jusqu’à atteindre la couche d’entrée <span class="math notranslate nohighlight">\(l = 1\)</span>, les
activations de la couche <span class="math notranslate nohighlight">\(l\)</span> étant alors rétroprojetées dans le plan
image. La présence de couches d’agrégation et de
rectification rend ce processus non inversible (par exemple, une
couche d’agrégation maximum nécessite de connaître à quelles
positions de l’image <span class="math notranslate nohighlight">\(\mathbf{Y_i^{(l)}}\)</span> sont situés les maxima
retenus).</p></li>
<li><p>Faire passer un grand nombre d’images dans le réseau et, pour un
neurone particulier, conserver celle qui a le plus activé ce
neurone. Il est alors possible de visualiser les images pour
comprendre ce à quoi le neurone s’intéresse dans son champ réceptif
(<a class="reference internal" href="#champr"><span class="std std-numref">Fig. 15</span></a>).</p></li>
</ul>
<figure class="align-center" id="champr">
<img alt="_images/champr.png" src="_images/champr.png" />
<figcaption>
<p><span class="caption-number">Fig. 15 </span><span class="caption-text">Champ récéptif de quelques neurones de la dernière couche
d’agrégation du réseau AlexNet, superposées aux images ayant le plus
fortement activé ces neurones. Le champ est encadré en blanc, et la
valeur d’activation correspondante est reportée en haut. On voit par
exemple que certains neurones sont très sensibles aux textes, d’autres
aux réflexions spéculaires, ou encore aux hauts du corps (source :<span id="id4">[<a class="reference internal" href="transferLearning.html#id52" title="R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In 2014 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), volume 00, 580-587. June 2014. URL: https://ieeexplore.ieee.org/abstract/document/6909475/, doi:10.1109/CVPR.2014.81.">4</a>]</span>)</span><a class="headerlink" href="#champr" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Cacher (par un rectangle noir par exemple) différentes parties de
l’image d’entrée qui est d’une certaine classe (disons un chien) et
observer la sortie du réseau (la probabilité de la classe de l’image
d’entrée). En représentant les valeurs de probabilité de la classe
d’intérêt comme une fonction de la position du rectangle occultant,
il est possible de voir si le réseau s’intéresse effectivement aux
parties de l’image spécifiques de la classe, ou à des autres zones
(le fond par exemple) (<a class="reference internal" href="#occlusion"><span class="std std-numref">Fig. 16</span></a>).</p></li>
</ul>
<figure class="align-center" id="occlusion">
<a class="reference internal image-reference" href="_images/occlusion.png"><img alt="_images/occlusion.png" src="_images/occlusion.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 16 </span><span class="caption-text">Occlusion d’une image (à gauche). Le rectangle noir est
déplacé dans l’image et pour chaque position la probabilité de la classe
de l’image (ici un loulou de Poméranie) est enregistrée. Ces
probabilités sont ensuite représentées sous forme d’une carte 2D (à
droite). La probabilité de la classe s’effondre lorsque le rectangle
couvre une partie de la face du chien. Cela suggère que cette face est
grandement responsable de la forte probabilité de classement de l’image
comme un loulou. A l’inverse, l’occlusion du fond n’altère pas la forte
valeur de probabilité de la classe  (source :<span id="id5">[<a class="reference internal" href="transferLearning.html#id17" title="Matthew D. Zeiler and Rob Fergus. Visualizing and understanding convolutional networks. CoRR, 2013. URL: http://dblp.uni-trier.de/db/journals/corr/corr1311.html#ZeilerF13.">5</a>]</span>)</span><a class="headerlink" href="#occlusion" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
</section>
<section id="methodes-fondees-sur-le-gradient">
<h3>Méthodes fondées sur le gradient<a class="headerlink" href="#methodes-fondees-sur-le-gradient" title="Lien vers cette rubrique">#</a></h3>
<p>Pour comprendre quelle(s) partie(s) de l’image est (sont) utilisée(s)
par le réseau pour effectuer une prédiction, il est possible de calculer
des cartes de saillance (saliency maps). L’idée est relativement simple
: calculer le gradient de la classe de sortie par rapport à l’image
d’entrée. Cela indique à quel point une petite variation dans l’image
induit un changement de prédiction. En visualisant les gradients, on
observe alors par exemple leurs fortes valeurs, indiquant qu’une petite
variation du pixel correspondant augmente la valeur de sortie.<br />
Il est également possible d’utiliser le gradient par rapport à la
dernière couche de convolution (approche Grad-CAM), ce qui permet de
récupérer des informations de localisation spatiale des régions
importantes pour la prédiction (<a class="reference internal" href="#gradcam"><span class="std std-numref">Fig. 17</span></a> droite).</p>
<p>Plus généralement, en choisissant un neurone intermédiaire du réseau
(d’une couche de convolution), la méthode de rétropropagation guidée
calcule le gradient de sa valeur par rapport aux pixels de l’image
d’entrée, ce qui permet de souligner les parties de l’image auxquelles
ce neurone répond (<a class="reference internal" href="#gradcam"><span class="std std-numref">Fig. 17</span></a> milieu).</p>
<figure class="align-center" id="gradcam">
<a class="reference internal image-reference" href="_images/gradcam.png"><img alt="_images/gradcam.png" src="_images/gradcam.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 17 </span><span class="caption-text">Approches par gradient de visualisation du fonctionnement
d’un réseau convolutif. Comparaison de la méthode de rétropropagation
guidée et de Grad-CAM (source :<span id="id6">[<a class="reference internal" href="transferLearning.html#id53" title="Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. Grad-cam: visual explanations from deep networks via gradient-based localization. In ICCV, 618-626. IEEE Computer Society, 2017. URL: http://dblp.uni-trier.de/db/conf/iccv/iccv2017.html#SelvarajuCDVPB17.">6</a>]</span>)</span><a class="headerlink" href="#gradcam" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
<p>Ces gradients peuvent également être utilisés dans la méthode de montée
de gradient (gradient Ascent), dont l’objectif est de générer une image
qui active de manière maximale un neurone donné du réseau. Le principe
est d’itérativement passer l’image d’entrée <span class="math notranslate nohighlight">\(\mathbf{I}\)</span> dans le réseau
pour obtenir les valeurs des cartes <span class="math notranslate nohighlight">\(\mathbf{Y_i^{(l)}}\)</span>, de
rétropropager pour obtenir le gradient d’un neurone par rapport aux
pixels de <span class="math notranslate nohighlight">\(\mathbf{I}\)</span> et d’opérer une petite modification de ces
pixels. Outre son aspect informatif sur la structure interne du réseau
étudié (visualisation des cartes <span class="math notranslate nohighlight">\(\mathbf{Y_i^{(l)}}\)</span> intermédiaires),
cette méthode produit des images parfois très artistiques (<a class="reference internal" href="#monteeg"><span class="std std-numref">Fig. 18</span></a>).</p>
<figure class="align-center" id="monteeg">
<img alt="_images/monteeg.png" src="_images/monteeg.png" />
<figcaption>
<p><span class="caption-number">Fig. 18 </span><span class="caption-text">Visualisation des 4 premières couches de convolution d’un
réseau convolutif par montée de gradient  (source :<span id="id7">[<a class="reference internal" href="transferLearning.html#id54" title="Jason Yosinski, Jeff Clune, Anh Mai Nguyen, Thomas J. Fuchs, and Hod Lipson. Understanding neural networks through deep visualization. CoRR, 2015. URL: http://dblp.uni-trier.de/db/journals/corr/corr1506.html#YosinskiCNFL15.">7</a>]</span>)</span><a class="headerlink" href="#monteeg" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="implementation">
<h2>Implémentation<a class="headerlink" href="#implementation" title="Lien vers cette rubrique">#</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torchsummary</span> <span class="kn">import</span> <span class="n">summary</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">StepLR</span>
</pre></div>
</div>
<p>On travaille sur les données MNIST</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># taille des batchs</span>
<span class="n">train_batch_size</span><span class="o">=</span><span class="mi">128</span>
<span class="n">test_batch_size</span> <span class="o">=</span> <span class="mi">128</span>

<span class="c1"># Learning rate</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="c1"># Nombre d&#39;epochs </span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Régularisation Dropout</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.25</span>

<span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
        <span class="p">])</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;../data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">dataset2</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;../data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                       <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">train_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="n">train_batch_size</span><span class="p">}</span>
<span class="n">test_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="n">test_batch_size</span><span class="p">}</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset1</span><span class="p">,</span><span class="o">**</span><span class="n">train_kwargs</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset2</span><span class="p">,</span> <span class="o">**</span><span class="n">test_kwargs</span><span class="p">)</span>
</pre></div>
</div>
<p>et on implémente un réseau convolutif ayant l’architecture suivante :</p>
<p>CONV1 - RELU - MAX POOLING - CONV2 - RELU - MAX POOLING - FCL - DROPOUT - Prediction</p>
<p>avec :</p>
<ul class="simple">
<li><p>des noyaux de convolution de taille 5<span class="math notranslate nohighlight">\(\times\)</span>5</p></li>
<li><p>un max pooling sur une région 2<span class="math notranslate nohighlight">\(\times\)</span>2</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
<p>On créé ensuite les fonction pour entraîner et tester le réseau</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch: </span><span class="si">{}</span><span class="s1"> [</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> (</span><span class="si">{:.0f}</span><span class="s1">%)]</span><span class="se">\t</span><span class="s1">Perte : </span><span class="si">{:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span>
                <span class="mf">100.</span> <span class="o">*</span> <span class="n">batch_idx</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
    <span class="k">return</span> <span class="n">loss</span>


<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>  <span class="c1"># sum up batch loss</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># get the index of the max log-probability</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">test_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Perte moyenne en test : </span><span class="si">{:.4f}</span><span class="s1">, Précision : </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> (</span><span class="si">{:.0f}</span><span class="s1">%)</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">test_loss</span><span class="p">,</span> <span class="n">correct</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span><span class="n">test_acc</span>
        <span class="p">))</span>
    <span class="k">return</span> <span class="n">test_loss</span><span class="p">,</span><span class="n">test_acc</span>
</pre></div>
</div>
<p>et on instantie le modèle</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">CNN</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">summary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
</pre></div>
</div>
<p>puis on l’entraîne</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trainLoss</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">testLoss</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">testAcc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">trainLoss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">t</span><span class="p">,</span><span class="n">a</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
    <span class="n">testLoss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">testAcc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trainLoss</span><span class="p">,</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">testLoss</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Fonction de perte&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Perte&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">testAcc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Précision&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Précision en test&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-center" id="perte">
<img alt="_images/precisionCNN.png" src="_images/precisionCNN.png" />
<figcaption>
<p><span class="caption-number">Fig. 19 </span><span class="caption-text">Précision en apprentissage.</span><a class="headerlink" href="#perte" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
<figure class="align-center" id="id8">
<img alt="_images/perteCNN.png" src="_images/perteCNN.png" />
<figcaption>
<p><span class="caption-number">Fig. 20 </span><span class="caption-text">Fonction de perte.</span><a class="headerlink" href="#id8" title="Lien vers cette image">#</a></p>
</figcaption>
</figure>
<div class="docutils container" id="id9">
<div role="list" class="citation-list">
<div class="citation" id="id46" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>V. Nair and G. Hinton. Rectified linear units improve restricted boltzmann machines. In Johannes Fürnkranz and Thorsten Joachims, editors, <em>ICML</em>, 807–814. Omnipress, 2010. URL: <a class="reference external" href="http://dblp.uni-trier.de/db/conf/icml/icml2010.html#NairH10">http://dblp.uni-trier.de/db/conf/icml/icml2010.html#NairH10</a>.</p>
</div>
<div class="citation" id="id14" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Deep sparse rectifier neural networks. In Geoffrey J. Gordon, David B. Dunson, and Miroslav Dudík, editors, <em>AISTATS</em>, volume 15 of JMLR Proceedings, 315–323. JMLR.org, 2011. URL: <a class="reference external" href="http://dblp.uni-trier.de/db/journals/jmlr/jmlrp15.html#GlorotBB11">http://dblp.uni-trier.de/db/journals/jmlr/jmlrp15.html#GlorotBB11</a>.</p>
</div>
<div class="citation" id="id15" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>Sergey Ioffe and Christian Szegedy. Batch normalization: accelerating deep network training by reducing internal covariate shift. In Francis R. Bach and David M. Blei, editors, <em>ICML</em>, volume 37 of JMLR Workshop and Conference Proceedings, 448–456. JMLR.org, 2015. URL: <a class="reference external" href="http://dblp.uni-trier.de/db/conf/icml/icml2015.html#IoffeS15">http://dblp.uni-trier.de/db/conf/icml/icml2015.html#IoffeS15</a>.</p>
</div>
<div class="citation" id="id47" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">4</a><span class="fn-bracket">]</span></span>
<p>R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In <em>2014 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, volume 00, 580–587. June 2014. URL: <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/6909475/">https://ieeexplore.ieee.org/abstract/document/6909475/</a>, <a class="reference external" href="https://doi.org/10.1109/CVPR.2014.81">doi:10.1109/CVPR.2014.81</a>.</p>
</div>
<div class="citation" id="id12" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">5</a><span class="fn-bracket">]</span></span>
<p>Matthew D. Zeiler and Rob Fergus. Visualizing and understanding convolutional networks. <em>CoRR</em>, 2013. URL: <a class="reference external" href="http://dblp.uni-trier.de/db/journals/corr/corr1311.html#ZeilerF13">http://dblp.uni-trier.de/db/journals/corr/corr1311.html#ZeilerF13</a>.</p>
</div>
<div class="citation" id="id48" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id6">6</a><span class="fn-bracket">]</span></span>
<p>Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. Grad-cam: visual explanations from deep networks via gradient-based localization. In <em>ICCV</em>, 618–626. IEEE Computer Society, 2017. URL: <a class="reference external" href="http://dblp.uni-trier.de/db/conf/iccv/iccv2017.html#SelvarajuCDVPB17">http://dblp.uni-trier.de/db/conf/iccv/iccv2017.html#SelvarajuCDVPB17</a>.</p>
</div>
<div class="citation" id="id49" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">7</a><span class="fn-bracket">]</span></span>
<p>Jason Yosinski, Jeff Clune, Anh Mai Nguyen, Thomas J. Fuchs, and Hod Lipson. Understanding neural networks through deep visualization. <em>CoRR</em>, 2015. URL: <a class="reference external" href="http://dblp.uni-trier.de/db/journals/corr/corr1506.html#YosinskiCNFL15">http://dblp.uni-trier.de/db/journals/corr/corr1506.html#YosinskiCNFL15</a>.</p>
</div>
<div class="citation" id="id25" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></span>
<p>D. Kingma and M. Welling. Auto-encoding variational bayes. <em>CoRR</em>, 2013. URL: <a class="reference external" href="http://dblp.uni-trier.de/db/journals/corr/corr1312.html#KingmaW13">http://dblp.uni-trier.de/db/journals/corr/corr1312.html#KingmaW13</a>.</p>
</div>
<div class="citation" id="id11" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></span>
<p>S. Hochreiter and J. Schmidhuber. Long short-term memory. <em>Neural Comput.</em>, 9(8):1735–1780, November 1997. URL: <a class="reference external" href="http://dx.doi.org/10.1162/neco.1997.9.8.1735">http://dx.doi.org/10.1162/neco.1997.9.8.1735</a>, <a class="reference external" href="https://doi.org/10.1162/neco.1997.9.8.1735">doi:10.1162/neco.1997.9.8.1735</a>.</p>
</div>
<div class="citation" id="id41" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>10<span class="fn-bracket">]</span></span>
<p>J Chung, Ç Gülçehre, K Cho, and Y Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. <em>CoRR</em>, 2014. URL: <a class="reference external" href="http://arxiv.org/abs/1412.3555">http://arxiv.org/abs/1412.3555</a>.</p>
</div>
<div class="citation" id="id10" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>11<span class="fn-bracket">]</span></span>
<p>M. Schuster and K.K. Paliwal. Bidirectional recurrent neural networks. <em>Trans. Sig. Proc.</em>, 45(11):2673–2681, November 1997. URL: <a class="reference external" href="http://dx.doi.org/10.1109/78.650093">http://dx.doi.org/10.1109/78.650093</a>, <a class="reference external" href="https://doi.org/10.1109/78.650093">doi:10.1109/78.650093</a>.</p>
</div>
<div class="citation" id="id18" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>A Graves, G Wayne, and I Danihelka. Neural turing machines. <em>CoRR</em>, 2014. URL: <a class="reference external" href="http://arxiv.org/abs/1410.5401">http://arxiv.org/abs/1410.5401</a>.</p>
</div>
<div class="citation" id="id40" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>13<span class="fn-bracket">]</span></span>
<p>Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In <em>Advances in Neural Information Processing Systems</em>, 2012. 2012.</p>
</div>
<div class="citation" id="id38" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>14<span class="fn-bracket">]</span></span>
<p>Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. <em>CoRR</em>, 2014. URL: <a class="reference external" href="http://arxiv.org/abs/1409.1556">http://arxiv.org/abs/1409.1556</a>.</p>
</div>
<div class="citation" id="id37" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>15<span class="fn-bracket">]</span></span>
<p>Min Lin, Qiang Chen, and Shuicheng Yan. Network in network. <em>CoRR</em>, 2013. URL: <a class="reference external" href="http://arxiv.org/abs/1312.4400">http://arxiv.org/abs/1312.4400</a>.</p>
</div>
<div class="citation" id="id36" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>16<span class="fn-bracket">]</span></span>
<p>Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott E. Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. <em>CoRR</em>, 2014. URL: <a class="reference external" href="http://arxiv.org/abs/1409.4842">http://arxiv.org/abs/1409.4842</a>.</p>
</div>
<div class="citation" id="id35" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>17<span class="fn-bracket">]</span></span>
<p>Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. <em>CoRR</em>, 2015. URL: <a class="reference external" href="http://arxiv.org/abs/1512.00567">http://arxiv.org/abs/1512.00567</a>.</p>
</div>
<div class="citation" id="id44" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>18<span class="fn-bracket">]</span></span>
<p>François Chollet. Xception: deep learning with depthwise separable convolutions. <em>CoRR</em>, 2016. URL: <a class="reference external" href="http://arxiv.org/abs/1610.02357">http://arxiv.org/abs/1610.02357</a>, <a class="reference external" href="https://arxiv.org/abs/1610.02357">arXiv:1610.02357</a>.</p>
</div>
<div class="citation" id="id34" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Christian Szegedy, Sergey Ioffe, and Vincent Vanhoucke. Inception-v4, inception-resnet and the impact of residual connections on learning. <em>CoRR</em>, 2016. URL: <a class="reference external" href="http://arxiv.org/abs/1602.07261">http://arxiv.org/abs/1602.07261</a>.</p>
</div>
<div class="citation" id="id33" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>20<span class="fn-bracket">]</span></span>
<p>Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. <em>CoRR</em>, 2015. URL: <a class="reference external" href="http://arxiv.org/abs/1512.03385">http://arxiv.org/abs/1512.03385</a>.</p>
</div>
<div class="citation" id="id31" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>21<span class="fn-bracket">]</span></span>
<p>Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. <em>IEEE Trans. on Knowl. and Data Eng.</em>, 22(10):1345–1359, October 2010. URL: <a class="reference external" href="http://dx.doi.org/10.1109/TKDE.2009.191">http://dx.doi.org/10.1109/TKDE.2009.191</a>, <a class="reference external" href="https://doi.org/10.1109/TKDE.2009.191">doi:10.1109/TKDE.2009.191</a>.</p>
</div>
<div class="citation" id="id54" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>22<span class="fn-bracket">]</span></span>
<p>Y. Song, T. Wang, P. Cai, S. Mondal, and J. Sahoo. A comprehensive survey of few-shot learning: evolution, applications, challenges, and opportunities. <em>ACM Computing Surveyx</em>, 2023.</p>
</div>
<div class="citation" id="id53" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>23<span class="fn-bracket">]</span></span>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, <em>Advances in Neural Information Processing Systems</em>, volume 30. Curran Associates, Inc., 2017. URL: <a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a>.</p>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="PMC.html"
       title="page précédente">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">précédent</p>
        <p class="prev-next-title">Perceptrons multicouches</p>
      </div>
    </a>
    <a class="right-next"
       href="ae.html"
       title="page suivante">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">suivant</p>
        <p class="prev-next-title">Auto-encodeurs</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contenu
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inspiration-biologique">Inspiration biologique</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convolution-discrete">Convolution discrète</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#definition-des-couches">Définition des couches</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#couche-de-convolution">Couche de convolution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#couche-non-lineaire">Couche non linéaire</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#couches-de-normalisation">Couches de normalisation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#couche-d-agregation-et-de-sous-echantillonnage">Couche d’agrégation et de sous-échantillonnage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#couche-completement-connectee">Couche complètement connectée</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regularisation">Régularisation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regularisation-de-la-fonction-de-cout">Régularisation de la fonction de coût</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dropout">Dropout</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#partage-de-parametres">Partage de paramètres</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#initialisation">Initialisation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apprentissage">Apprentissage</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#le-probleme-de-l-entrainement">Le problème de l’entraînement</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisation-du-mecanisme-des-reseaux-convolutifs">Visualisation du mécanisme des réseaux convolutifs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#methodes-de-visualisation-de-base">Méthodes de visualisation de base</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#methodes-fondees-sur-les-activations">Méthodes fondées sur les activations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#methodes-fondees-sur-le-gradient">Méthodes fondées sur le gradient</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implémentation</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Par Vincent BARRA
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>