
<!DOCTYPE html>

<html lang="fr">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introduction aux réseaux de neurones &#8212; Apprentissage profond</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Recherche" href="search.html" />
    <link rel="prev" title="Apprentissage profond" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="fr">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Apprentissage profond</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Apprentissage profond
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Introduction aux réseaux de neurones
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/vbarra/dlbook.git"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/vbarra/dlbook.git/issues/new?title=Issue%20on%20page%20%2FNN.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/NN.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reseaux-de-neurones-et-apprentissage-automatique">
   Réseaux de neurones et apprentissage automatique
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#du-neurone-biologique-au-neurone-formel">
     Du neurone biologique au neurone formel
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-des-reseaux-de-neurones">
     Classification des réseaux de neurones
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#applications">
     Applications
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#perceptron">
   Perceptron
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#definitions">
     Définitions
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Introduction aux réseaux de neurones</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reseaux-de-neurones-et-apprentissage-automatique">
   Réseaux de neurones et apprentissage automatique
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#du-neurone-biologique-au-neurone-formel">
     Du neurone biologique au neurone formel
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-des-reseaux-de-neurones">
     Classification des réseaux de neurones
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#applications">
     Applications
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#perceptron">
   Perceptron
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#definitions">
     Définitions
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="introduction-aux-reseaux-de-neurones">
<h1>Introduction aux réseaux de neurones<a class="headerlink" href="#introduction-aux-reseaux-de-neurones" title="Lien permanent vers ce titre">#</a></h1>
<div class="section" id="reseaux-de-neurones-et-apprentissage-automatique">
<h2>Réseaux de neurones et apprentissage automatique<a class="headerlink" href="#reseaux-de-neurones-et-apprentissage-automatique" title="Lien permanent vers ce titre">#</a></h2>
<p>Les réseaux de neurones artificiels sont des techniques
issues du domaine du connexionisme. Le courant connexionniste insiste
sur le grand nombre de connexions (sous forme de réseau) réalisées entre
les différents automates que sont les neurones. Le connexionisme permet
:</p>
<ul class="simple">
<li><p>de disposer de nouveaux moyens de calcul : conversion de
l’information des systèmes avec des applications pratiques ;</p></li>
<li><p>de modéliser des phénomènes biologiques pour en apprendre davantage
sur le cerveau en l’observant comme si c’était une machine de
traitement électrique.</p></li>
</ul>
<p>La démarche des réseaux de neurones s’oppose en certains points à celle
de l’intelligence artificielle basée règles,
qui sont manipulées selon les techniques de la logique formelle afin de
fournir une représentation explicite du raisonnement. Cette méthodologie implique
une approche « descendante » : elle part de l’analyse de la manière
dont l’être humain procède pour résoudre des problèmes ou pour les
apprendre, et tente de restituer cette démarche en la décomposant en
unités élémentaires.
Les réseaux de neurones, eux, procèdent selon une
approche « ascendante » qui tente de produire des phénomènes complexes
à partir
d’opérations très élémentaires.</p>
<div class="section" id="du-neurone-biologique-au-neurone-formel">
<h3>Du neurone biologique au neurone formel<a class="headerlink" href="#du-neurone-biologique-au-neurone-formel" title="Lien permanent vers ce titre">#</a></h3>
<p>La reconnaissance du fait que le cerveau fonctionne de manière
entièrement différente de celle d’un ordinateur conventionnel a joué un
rôle très important dans le développement des réseaux de neurones
artificiels. Les travaux effectués pour essayer de comprendre le
comportement du cerveau humain ont mené à représenter celui-ci par un
ensemble de composants structurels appelés neurones, massivement
interconnectés entre eux. Le cerveau humain en contient en moyenne une dizaine de milliards, chacun d’entre eux étant connecté, encore une fois en moyenne,
connecté à dix mille autres.<br />
Le neurone biologique est composé de quatre parties distinctes (<a class="reference internal" href="#neurone"><span class="std std-numref">Fig. 1</span></a>) :</p>
<ul class="simple">
<li><p>le <em>corps cellulaire</em>, qui contient le noyau de la cellule nerveuse;
c’est en cet endroit que prend naissance l’influx nerveux, qui
représente l’état d’activité du neurone;</p></li>
<li><p>les <em>dendrites</em>, ramifications tubulaires courtes formant une espèce
d’arborescence autour du corps cellulaire; ce sont les entrées
principales du neurone, qui captent l’information venant d’autres
neurones;</p></li>
<li><p>l”<em>axone</em>, longue fibre nerveuse qui se ramifie à son extrémité; c’est
la sortie du neurone et le support de l’information vers les autres
neurones;</p></li>
<li><p>la <em>synapse</em>, qui communique l’information, en la pondérant par un
poids synaptique, à un autre neurone; elle est essentielle dans le
fonctionnement du système nerveux.</p></li>
</ul>
<div class="figure align-default" id="neurone">
<img alt="_images/neurone.png" src="_images/neurone.png" />
<p class="caption"><span class="caption-number">Fig. 1 </span><span class="caption-text">Neurone biologique</span><a class="headerlink" href="#neurone" title="Lien permanent vers cette image">#</a></p>
</div>
<p>La transmission de l’information d’un neurone à l’autre s’effectue au
moyen de l’influx nerveux, qui est constitué d’une impulsion électrique,
d’une durée d’environ 2 ms et d’une amplitude de 100 mV. Une cellule
nerveuse standard non sollicitée en émet en moyenne cinquante à la
seconde (activité spontanée). La probabilité d’émettre une impulsion est
accrue ou réduite selon que la somme pondérée des entrées du neurone est
globalement excitatrice ou inhibitrice. Cette fréquence peut ainsi être
portée jusqu’à 100 impulsions par seconde, pour un neurone bombardé
d’effets synaptiques excitateurs ; dans le cas contraire, elle peut être
réduite à néant (le neurone reste silencieux). Les effets synaptiques
qui agissent sur le neurone entraînent donc une modulation de la
fréquence d’émission de l’influx nerveux. Le message transmis est
précisément contenu dans le nombre d’influx nerveux émis, défini par une
moyenne sur quelques dizaines de ms. L’information contenue dans le
cerveau, quant à elle, est représentée par les poids synaptiques
attribués aux entrées de chaque neurone. Le cerveau est capable
d’organiser ces neurones, selon un assemblage complexe, non-linéaire et
extrêmement parallèle, de manière à pouvoir accomplir des tâches très
élaborées. Du fait du grand nombre de neurones et de leurs
interconnexions, ce système possède une propriété de tolérance aux
fautes. Ainsi, la défectuosité d’un neurone n’entraînera aucune perte
réelle d’information, mais seulement une faible dégradation en qualité
de toute l’information contenue dans le système.</p>
<p>C’est la tentative de donner à l’ordinateur les qualités de perception
du cerveau humain qui a conduit à une modélisation électrique de
celui-ci. C’est cette modélisation que tentent de réaliser les réseaux
de neurones artificiels, dont l’élaboration repose sur base de la
définition suivante, proposée par Haykin :\</p>
<p>Un réseau de neurones est un processus distribué de manière massivement
parallèle, qui a une propension naturelle à mémoriser des connaissances
de façon expérimentale et de les rendre disponibles pour utilisation. Il
ressemble au cerveau en deux points :</p>
<ol class="simple">
<li><p>la connaissance est acquise au travers d’un processus
d’apprentissage;</p></li>
<li><p>les poids des connections entre les neurones sont utilisés pour
mémoriser la connaissance</p></li>
</ol>
<p>La première étude systématique du neurone artificiel est due au
neuropsychiatre McCulloch et au logicien Pitts qui s’inspirèrent de
leurs travaux sur les neurones biologiques.</p>
</div>
<div class="section" id="classification-des-reseaux-de-neurones">
<h3>Classification des réseaux de neurones<a class="headerlink" href="#classification-des-reseaux-de-neurones" title="Lien permanent vers ce titre">#</a></h3>
<p>Un réseau de neurones est constitué d’un grand nombre de
cellules de base interconnectées. De nombreuses variantes sont définies
selon le choix de la cellule élémentaire, de l’architecture et de la
dynamique du réseau.</p>
<p>Une cellule élémentaire peut manipuler des valeurs binaires ou réelles.
Les valeurs binaires sont représentées par 0 et 1 ou -1 et 1.
Différentes fonctions d’ctivation peuvent être utilisées pour le calcul de la
sortie. Le calcul de la sortie peut être déterministe ou probabiliste.</p>
<p>L’architecture du réseau peut être sans rétroaction, c’est à dire que la
sortie d’une cellule ne peut influencer son entrée. Elle peut être avec
rétroaction totale ou partielle.</p>
<p>La dynamique du réseau peut être synchrone : toutes les cellules
calculent leurs sorties respectives simultanément. La dynamique peut
être asynchrone. Dans ce dernier cas, on peut avoir une dynamique
asynchrone séquentielle : les cellules calculent leurs sorties chacune à
son tour en séquence ou avoir une dynamique asynchrone aléatoire.</p>
<p>Par exemple, si on considère des neurones à sortie stochastique -1 ou 1
calculée par une fonction à seuil basée sur la fonction sigmoïde, une
interconnection complète et une dynamique synchrone, on obtient le
modèle de Hopfield et la notion de mémoire associative.</p>
<p>Si on considère des neurones déterministes à sortie réelle calculée à
l’aide de la fonction sigmoïde, une architecture sans rétroaction en
couches successives avec une couche d’entrée et une couche de sortie,
une dynamique asynchrone séquentielle, on obtient le modèle du
Perceptron multi-couches (PMC).</p>
</div>
<div class="section" id="applications">
<h3>Applications<a class="headerlink" href="#applications" title="Lien permanent vers ce titre">#</a></h3>
<p>En apprentissage, les réseaux de neurones sont essentiellement utilisés pour :</p>
<ul class="simple">
<li><p>l’apprentissage supervisé ;</p></li>
<li><p>l’apprentissage non supervisé ;</p></li>
<li><p>l’apprentissage par renforcement.</p></li>
</ul>
<p>Dans la suite, nous nous intéressons essentiellement au cas de l’apprentissage
supervisé. Le cas des réseaux de neurones en apprentissage non supervisé
concerne principalement les cartes de Kohonen, les machines de Boltzmann
restreintes (RBM) et les autoencodeurs.</p>
</div>
</div>
<div class="section" id="perceptron">
<h2>Perceptron<a class="headerlink" href="#perceptron" title="Lien permanent vers ce titre">#</a></h2>
<div class="section" id="definitions">
<h3>Définitions<a class="headerlink" href="#definitions" title="Lien permanent vers ce titre">#</a></h3>
<div class="proof definition admonition" id="definition-0">
<p class="admonition-title"><span class="caption-number">Definition 1 </span> (Neurone)</p>
<div class="definition-content section" id="proof-content">
<p>Un neurone est une fonction non linéaire, paramétrée à valeurs bornées.
Les <span class="math notranslate nohighlight">\(D\)</span> variables sur lesquelles opère le neurone sont habituellement
désignées sous le terme d’entrées du neurone (notées
<span class="math notranslate nohighlight">\(x_i,i\in[\![1,D]\!])\)</span>, et la valeur de la fonction sous celui de sortie
<span class="math notranslate nohighlight">\(y\)</span>.<br />
Le neurone formel calcule la sortie selon la formule :</p>
<div class="math notranslate nohighlight">
\[y = f(w_0+\displaystyle\sum_{i=1}^Dw_ix_i) = f(w_0+\mathbf w^\top \mathbf x)\]</div>
<p>où :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf w = (w_1\cdots w_D)^\top\)</span> est le vecteur des poids synaptiques qui pondèrent les entrées du neurone,</p></li>
<li><p><span class="math notranslate nohighlight">\(w_0\)</span> est un biais</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf w^\top \mathbf x\)</span> est le potentiel du neurone</p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> est la fonction d’activation associée au neurone.</p></li>
</ul>
</div>
</div><div class="proof definition admonition" id="definition-1">
<p class="admonition-title"><span class="caption-number">Definition 2 </span> (Réseau de neurones)</p>
<div class="definition-content section" id="proof-content">
<p>Un réseau de neurones est un ensemble de neurones interconnectés. Les
réseaux de neurones peuvent être visualisés par l’intermédiaire d’un
graphe orienté. Chaque neurone est un noeud, les neurones étant
connectés par des arêtes.</p>
</div>
</div><p>On distingue habituellement neurone d’entrée et neurone de
sortie. Un neurone d’entrée calcule <span class="math notranslate nohighlight">\(y = x\)</span> où <span class="math notranslate nohighlight">\(x\)</span> est une entrée unique
du neurone. Les neurones de sortie prennent un nombre quelconque
d’entrées. Interconnectés, l’ensemble de ces neurones calcule <span class="math notranslate nohighlight">\(\mathbf y(x)\)</span>
dont la dimension est donnée par le nombre de neurones d’entrée et de
sortie (l’entrée du réseau est acceptée par les neurones d’entrée, qui
forment la rétine), et la sortie du réseau est formée par les neurones
de sortie.</p>
<p>Le cas le plus simple est celui d’un réseau comportant un seul neurone de sortie.
C’est le <em>perceptron</em>. Le perceptron est un modèle de réseau de neurones
avec algorithme d’apprentissage (Rosenblatt en 1958). L’idée
sous-jacente de ce modèle est le fonctionnement de la rétine, l’étude de
la perception visuelle. Nous commençons par aborder le cas du perceptron
linéaire à seuil.</p>
<div class="proof definition admonition" id="definition-2">
<p class="admonition-title"><span class="caption-number">Definition 3 </span> (Perceptron linéire à seuil)</p>
<div class="definition-content section" id="proof-content">
<p>Un perceptron linéaire à seuil prend en entrée <span class="math notranslate nohighlight">\(D\)</span> valeurs
<span class="math notranslate nohighlight">\(x_1\cdots x_D\)</span> (la rétine) et calcule une sortie <span class="math notranslate nohighlight">\(y\)</span>. Suivant la
définition précédente, un perceptron est défini par la donnée de <span class="math notranslate nohighlight">\(D+1\)</span>
constantes : les <strong>poids synaptiques</strong> <span class="math notranslate nohighlight">\(w_1,\cdots,w_D\)</span> et un seuil (ou
le biais) <span class="math notranslate nohighlight">\(\theta\)</span>. La sortie <span class="math notranslate nohighlight">\(y\)</span> est calculée par</p>
<div class="math notranslate nohighlight">
\[\begin{split}y= 
\left \{
\begin{array}{lr}
   1 &amp; \textrm{si}\quad w^Tx=\displaystyle\sum_{i=1}^Dw_ix_i&gt;\theta\\
   0 &amp; \textrm{sinon}\\
\end{array}
\right.\end{split}\]</div>
</div>
</div><p>Les entrées <span class="math notranslate nohighlight">\(x_1,\cdots x_D\)</span> peuvent être à valeurs dans {0,1} (ou
{-1,1}) ou réelles, les poids peuvent être entiers ou réels.</p>
<p>Pour simplifier les notations et certaines preuves, on remplace souvent
le seuil par un poids supplémentaire <span class="math notranslate nohighlight">\(w_0\)</span> associé à une entrée <span class="math notranslate nohighlight">\(x_0=1\)</span>.  (<code class="xref std std-numref docutils literal notranslate"><span class="pre">perceptron</span></code>). L’équivalence entre le modèle avec
seuil et le modèle avec entrée supplémentaire à 1 est immédiate : le
coefficient <span class="math notranslate nohighlight">\(w_0\)</span> est l’opposé du seuil <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>:name: perceptron
Neurone Représentation d’un perceptron sous la forme d’un graphe orienté</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
On note $\mathbf w$ (respectivement $\mathbf x$) $\in\mathbb R^{D+1}$ le vecteur des poids
(resp. des entrées), augmentée de $w_0$ (resp. $x_0$=1). Comme suggéré
par la définition, on peut décomposer le calcul de la sortie $y$ en un
premier calcul de la quantité $w^Tx=\displaystyle\sum_{i=0}^Dw_ix_i$
appelée **potentiel post-synaptique** ou **entrée totale**, suivi d&#39;une
application d&#39;une **fonction d&#39;activation** sur cette entrée totale.
Dans le cas du perceptron linéaire à seuil, la fonction d&#39;activation est
la fonction de Heaviside définie par $f(x)=1_{\{x&gt;0\}}$ lorsque la
sortie est en {0,1}, et $g(x) = 2f(x) - 1$ lorsque la sortie est en
{-1,1}.\

### Utilisation : discrimination linéaire

Soit ${\cal E}_a$ un ensemble d&#39;exemples dans $\mathbb R^D\times${0,1} . On
note $${\cal E}_a^0=\{x\in \mathbb R^D/(x,0)\in {\cal E}_a\}$$ et
$${\cal E}_a^1=\{x\in \mathbb R^D/(x,1)\in {\cal E}_a\}$$ On dit que
${\cal E}_a$ est **linéairement séparable** s&#39;il existe un hyperplan $H$
de $\mathbb R^D$ tel que les ensembles ${\cal E}_a^0$ et ${\cal E}_a^1$
soient situés de part et d&#39;autre de cet hyperplan.\
On montre qu&#39;un perceptron linéaire à seuil à $D$ entrées divise
l&#39;espace des entrées $\mathbb R^D$ en deux sous-espaces délimités par un
hyperplan $w^Tx=0$. Réciproquement, tout ensemble linéairement séparable
peut être discriminé par un perceptron.\
Un perceptron est donc un discriminant linéaire. On montre facilement
qu&#39;un échantillon de $\mathbb R^D$ est séparable par un hyperplan si et
seulement si l&#39;échantillon de $\mathbb R^{D+1}$ obtenu en rajoutant une
entrée toujours égale à 1 est séparable par un hyperplan passant par
l&#39;origine.\
Toute fonction de $\mathbb R^D$ dans {0,1} n&#39;est bien sur pas calculable par
un tel perceptron.\

### Algorithme d&#39;apprentissage par correction d&#39;erreur

Étant donné un échantillon d&#39;apprentissage ${\cal E}_a$ de
$\mathbb R^D\times$ {0,1} (respectivement $\{0,1\}^n\times$ {0,1}),
c&#39;est-à-dire un ensemble d&#39;exemples dont les descriptions sont $D$
attributs réels (respectivement binaires) et la classe est binaire, il
s&#39;agit de trouver un algorithme qui infère à partir de ${\cal E}_a$ un
perceptron qui classifie correctement les éléments de ${\cal E}_a$ au vu
de leurs descriptions si c&#39;est possible, ou au mieux sinon.\
L&#39;algorithme d&#39;apprentissage peut être décrit succinctement de la
manière suivante. On initialise les poids du perceptron à des valeurs
quelconques. A chaque fois que l&#39;on présente un nouvel exemple, on
ajuste les poids selon que le perceptron l&#39;a correctement classé ou non.
L&#39;algorithme s&#39;arrête lorsque tous les exemples ont été présentés sans
modification d&#39;aucun poids.\
Dans la suite, on note $x_n$ une entrée. La i$^\textrm{ème}$ composante
de $x_n$ est notée $x_n^i$. Pour simplifier l&#39;explication de
l&#39;algorithme, cette composante sera supposée binaire. Un échantillon
${\cal E}_a$ est un ensemble de couples $(x_n,t_n)$ où $t_n$ est la
classe binaire de $x_n$. Si une entrée $x_n$ est présentée en entrée
d&#39;un perceptron, nous noterons $y_n$ la sortie binaire calculée par le
perceptron. Rappelons qu&#39;il existe une $(D+1)^\textrm{ème}$ entrée $x_0$
de valeur 1 pour le perceptron.\
L&#39;algorithme d&#39;apprentissage par correction d&#39;erreur du perceptron
linéaire à seuil suit alors le schéma suivant :

::: algorithm
Initialisation aléatoire des $w_i$\
Prendre un exemple $(x_n,t_n)$ dans ${\cal E}_a$\
Calculer la sortie $y_n$ du perceptron pour l&#39;entrée $x_n$\
$w_i \leftarrow w_i+(t_n-y_n)x_n^i$\
:::

La procédure d&#39;apprentissage du perceptron est une procédure de
correction d&#39;erreur puisque les poids ne sont pas modifiés lorsque la
sortie attendue $t_n$ est égale à la sortie calculée $y_n$ par le
perceptron courant.\
Étudions les modifications sur les poids lorsque $t_n$ diffère de $y_n$,
lorsque $x\in \{0,1\}^n$ :

-   si $y_n$=0 et $t_n$=1, cela signifie que le perceptron n&#39;a pas assez
    pris en compte les neurones actifs de l&#39;entrée (c&#39;est-à-dire les
    neurones ayant une entrée à 1) ; dans ce cas,
    $w_i \leftarrow w_i+x_n^i$; l&#39;algorithme ajoute la valeur de la
    rétine aux poids synaptiques (renforcement).

-   si $y_n$=1 et $t_n$=0, alors $w_i \leftarrow w_i-x_n^i$ ;
    l&#39;algorithme retranche la valeur de la rétine aux poids synaptiques
    (inhibition).

Remarquons que, en phase de calcul, les constantes du perceptron sont
les poids synaptiques alors que les variables sont les entrées. Tandis
que, en phase d&#39;apprentissage, ce sont les coefficients synaptiques qui
sont variables alors que les entrées de l&#39;échantillon ${\cal E}_a$
apparaissent comme des constantes.\
Certains éléments importants ont été laissés volontairement imprécis.

-   en premier lieu, il faut préciser comment est fait le choix d&#39;un
    élément de ${\cal E}_a$ : aléatoirement ? En suivant un ordre
    prédéfini ? Doivent-ils être tous présentés ?

-   le critère d&#39;arrêt de la boucle principale de l&#39;algorithme n&#39;est pas
    défini : après un certain nombre d&#39;étapes ? Lorsque tous les
    exemples ont été présentés ? Lorsque les poids ne sont plus modifiés
    pendant un certain nombre d&#39;étapes ?

Nous reviendrons sur toutes ces questions par la suite. Exemple :
apprentissage du OU binaire\
Les descriptions appartiennent à {0,1}$^2$, les entrées du perceptron
appartiennent à {0,1}$^3$, la première composante correspond à l&#39;entrée
$x_0$ et vaut toujours 1, les deux composantes suivantes correspondent
aux variables $x_1$ et $x_2$ . On suppose qu&#39;à l&#39;initialisation, les
poids suivants ont été choisis : $w_0$=0 ; $w_1$ = 1 et $w_2$ = -1. On
suppose que les exemples sont présentés dans l&#39;ordre lexicographique.\

::: {#tabou}
   étape   $w^{t-1}_0$   $w^{t-1}_1$   $w^{t-1}_2$   Entrée   $\dsum_{i=0}^2w^{t-1}_ix_i$   $y$   $t$   $w^{t}_0$   $w^{t}_1$   $w^{t}_2$
  ------- ------------- ------------- ------------- -------- ----------------------------- ----- ----- ----------- ----------- -----------
   Init                                                                                                     0           1          -1
     1          0             1            -1         100                  0                 0     0        0           1          -1
     2          0             1            -1         101                 -1                 0     1        1           1           0
     3          1             1             0         110                  2                 1     1        1           1           0
     4          1             1             0         111                  2                 1     1        1           1           0
     5          1             1             0         100                  1                 1     0        0           1           0
     6          0             1             0         101                  0                 0     1        1           1           1
     7          1             1             1         110                  2                 1     1        1           1           1
     8          1             1             1         111                  3                 1     1        1           1           1
     9          1             1             1         100                  1                 1     0        0           1           1
    10          0             1             1         101                  1                 1     1        0           1           1

  : Apprentissage du OU binaire
:::

Le tableau [1.1](#tabou){reference-type=&quot;ref&quot; reference=&quot;tabou&quot;}
présente la trace de l&#39;algorithme à partir de cette initialisation.
Aucune entrée ne modifie le perceptron à partir de l&#39;itération 10.\
\
On peut montrer que si l&#39;échantillon ${\cal E}_a$ est linéairement
séparable et si les exemples sont présentés de manière équitable
(c&#39;est-à-dire que la procédure de choix des exemples n&#39;en exclut aucun),
la procédure d&#39;apprentissage par correction d&#39;erreur converge vers un
perceptron linéaire à seuil qui sépare linéairement ${\cal E}_a$.\
L&#39;inconvénient majeur de cet apprentissage est que si l&#39;échantillon
présenté n&#39;est pas linéairement séparable, l&#39;algorithme ne convergera
pas et l&#39;on aura aucun moyen de le savoir. On pourrait penser qu&#39;il
suffit d&#39;observer l&#39;évolution des poids synaptiques pour en déduire si
l&#39;on doit arrêter ou non l&#39;algorithme. En effet, si les poids et le
seuil prennent deux fois les mêmes valeurs sans que le perceptron ait
appris et alors que tous les exemples ont été présentés, cela signifie
que l&#39;échantillon n&#39;est pas séparable. Et l&#39;on peut penser que l&#39;on peut
borner les poids et le seuil en fonction de la taille de la rétine.
C&#39;est vrai mais les résultats de complexité suivants montrent que cette
idée n&#39;est pas applicable en pratique.\

1.  Toute fonction booléenne linéairement séparable sur $D$ variables
    peut être réalisée par un perceptron dont les poids synaptiques
    entiers $w_i$ sont tels que
    $\left\lceil w_i\right\rceil \leq (D+1)^{\frac{D+1}{2}}$

2.  Il existe des fonction booléennes linéairement séparables sur $D$
    variables qui requièrent des poids entiers supérieurs à
    $2^{\frac{D+1}{2}}$

Ces résultats sont assez décevants. Le premier montre que l&#39;on peut
borner les poids synaptiques en fonction de la taille de la rétine, mais
par un nombre tellement grand que toute application pratique de ce
résultat semble exclue. Le second résultat montre en particulier que
l&#39;algorithme d&#39;apprentissage peut nécessiter un nombre exponentiel
d&#39;étapes (en fonction de la taille de la rétine) avant de s&#39;arrêter. En
effet, les poids ne varient qu&#39;au plus d&#39;une unité à chaque étape. Même
lorsque l&#39;algorithme d&#39;apprentissage du perceptron converge, rien ne
garantit que la solution sera robuste, c&#39;est-à-dire qu&#39;elle ne sera pas
remise en cause par la présentation d&#39;un seul nouvel exemple. Pire
encore, cet algorithme n&#39;a aucune tolérance au bruit : si du bruit,
c&#39;est-à-dire une information mal classée, vient perturber les données
d&#39;entrée, le perceptron ne convergera jamais. En effet, des données
linéairement séparables peuvent ne plus l&#39;être à cause du bruit. En
particulier, les problèmes non-déterministes, c&#39;est-à-dire pour lesquels
une même description peut représenter des éléments de classes
différentes, ne peuvent pas être traités à l&#39;aide d&#39;un perceptron.

### Algorithme d&#39;apprentissage par descente de gradient {#subsec:descentegradient}

Plutôt que d&#39;obtenir un perceptron qui classifie correctement tous les
exemples, il s&#39;agit maintenant de calculer une erreur et d&#39;essayer de
minimiser cette erreur. Pour introduire cette notion d&#39;erreur, on
utilise des poids réels.\
Un perceptron linéaire prend en entrée un vecteur $x_n$ et calcule une
sortie $y_n$. Un perceptron est défini par la donnée d&#39;un vecteur $w$ de
coefficients synaptiques. La sortie $y_n$ est définie par $y_n=w^Tx_n$\
L&#39;erreur du perceptron sur un échantillon d&#39;apprentissage ${\cal E}_a$
d&#39;exemples $(x_n,t_n)$ est définie en utilisant par l&#39;erreur quadratique
:
$$E(w)=\frac{1}{2}\displaystyle\sum_{(x_n,t_n)\in {\cal E}_a} (t_n-y_n)^2$$
L&#39;erreur mesure donc l&#39;écart entre les sorties attendue et calculée sur
l&#39;échantillon complet. On remarque que $E(w) = 0$ si et seulement si le
perceptron classifie correctement l&#39;échantillon complet. On suppose
${\cal E}_a$ fixé, le problème est donc de déterminer, par descente de
gradient, un vecteur $\tilde{w}$ qui minimise $E(w)$. On a alors :
$$\begin{aligned}
\frac{\partial E(w)}{\partial w_i}&amp;=\frac{\partial}{\partial w_i}\left (\frac{1}{2}\displaystyle\sum_{(x_n,t_n)\in {\cal E}_a} (t_n-y_n)^2 \right )\\
                                                                                &amp;=\frac{1}{2}\displaystyle\sum_{{\cal E}_a}\frac{\partial}{\partial w_i}(t_n-y_n)^2\\
                                                                                &amp;=\displaystyle\sum_{{\cal E}_a}(t_n-y_n)\frac{\partial}{\partial w_i}(t_n-w^Tx_n)\\
                                                                                &amp;=\displaystyle\sum_{{\cal E}_a}(t_n-y_n)(-x_n^i)\\
\end{aligned}$$ L&#39;application de la méthode du gradient invite donc à
modifier le poids $w_i$ après une présentation complète de ${\cal E}_a$
d&#39;une quantité $\Delta w_i$ définie par :
$$\Delta w_i=-\epsilon \frac{\partial E(w)}{\partial w_i}$$

L&#39;algorithme d&#39;apprentissage par descente de gradient du perceptron
linéaire peut maintenant être défini (algorithme
[\[A:descGrad\]](#A:descGrad){reference-type=&quot;ref&quot;
reference=&quot;A:descGrad&quot;}).

::: algorithm
Initialisation aléatoire des $w_i$\
$\Delta w_i \leftarrow 0$\
Calculer $y_n$\
$\Delta w_i \leftarrow \Delta w_i +\epsilon(t_n-y_n)x_n^i$
$w_i \leftarrow w_i+ \Delta w_i$\
:::

La fonction erreur quadratique ne possède qu&#39;un minimum (la surface est
une paraboloïde). La convergence est assurée, même si l&#39;échantillon
d&#39;entrée n&#39;est pas linéairement séparable, vers un minimum de la
fonction erreur pour un $\epsilon$ bien choisi, suffisamment petit. Si
$\epsilon$ est trop grand, on risque d&#39;osciller autour du minimum. Pour
cette raison, une modification classique est de diminuer graduellement
la valeur de $\epsilon$ en fonction du nombre d&#39;itérations. Le principal
défaut est que la convergence peut être très lente et que chaque étape
nécessite le calcul sur tout l&#39;ensemble d&#39;apprentissage.\
Au lieu de calculer les variations des poids en sommant sur tous les
exemples de ${\cal E}_a$, l&#39;idée est alors de modifier les poids à
chaque présentation d&#39;exemple. La règle de modification des poids
devient : $$\Delta w_i=\epsilon (t_n-y_n)x_n^i$$

Cette règle est appelée règle delta, ou règle Adaline, ou encore règle
de Widrow-Hoff, et l&#39;algorithme
[\[A:adaline\]](#A:adaline){reference-type=&quot;ref&quot; reference=&quot;A:adaline&quot;}
décrit cette règle :

::: algorithm
Initialisation aléatoire des $w_i$\
Prendre un exemple $(x_n,t_n)  \in {\cal E}_a$\
Calculer $y_n$\
$w_i \leftarrow w_i +\epsilon(t_n-y_n)x_n^i$
:::

En général, on parcourt l&#39;échantillon dans un ordre prédéfini. Le
critère d&#39;arrêt généralement choisi fait intervenir un seuil de
modifications des poids pour un passage complet de l&#39;échantillon.\
Au coefficient $\epsilon$ près dans la règle de modification des poids,
on retrouve l&#39;algorithme d&#39;apprentissage par correction d&#39;erreur. Pour
l&#39;algorithme de Widrow-Hoff, il y a correction chaque fois que la sortie
totale (qui est un réel) est différente de la valeur attendue. Ce n&#39;est
donc pas une méthode d&#39;apprentissage par correction d&#39;erreur puisqu&#39;il y
a modification du perceptron dans (presque) tous les cas. Rappelons
également que l&#39;algorithme par correction d&#39;erreur produit en sortie un
perceptron linéaire à seuil alors que l&#39;algorithme par descente de
gradient produit un perceptron linéaire. L&#39;avantage de l&#39;algorithme de
Widrow-Hoff par rapport à l&#39;algorithme par correction d&#39;erreur est que,
même si l&#39;échantillon d&#39;entrée n&#39;est pas linéairement séparable,
l&#39;algorithme va converger vers une solution optimale (sous réserve du
bon choix du paramètre $\epsilon$). L&#39;algorithme est, par conséquent,
plus robuste au bruit.\
L&#39;algorithme de Widrow-Hoff s&#39;écarte de l&#39;algorithme du gradient sur un
point important : on modifie les poids après présentation de chaque
exemple en fonction de l&#39;erreur locale et non de l&#39;erreur globale. On
utilise donc une méthode de type **gradient stochastique**. Rien ne
prouve alors que la diminution de l&#39;erreur en un point ne va pas être
compensée par une augmentation de l&#39;erreur pour les autres points. La
justification empirique de cette manière de procéder est commune à
toutes les méthodes adaptatives : le champ d&#39;application des méthodes
adaptatives est justement l&#39;ensemble des problèmes pour lesquels des
ajustements locaux vont finir par converger vers une solution globale.

L&#39;algorithme de Widrow-Hoff est très souvent utilisé en pratique et
donne de bons résultats. Iil sera utilisé dans les autres réseaux de
neurones rencontrés dans ce cours, avec sa variante où la modification
des poids se fait après présentation d&#39;un sous ensemble de données
d&#39;apprentissage (apprentissage par batchs). La convergence est, en
général, plus rapide que par la méthode du gradient. Il est fréquent
pour cet algorithme de faire diminuer la valeur de $\epsilon$ en
fonction du nombre d&#39;itérations comme pour l&#39;algorithme du gradient.

### Pour en finir avec le perceptron

L&#39;apprentissage par correction ou par la méthode du gradient ne sont
rien d&#39;autre que des techniques de séparation linéaire qu&#39;il faudrait
comparer aux techniques utilisées habituellement en statistiques
(discriminant linéaire, machines à vecteurs de support,\...). Ces
méthodes sont non paramétriques, c&#39;est-à-dire qu&#39;elles n&#39;exigent aucune
autre hypothèse sur les données que la séparabilité.

On peut montrer que presque tous les échantillons de moins de $2D$
exemples sont linéairement séparables lorsque $D$ est le nombre de
variables. Une classification correcte d&#39;un petit échantillon n&#39;a donc
aucune valeur prédictive. Par contre, lorsque l&#39;on travaille sur
suffisamment de données et que le problème s&#39;y prête, on constate
empiriquement que le perceptron appris par un des algorithmes précédents
a un bon pouvoir prédictif.

Il est bien évident que la plupart des problèmes d&#39;apprentissage qui se
posent naturellement ne peuvent pas être résolus par des méthodes aussi
simples : il n&#39;y a que très peu d&#39;espoir que les exemples naturels se
répartissent sagement de part et d&#39;autre d&#39;un hyperplan. Deux manières
de résoudre cette difficulté peuvent être envisagées : soit mettre au
point des séparateurs non-linéaires, soit (ce qui revient à peu près au
même) complexifier l&#39;espace de représentation de manière à linéariser le
problème initial.\
Les réseaux multicouches abordent ce type de problème.

## Perceptrons multicouches {#subsec:multilayer-perceptron}

::: definition
Un perceptron à $(L+1)$ couches (figure
[1.3](#fig:multilayer-perceptron){reference-type=&quot;ref&quot;
reference=&quot;fig:multilayer-perceptron&quot;}) est un réseau constitué d&#39;une
rétine à $D$ neurones (auxquels on rajoute l&#39;entrée $x_0$), $C$ neurones
de sortie, et des neurones dits **cachés**, organisés dans $L$ couches
cachées intermédiaires. De fait, un tel réseau comporte $(L+2)$ couches
mais on compte rarement la rétine, puisque cette dernière n&#39;effectue pas
de calculs. Le $i^{\text{e}}$ neurone dans la couche cachée $l$ calcule
la sortie $$\begin{aligned}
    y_i^{(l)} &amp;= f\left(z_i^{(l)}\right) \quad\text{ avec }\quad z_i^{(l)} = \sum _{k = 1} ^{m^{(l-1)}} w_{i,k}^{(l)} y_k^{(l-1)} + w_{i,0}^{(l)}
\end{aligned}$$ où $w_{i,k}^{(l)}$ est le poids de la connexion entre le
$k^{\text{e}}$ neurone de la couche $(l-1)$ et le $i^{\text{e}}$ neurone
de la couche $l$, et $w_{i,0}^{(l)}$ est le biais. De plus, $m^{(l)}$
est le nombre de neurones de la couche $l$, de sorte que $D = m^{(0)}$
et $C = m^{(L+1)}$. Enfin, $f$ est la fonction d&#39;activation du neurone
(supposée identique pour tous les neurones).\
:::

En introduisant dans chaque couche un neurone supplémentaire
$y_0^{(l)} = 1$ pour gérer le biais, on a : $$\begin{aligned}
    \label{eq:multilayer-perceptron}
    z_i^{(l)} = \sum _{k = 0} ^{m^{(l-1)}} w_{i,k}^{(l)} y_k^{(l-1)}\quad \text{ ou }\quad z^{(l)} = w^{(l)} y^{(l-1)}
\end{aligned}$$ avec $z^{(l)}$, $w^{(l)}$ et $y^{(l-1)}$ les
représentations vectorielle et matricielle des entrées $z_i^{(l)}$, des
poids $w_{i,k}^{(l)}$ et des sorties $y_k^{(l-1)}$.

&lt;figure id=&quot;fig:multilayer-perceptron&quot;&gt;

&lt;figcaption&gt;Perceptron multicouches à &lt;span
class=&quot;math inline&quot;&gt;(&lt;em&gt;L&lt;/em&gt;+1)&lt;/span&gt; couches, &lt;span
class=&quot;math inline&quot;&gt;&lt;em&gt;D&lt;/em&gt;&lt;/span&gt; entrées et &lt;span
class=&quot;math inline&quot;&gt;&lt;em&gt;C&lt;/em&gt;&lt;/span&gt; sorties.&lt;/figcaption&gt;
&lt;/figure&gt;

Un tel réseau représente une fonction $$\begin{aligned}
    y(\cdot,w) &amp;:&amp; \mathbb{R}^D \rightarrow \mathbb{R}^C\\
    x &amp;\mapsto&amp; y(x,w)
\end{aligned}$$ où $y(x,w)$ est tel que $y_i(x,w) = y_i^{(L+1)}$ et $w$
est le vecteur de tous les poids du réseau.

On parlera de **réseau profond (Deep network)** lorsque le nombre de
couches cachées est supérieur à 3.

### Fonctions d&#39;activation {#subsec:activation-functions}

Trois grandes classes de fonction d&#39;activation $f$ sont généralement
utilisées : les fonctions de seuils (comme dans le perceptron linéaire à
seuil), les fonctions linéaires par morceau et les fonctions de type
sigmoïde. Dans les deux premiers cas, de nombreux problèmes se
présentent, notamment en raison de la non différentiabilité de ces
fonctions (qui est nécessaire dans les algorithmes d&#39;apprentissage du
type descente de gradient), ou encore en raison de la faiblesse de leur
pouvoir d&#39;expression. Ainsi, il est préférable d&#39;utiliser des fonctions
de type sigmoïde, et par exemple la sigmoïde logistique est donnée par :
$$\begin{aligned}
    \label{eq:logistic-sigmoid}
    \sigma(z) = \frac{1}{1 + \exp(-z)}.
\end{aligned}$$

La tangente hyperbolique $\tanh(z)$, également utilisée pour ses bonnes
propriétés de dérivabilité ($(\tanh)&#39;=1-\tanh^2$), peut être vue comme
une transformation linéaire de la sigmoïde dans l&#39;intervalle $[-1,1]$.

Ces réseaux peuvent être utilisés en régression (sortie à valeurs dans
$\mathbb{R}^C$) ou en classification. Dans ce dernier cas, la fonction
d&#39;activation softmax est utilisée à la sortie du réseau pour interpréter
les sorties comme des valeurs de probabilité a posteriori. S&#39;il s&#39;agit
de classer un exemple $x$ à la classe $c$, la probabilité conditionnelle
$p(c|x)$ peut être calculée en utilisant la règle de Bayes
:$$\begin{aligned}
p(c|x) = \frac{p(x|c)p(c)}{p(x)}
\end{aligned}$$ $p(c|x)$ est alors interprétée comme une probabilité a
posteriori. Disposant de ces probabilités pour tout $c=1,\ldots,C$, la
règle de décision de Bayes donne :$$\begin{aligned}
c: \mathbb{R}^D \rightarrow \{1,\ldots,C\}, x \mapsto  argmax_{c}\left(p(c|x)\right).
\end{aligned}$$ L&#39;utilisation de la fonction d&#39;activation softmax en
sortie permet d&#39;interpréter les sorties du réseau comme de telles
probabilités :la sortie du $i^{\text{e}}$ neurone de la couche de sortie
est

$$\begin{aligned}
    \sigma(z^{(L+1)},i) = \frac{\exp(z_i^{(L+1)})}{\displaystyle\sum_{k = 1} ^C \exp(z_k^{(L+1)})}.
\end{aligned}$$

En apprentissage profond, il a été reporté que la sigmoïde et la
tangente hyperbolique avaient des performances moindres que la fonction
d&#39;activation softsign : $$\begin{aligned}
    \label{eq:softsign}
    s(z) = \frac{1}{1+ |z|}.
\end{aligned}$$ En effet, les valeurs de $z$ arrivant près des paliers
de saturation de ces fonctions donnent des gradients faibles, qui ont
tendance à s&#39;annuler lors de la phase d&#39;apprentissage détaillée plus
loin (rétropropagation du gradient). Une autre fonction, non saturante
elle, peut être utilisée : $$\begin{aligned}
    \label{eq:relu}
    r(z) = \max (0,z).
\end{aligned}$$ Les neurones cachés utilisant la fonction décrite dans
l&#39;équation [\[eq:relu\]](#eq:relu){reference-type=&quot;eqref&quot;
reference=&quot;eq:relu&quot;} sont appelés neurones linéaires rectifiés
(**Rectified Linear Units, ReLUs**), et sont en pratique très utilisés.\
Quelques fonctions d&#39;activation sont présentées dans la figure
[1.4](#fig:sigmoid-tanh){reference-type=&quot;ref&quot;
reference=&quot;fig:sigmoid-tanh&quot;}.

&lt;figure id=&quot;fig:sigmoid-tanh&quot;&gt;

&lt;figcaption&gt;Quelques fonctions d’activation classiques.&lt;/figcaption&gt;
&lt;/figure&gt;

### Entraînement des réseaux multicouches {#subsec:supervised-training}

Pour pouvoir utiliser les réseaux multicouches en apprentissage, deux
ingrédients sont indispensables :

-   une méthode indiquant comment choisir une architecture de réseau
    pour résoudre un problème donné. C&#39;est-à-dire, pouvoir répondre aux
    questions suivantes : combien de couches cachées ? combien de
    neurones par couche cachée ?

-   une fois l&#39;architecture choisie, un algorithme d&#39;apprentissage qui
    calcule, à partir d&#39;un l&#39;échantillon d&#39;apprentissage
    ${\cal E}_a = \left \{(x_n, t_n), 1 \leq n \leq N \right \}$ , les
    valeurs des poids synaptiques pour construire un réseau adapté au
    problème (c&#39;est à dire approchant une fonction $g$ désirée mais
    inconnue, telle qu&#39;en particulier $t_n \approx g(x_n)$) .

Sur le premier point, quelques algorithmes d&#39;apprentissage
auto-constructifs ont été proposés. Leur rôle est double :

-   apprentissage de l&#39;échantillon avec un réseau courant,

-   modification du réseau courant, en ajoutant de nouvelles cellules ou
    une nouvelle couche, en cas d&#39;échec de l&#39;apprentissage.

Il semble assez facile de concevoir des algorithmes auto-constructifs
qui classent correctement l&#39;échantillon, mais beaucoup plus difficile
d&#39;en obtenir qui aient un bon pouvoir de généralisation.\
Il a fallu attendre le milieu des années 1980 pour que le deuxième
problème trouve une solution : l&#39;algorithme de **rétropropagation du
gradient**, découvert simultanément par des équipes française et
américaine.

L&#39;entraînement, comme dans le cas de l&#39;algorithme
[\[A:descGrad\]](#A:descGrad){reference-type=&quot;ref&quot;
reference=&quot;A:descGrad&quot;}, consiste à trouver les poids qui minimisent une
fonction d&#39;erreur, mesurant l&#39;écart entre la sortie du réseau $y(x_n)$
et $t_n$, pour tous les exemples de ${\cal E}_a$. Les fonctions
couramment choisies sont les sommes des fonctions de perte sur chaque
exemple, et incluent l&#39;erreur quadratique $$\begin{aligned}
    E(w) = \dsum_{n = 1}^N E_n(w) = \dsum_{n = 1}^N \sum_{i = 1}^C (y_i(x_n,w) - t^i_{n})^2
\end{aligned}$$ ou l&#39;erreur d&#39;entropie croisée $$\begin{aligned}
    E(w) = \dsum_{n = 1}^N E_n(w) = \dsum_{n = 1}^N \sum_{i = 1}^C t^i_{n} \log(y_i(x_n,w)),
\end{aligned}$$ où $t^i_{n}$ est la $i^{\text{e}}$ composante de $t_n$.

### Stratégies d&#39;entraînement

Parmi les stratégies d&#39;entraînement qui peuvent être retenues, trois
sont classiquement utilisées

-   entraînement sur ${\cal E}_a$, les poids étant mis à jour après
    présentation, en fonction de l&#39;erreur totale
    $E(w) = \dsum_{n=1}^N E_n(w)$.

-   entraînement stochastique : un exemple est présenté et les poids
    sont mis à jour sur l&#39;erreur $E_n(w)$ calculée sur cet exemple
    (règle Adaline)

-   entraînement par batch sur un sous-ensemble
    $M \subseteq \{1,\ldots,N\}$ de ${\cal E}_a$, les poids étant mis à
    jour en fonction de l&#39;erreur cumulée
    $E_M(w) = \dsum_{n \in M} E_n(w)$.

### Optimisation des paramètres {#subsubsec:parameter-optimization}

Considérons le cas de l&#39;entraînement stochastique. La condition
nécessaire d&#39;optimalité d&#39;ordre 1 donne $$\begin{aligned}
    \frac{\partial E_n}{\partial w} = \nabla E_n(w) = 0
\end{aligned}$$

Une méthode itérative est utilisée pour trouver une solution approchée.
Si $w[t]$ est le vecteur de poids à la $t^{\text{e}}$ itération, une
mise à jour des poids $\Delta w[t]$ est calculée et propagée à
l&#39;itération suivante : $w[t+1] = w[t] + \Delta w[t]$. Comme dans le cas
du perceptron, on peut utiliser une méthode de type descente de gradient
(ordre 1), ou une méthode type Newton (ordre 2, qui nécessite alors le
calcul ou l&#39;estimation du Hessien $H_n$ de $E_n$ à chaque itération).

-   pour la méthode de descente du gradient, comme dans, la section
    [1.2.4](#subsec:descentegradient){reference-type=&quot;ref&quot;
    reference=&quot;subsec:descentegradient&quot;}, la mise à jour est effectuée
    par $$\begin{aligned}
                \Delta w[t] = - \gamma \frac{\partial E_n}{\partial w[t]} = - \gamma \nabla E_n (w[t])
            
    \end{aligned}$$ où $\gamma$ est le taux d&#39;apprentissage.

-   pour les méthodes d&#39;ordre 2, type Newton, la mise à jour s&#39;effectue
    selon le schéma $$\begin{aligned}
            \Delta w[t] = - \gamma \left(\frac{\partial^2 E_n}{\partial w[t]^2}\right)^{-1} \frac{\partial E_n}{\partial w[t]} = - \gamma \left(H_n(w[t])\right)^{-1} \nabla E_n(w[t])
        
    \end{aligned}$$ où $\gamma$ est le taux d&#39;apprentissage. L&#39;ordre 2
    assure une convergence plus rapide, mais requiert le calcul et
    l&#39;inversion du Hessien $H_n(w[t])$ de $E_n$, ce qui est coûteux.

### Initialisation des poids {#sububsec:weight-initialization}

Une méthode itérative d&#39;optimisation étant utilisée, l&#39;initialisation
des poids requiert une attention toute particulière. En faisant
l&#39;hypothèse que les entrées de chaque cellule de la rétine sont
distribuées selon une loi gaussienne, il est courant de choisir les
poids aléatoirement dans $$\begin{aligned}
    \label{eq:weight-initialization}
    - \frac{1}{\sqrt{m^{(l-1)}}} &lt; w_{i,j}^{(l)} &lt; \frac{1}{\sqrt{m^{(l-1)}}}.
\end{aligned}$$

En utilisant des fonctions d&#39;activation sigmoïde, il a été prouvé que
l&#39;apprentissage était alors optimal, en le sens que l&#39;apprentissage est
rapide et que les poids atteignent une valeur stable quasiment tous en
même temps.

Un autre schéma d&#39;initialisation est possible (initialisation
normalisée, ou initialisation de Xavier) en choisissant
$$\begin{aligned}
    \label{eq:normalized-initialization}
    - \frac{\sqrt{6}}{\sqrt{m^{(l-1)} + m^{(l)}}} &lt; w_{i,j}^{(l)} &lt; \frac{\sqrt{6}}{\sqrt{m^{(l-1)} + m^{(l)}}}.
\end{aligned}$$

### Rétropropagation de l&#39;erreur {#subsubsec:error-backproagation}

L&#39;algorithme
[\[alg:error-backpropagation\]](#alg:error-backpropagation){reference-type=&quot;ref&quot;
reference=&quot;alg:error-backpropagation&quot;}, dit algorithme de
rétropropagation du gradient, est utilisé pour évaluer le gradient
$\nabla E_n (w[t])$ de l&#39;erreur $E_n$ à chaque itération, ceci pour tous
les poids

::: algorithm
1.  Propager un exemple $x_n$ dans le réseau.

2.  Calculer les erreurs $\delta_i^{(L+1)}$ des neurones de sortie :
    $$\begin{aligned}
                (\forall i\in\{1\cdots C\})\quad\delta_i^{(L+1)} = \frac{\partial E_n}{\partial y_i^{(L+1)}} f&#39;(z_i^{(L+1)}).
            
    \end{aligned}$$

3.  Déterminer $\delta _i ^{(l)}$ pour toutes les couches cachées :
    $$\begin{aligned}
                (\forall l\in\{1\cdots L\})(\forall i\in\{1\cdots m^l\})\quad\delta _i ^{(l)} = f&#39; (z_i^{(l)}) \sum _{k = 1} ^{m^{(l+1)}} w_{i,k}^{(l+1)} \delta _k ^{(l+1)}.
            
    \end{aligned}$$

4.  Calculer les composantes du gradient : $$\begin{aligned}
                \label{eq:backprop-derivative}
                \frac{\partial E_n}{\partial w_{j,i}^{(l)}} = \delta _j ^{(l)} y_i^{(l-1)}.
            
    \end{aligned}$$

[]{#alg:error-backpropagation label=&quot;alg:error-backpropagation&quot;}
:::

Dans le cas d&#39;un apprentissage stochastique, cet algorithme est appliqué
jusqu&#39;à convergence, pour estimer les poids du réseau de neurones.

### Critères d&#39;arrêt

Plusieurs critères d&#39;arrêt peuvent être utilisés avec l&#39;algorithme de
rétropropagation du gradient. Le plus commun consiste à fixer un nombre
maximum de périodes d&#39;entraînement (sur ${\cal E}_a$), ce qui fixe
effectivement une limite supérieure sur la durée de l&#39;apprentissage. Ce
critère est important car la rétropropagation n&#39;offre aucune garantie
quant à la convergence de l&#39;algorithme. Il peut arriver, par exemple,
que le processus d&#39;optimisation reste pris dans un minimum local. Sans
un tel critère, l&#39;algorithme pourrait ne jamais se terminer. Un deuxième
critère commun consiste à fixer une borne inférieure sur l&#39;erreur
quadratique moyenne. Dépendant de l&#39;application, il est parfois possible
de fixer *a priori* un objectif à atteindre. Lorsque l&#39;indice de
performance choisi diminue en dessous de cet objectif, on considère
simplement que le réseau a suffisamment bien appris ses données et on
arrête l&#39;apprentissage.\
Les deux critères précédents sont utiles mais ils comportent aussi des
limitations. Le critère relatif au nombre maximum de périodes
d&#39;entraînement n&#39;est aucunement lié à la performance du réseau. Le
critère relatif à l&#39;erreur minimale obtenue mesure quant à lui un indice
de performance mais ce dernier peut engendrer un phénomène dit de
sur-apprentissage qui n&#39;est pas désirable dans la pratique, surtout si
l&#39;on ne possède pas une grande quantité de données d&#39;apprentissage, ou
si ces dernières ne sont pas de bonne qualité.\
Un processus d&#39;apprentissage comme celui de la rétropropagation, vise à
réduire autant que possible l&#39;erreur que commet le réseau. Mais cette
erreur est mesurée sur un ensemble de données d&#39;apprentissage
${\cal E}_a$. Si les données sont bonnes, c&#39;est-à-dire quelles
représentent bien le processus physique sous-jacent que l&#39;on tente
d&#39;apprendre ou de modéliser, et que l&#39;algorithme a convergé sur un
optimum global, alors il devrait bien se comporter sur d&#39;autres données
issues du même processus physique. Cependant, si les données
d&#39;apprentissage sont partiellement corrompues par du bruit ou par des
erreurs de mesure, alors il n&#39;est pas évident que la performance
optimale du réseau soit atteinte en minimisant l&#39;erreur, lorsqu&#39;on la
testera sur un jeu de données différent de celui qui a servi à
l&#39;entraînement. On parle alors de la capacité de généralisation du
réseau, c&#39;est-à-dire sa capacité à bien se comporter avec des données
qu&#39;il n&#39;a jamais vu auparavant.

Une solution à ce problème consiste à faire appel à un autre critère
d&#39;arrêt basé sur une technique de validation croisée. Cette technique
consiste à utiliser deux ensembles indépendants de données. En pratique,
il s&#39;agit de partitionner ${\cal E}_a$ pour entraîner le réseau en un
ensemble d&#39;apprentissage (ajustement des poids) un ensemble de
validation (calcul d&#39;un indice de performance). Le critère d&#39;arrêt
consiste alors à stopper l&#39;apprentissage lorsque l&#39;indice de performance
calculé sur les données de validation cesse de s&#39;améliorer pendant
plusieurs périodes d&#39;entraînement. Lors de deux périodes successives
d&#39;entraînement, des exemples peuvent être échangés entre ensembles
d&#39;apprentissage et de validation.

### Propriété fondamentale

Terminons par une dernière remarque sur la puissance de représentation
des réseaux multicouches. La plupart des fonctions numériques peuvent
être approximées avec une précision arbitraire par des réseaux à une
seule couche cachée. Mais cette couche cachée peut être démesurément
grande et le théorème de Hornik, qui affirme cette propriété
d&#39;approximateurs universels des réseaux multicouches, est
essentiellement un résultat théorique sur l&#39;expressivité des réseaux.

Plus formellement, la propriété fondamentale des réseaux de neurones est
l&#39;approximation parcimonieuse, qui traduit deux propriétés distinctes :
d&#39;une part les réseaux de neurones sont des approximateurs universels,
et d&#39;autre part, une approximation à l&#39;aide d&#39;un réseau de neurones
nécessite, en général, moins de paramètres ajustables que les
approximateurs usuels.

-   Approximateurs universels : Cybenko a énoncé en 1989 la propriété
    suivante : toute fonction bornée, suffisamment régulière, peut être
    approchée uniformément, avec une précision arbitraire, dans un
    domaine fini de l&#39;espace de ses variables, par un réseau de neurones
    comportant une couche de neurones cachés en nombre fini, possédant
    tous la même fonction d&#39;activation, et un neurone de sortie
    linéaire.\

-   Parcimonie : Hornik a montré en 1994 que si la sortie d&#39;un réseau de
    neurones est une fonction non linéaire des paramètres ajustables,
    elle est plus parcimonieuse que si elle était une fonction linéaire
    de ces paramètres. De plus, pour les réseaux dont la fonction
    d&#39;activation des neurones est une sigmoïde, l&#39;erreur commise dans
    l&#39;approximation varie comme l&#39;inverse du nombre de neurones cachés,
    et elle est indépendante du nombre de variables de la fonction à
    approcher. Ainsi, pour une précision donnée (*i.e.* étant donné un
    nombre de neurones cachés) le nombre de paramètres du réseau est
    proportionnel au nombre de variables de la fonction à approcher.\

Dans la plupart des cas d&#39;utilisation des réseaux de neurones, il va
s&#39;agir d&#39;établir un modèle d&#39;une fonction inconnue à partir de mesures
bruitées de l&#39;ensemble d&#39;apprentissage, permettant de reproduire les
sorties à partir des entrées, et de proposer une généralisation à des
données test. On cherche alors la **fonction de régression** du
processus considéré, *i.e.* la fonction obtenue en calculant la moyenne
d&#39;une infinité de mesures effectuées en chaque point du domaine de
validité du modèle. Le nombre de points de ce domaine étant lui-même
infini, la connaissance de la fonction de régression nécessiterait donc
une infinité de mesures en un nombre infini de points.\
Les réseaux de neurones, en raison de leur propriété fondamentale, sont
de bons candidats pour réaliser une approximation de la fonction de
régression à partir d&#39;un nombre fini de mesures. Ils entrent donc dans
le cadre des méthodes statistiques d&#39;apprentissage, et élargissent ce
domaine déjà bien exploré pour des fonctions de régression linéaire au
cas non linéaire.\

### Régularisation

La notion d&#39;approximateur universel peut induire également un problème
de surapprentissage (overfitting) de ${\cal E}_a$. Les techniques de
régularisation permettent d&#39;éviter ce problème, et permettent aux
réseaux de neurones (et à d&#39;autres algorithmes d&#39;ailleurs, comme les
autoencodeurs ou les SVM par exemple) d&#39;avoir une bonne capacité de
généralisation.\
Il existe plusieurs techniques permettant d&#39;introduire de la
régularisation dans les réseaux. Parmi elles, on note :

-   ${\cal E}_a$ est enrichi pour introduire certaines invariances que
    le réseau est supposé apprendre.

-   à chaque exemple présenté, chaque neurone caché est supprimé du
    calcul de la sortie avec probabilité $\frac{1}{2}$. Cette technique
    peut être vue comme la construction d&#39;un modèle moyen
    d&#39;apprentissage de plusieurs réseaux distincts.

-   lorsque ${\cal E}_a$ est séparé en un ensemble d&#39;apprentissage
    ${\cal E}^1_a$ et un ensemble de validation ${\cal E}^2_a$, il est
    courant de voir que l&#39;erreur baisse sur ${\cal E}^1_a$ au fil des
    itérations, alors que l&#39;erreur sur ${\cal E}^2_a$ tend à augmenter
    lorsque le réseau commence à sur-apprendre sur ${\cal E}^1_a$.
    L&#39;entraînement est alors stoppé dès que l&#39;erreur sur ${\cal E}^2_a$
    atteint un minimum. Cette technique est appelée early stopping
    (arrêt précoce).

-   le partage de poids : plusieurs neurones d&#39;une même couche partagent
    des mêmes valeurs de poids. La complexité du réseau est réduite et
    des informations *a priori* peuvent être introduites par ce biais
    dans l&#39;architecture du réseau. L&#39;algorithme de rétropropagation du
    gradient s&#39;en trouve modifié et l&#39;équation
    [\[eq:backprop-derivative\]](#eq:backprop-derivative){reference-type=&quot;eqref&quot;
    reference=&quot;eq:backprop-derivative&quot;} devient $$\begin{aligned}
        \frac{\partial E_n}{\partial w_{j,i}^{(l)}} = \sum _{k = 1} ^{m^{(l)}} \delta_k^{(l)} y_i^{(l-1)}
    \end{aligned}$$ en supposant que tous les neurones de la couche $l$
    sont tels que $w_{j,i}^{(l)} = w_{k,i}^{(l)}$ pour
    $1 \leq j,k \leq m^{(l)}$

-   un terme de régularisation est ajouté à la fonctionnelle à minimiser
    pour contrôler la complexité et le forme de la solution et, par
    exemple $$\begin{aligned}
        \hat{E}_n (w) = E_n (w) + \eta P(w)
    \end{aligned}$$ où $P(w)$ influence la forme de la solution et
    $\eta$ contrôle l&#39;influence du terme de régularisation. $P(w)$ peut
    prendre la forme d&#39;une fonction de la norme $L_p$ de $w$. Deux
    exemples classiques sont :

    -   la régularisation $L_2$ : $$\begin{aligned}
            P(w) = \|w\|_2^2 = w^Tw.
        \end{aligned}$$ où le principe est de pénaliser les poids de
        fortes valeurs, qui tendent à amplifier le problème de
        surapprentissage.

    -   la régularisation $L_1$ : $$\begin{aligned}
            P(w) = \|w\|_1 = \dsum_{k = 1} ^W |w_k|.
        \end{aligned}$$ où $W$ est la dimension de $w$, qui tend à
        rendre épars le vecteur de poids (beaucoup de valeurs de poids
        deviennent nulles).

### Exemple

On va considérer le réseau décrit sur la figure
[1.5](#F:XOR_BackPropagation){reference-type=&quot;ref&quot;
reference=&quot;F:XOR_BackPropagation&quot;} pour apprendre la fonction du OU
exclusif (aussi appelé XOR). L&#39;opérateur XOR est défini par sa table de
vérité donnée par le tableau [1.2](#T:XOR){reference-type=&quot;ref&quot;
reference=&quot;T:XOR&quot;}.\

::: {#T:XOR}
   $x_1 \backslash x_2$   0   1
  ---------------------- --- ---
            0             0   1
            1             1   0

  : Table de vérité du XOR
:::

#### Réseau

Sur le réseau de la figure
[1.5](#F:XOR_BackPropagation){reference-type=&quot;ref&quot;
reference=&quot;F:XOR_BackPropagation&quot;} les différentes relations sont
données par l&#39;équation [\[E:XOR\]](#E:XOR){reference-type=&quot;ref&quot;
reference=&quot;E:XOR&quot;} où les paramètres en rouge correspondent aux poids à
calculer durant la phase d&#39;apprentissage.

$$\left\{
        \begin{array}{r c l}
            z_1 &amp;=&amp; {\color{red}w_1}~x_1+{\color{red}w_2}~x_2+{\color{red}b_1}\\
            z_2 &amp;=&amp; {\color{red}w_3}~x_1+{\color{red}w_4}~x_2+{\color{red}b_2}\\
            z_3 &amp;=&amp; {\color{red}w_5}~x_1+{\color{red}w_6}~x_2+{\color{red}b_3}\\
            z_4 &amp;=&amp; {\color{red}w_7}~h_1\left(z_1\right)+{\color{red}w_8}~h_2\left(z_2\right)+{\color{red}w_9}~h_3\left(z_3\right)+{\color{red}b_4}\\
            y &amp;=&amp; h_4\left(z_4\right) \\
            h_i\left(z_i\right) &amp;=&amp; \frac{1}{1+e^{-z_i}} \ \ \ \ (sigmoide)
        \end{array}
    \right.
    \label{E:XOR}$$

&lt;figure id=&quot;F:XOR_BackPropagation&quot;&gt;

&lt;figcaption&gt;Exemple d’un réseau pour apprendre la relation
XOR.&lt;/figcaption&gt;
&lt;/figure&gt;

#### Phase d&#39;apprentissage

Durant la phase d&#39;apprentissage, on minimise un risque empirique par une
fonction de coût. Dans cet exemple, nous allons choisir la minimisation
de l&#39;écart quadratique avec la base d&#39;apprentissage labelisée
${\cal E}_a =\left( \textbf{x}, \textbf{y}_{lab} \right)$ ou une partie
de cette base d&#39;apprentissage $\mathcal{E}_a^\prime$ :
$$E\left({\cal E}_a\right)=E_{tot}=\displaystyle\frac{1}{2}\sum_k \left(y[k]_{lab} - y \right)^2 = \displaystyle\frac{1}{2}\sum_k\left(y[k]_{lab} - h_4\left(z_4\right)  \right)^2.$$
On peut utiliser qu&#39;une partie de la base, voire que le $k^{ieme}$
échantillon de la base (cf. gradient stochastique) :
$$E\left(x_k\right)=E_{k}=\displaystyle\frac{1}{2}\left(y[k]_{lab} - y \right)^2 = \displaystyle\frac{1}{2}\left(y[k]_{lab} - h_4\left(z_4\right)  \right)^2 .
    \label{E:Ek}$$

L&#39;objectif de la phase d&#39;apprentissage est de mettre à jour les poids du
réseau par une approche de descente du gradient. Si l&#39;on considère un
poids quelconque du réseau que l&#39;on note $\theta$, sa mise à jour durant
l&#39;itération $n+1$ se fait pas l&#39;équation suivante:
$$\theta^{\left(n+1\right)} = \theta^{\left(n\right)} + \gamma_n\times \Delta \theta$$
où $$\Delta \theta = -\nabla_\theta E.$$ On peut choisir $E=E_{tot}$ ou
$E=E_k$ et pour cet exemple nous choisirons le deuxième cas.

##### Couche de sortie

Pour la couche de sortie, prenons par exemple le paramètre $w_7$, sa
mise à jour est donnée par la relation suivante :
$$w_7^{\left(n+1\right)} = w_7^{\left(n\right)} - \eta \times \frac{\partial E_k}{\partial w_7}.$$

Le problème consiste à calculer $\frac{\partial E_k}{\partial w_7}$,
pour cela nous allons utiliser le théorème de dérivation des fonctions
composées, d&#39;où:
$$\frac{\partial E_k}{\partial w_7} = \frac{\partial E_k}{\partial h_4} \times  \frac{\partial h_4}{\partial z_4} \times  \frac{\partial z_4}{\partial w_7}$$
Cette relation est représentée graphiquement sur la figure
[1.6](#F:CoucheSortie){reference-type=&quot;ref&quot;
reference=&quot;F:CoucheSortie&quot;}.\
A l&#39;aide de l&#39;équation [\[E:XOR\]](#E:XOR){reference-type=&quot;ref&quot;
reference=&quot;E:XOR&quot;} et de l&#39;équation
[\[E:Ek\]](#E:Ek){reference-type=&quot;ref&quot; reference=&quot;E:Ek&quot;}, on obtient:
$$\left\{
        \begin{array}{r c l}
            \displaystyle\frac{\partial E_k}{\partial h_4} &amp;=&amp; \frac{\partial }{\partial h_4}\left( \frac{1}{2}\left(y[k]_{lab} - h_4\left(z_4\right)  \right)^2 \right) = -\left(y[k]_{lab} - h_4\left(z_4\right)  \right)\\
            \displaystyle\frac{\partial h_4}{\partial z_4}  &amp;=&amp; \frac{\partial }{\partial z_4}\left( \frac{1}{1+e^{-z_4}}\right) = \frac{e^{-z_4}}{\left(1+e^{-z_4}\right)^2} = h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) \\
            \displaystyle\frac{\partial z_4}{\partial w_7} &amp;=&amp; h_1\left(z_1\right)
        \end{array}
    \right.
    \label{E:CompOutLayer}$$ d&#39;où

::: tcolorbox
w_7\^(n+1) = w_7\^(n) + (y\[k\]\_lab - h_4(z_4)) h_4(z_4)( 1 - h_4(z_4))
h_1(z_1).
:::

On peut réaliser la même démarche pour les poids $w_8$, $w_9$ et $b_4$,
pour obtenir les relations suivantes :

$$\left\{
        \begin{array}{r c l}
            w_8^{\left(n+1\right)} &amp;=&amp; w_8^{\left(n\right)} + \eta \times \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_2\left(z_2\right) \\
            w_9^{\left(n+1\right)} &amp;=&amp; w_9^{\left(n\right)} + \eta \times \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_3\left(z_3\right) \\
            b_4^{\left(n+1\right)} &amp;=&amp; b_4^{\left(n\right)} + \eta \times \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) 
        \end{array}
    \right.
    \label{E:OutLayer}$$

&lt;figure id=&quot;F:CoucheSortie&quot;&gt;

&lt;figcaption&gt;Rétropropagation du gradient sur la couche de
sortie.&lt;/figcaption&gt;
&lt;/figure&gt;

##### Couche cachée

Pour la couche cachée du réseau, c&#39;est exactement le même raisonnement.
Prenons par exemple, le paramètre $w_1$ pour le calcul :
$$w_1^{\left(n+1\right)} = w_1^{\left(n\right)} - \eta \times \frac{\partial E_k}{\partial w_1}.$$
Le problème maintenant consiste à calculer
$\frac{\partial E_k}{\partial w_1}$, pour cela nous allons utiliser le
théorème de dérivation des fonctions composées, d&#39;où:
$$\frac{\partial E_k}{\partial w_1} = \frac{\partial E_k}{\partial z_4} \times  \frac{\partial z_4}{\partial h_1}  \times  \frac{\partial h_1}{\partial z_1} \times  \frac{\partial z_1}{\partial w_1}$$
Cette relation est représentée graphiquement sur la figure
[1.7](#F:CoucheCachee){reference-type=&quot;ref&quot;
reference=&quot;F:CoucheCachee&quot;}.\
A l&#39;aide de l&#39;équation [\[E:XOR\]](#E:XOR){reference-type=&quot;ref&quot;
reference=&quot;E:XOR&quot;}, de l&#39;équation [\[E:Ek\]](#E:Ek){reference-type=&quot;ref&quot;
reference=&quot;E:Ek&quot;} et de l&#39;équation
[\[E:CompOutLayer\]](#E:CompOutLayer){reference-type=&quot;ref&quot;
reference=&quot;E:CompOutLayer&quot;} on obtient: $$\left\{
        \begin{array}{r c l}
            \displaystyle\frac{\partial E_k}{\partial z_4} &amp;=&amp; -\left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right)\\
            \displaystyle\frac{\partial z_4}{\partial h_1}  &amp;=&amp; w_7 \\
            \displaystyle\frac{\partial h_1}{\partial z_1} &amp;=&amp; h_1\left(z_1\right)\left( 1 - h_1\left(z_1\right)\right)\\
            \displaystyle\frac{\partial z_1}{\partial w_1} &amp;=&amp; x_1
        \end{array}
    \right.
    \label{E:CompOut}$$ d&#39;où

::: tcolorbox
w_1\^(n+1) = w_1\^(n) + (y\[k\]\_lab - h_4(z_4)) h_4(z_4)( 1 - h_4(z_4))
h_1(z_1)( 1 - h_1(z_1)) w_7 x_1
:::

On peut réaliser la même démarche pour les poids $w_2$ et $b_1$, pour
obtenir les relations suivantes :

$$\left\{
        \begin{array}{r c l}
            w_2^{\left(n+1\right)} &amp;=&amp; w_2^{\left(n\right)} + \eta \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_1\left(z_1\right)\left( 1 - h_1\left(z_1\right)\right) w_7 x_2\\
            b_1^{\left(n+1\right)} &amp;=&amp; b_1^{\left(n\right)} + \eta \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_1\left(z_1\right)\left( 1 - h_1\left(z_1\right)\right) w_7
        \end{array}
    \right.
    \label{E:CompHiddenLayer}$$

&lt;figure id=&quot;F:CoucheCachee&quot;&gt;

&lt;figcaption&gt;Rétropropagation du gradient sur la couche
cachée.&lt;/figcaption&gt;
&lt;/figure&gt;

Il suffit de réaliser des calculs identiques pour les autres neurones et
on obtient les relations suivantes : $$\left\{
            \begin{array}{r c l}
                w_3^{\left(n+1\right)} &amp;=&amp; w_3^{\left(n\right)} + \eta \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_2\left(z_2\right)\left( 1 - h_2\left(z_2\right)\right) w_8 x_1\\                
                w_4^{\left(n+1\right)} &amp;=&amp; w_4^{\left(n\right)} + \eta \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_2\left(z_2\right)\left( 1 - h_2\left(z_2\right)\right) w_8 x_2\\
                w_5^{\left(n+1\right)} &amp;=&amp; w_5^{\left(n\right)} + \eta \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_3\left(z_3\right)\left( 1 - h_3\left(z_3\right)\right) w_9 x_1\\                
                w_6^{\left(n+1\right)} &amp;=&amp; w_6^{\left(n\right)} + \eta \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_3\left(z_3\right)\left( 1 - h_3\left(z_3\right)\right) w_9 x_2\\
                b_2^{\left(n+1\right)} &amp;=&amp; b_2^{\left(n\right)} + \eta \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_2\left(z_2\right)\left( 1 - h_2\left(z_2\right)\right) w_8 \\
                b_3^{\left(n+1\right)} &amp;=&amp; b_3^{\left(n\right)} + \eta \left(y[k]_{lab} - h_4\left(z_4\right)\right) h_4\left(z_4\right)\left( 1 - h_4\left(z_4\right)\right) h_3\left(z_3\right)\left( 1 - h_3\left(z_3\right)\right) w_9               
            \end{array}
        \right.$$

##### Initialisation des poids {#initialisation-des-poids}

-   les biais sont initialisés à zéro
    $( b_1, b_2, b_3, b_4 ) = \mathbf{0}_4$ ;

-   pour les poids $w_i$, ils sont initialisées de façon aléatoire
    dépendant de la taille de la couche d&#39;avant $m^{(l-1)}$ et d&#39;après
    $m^{(l)}$.\
    L&#39;initialisation de Xavier propose un tirage uniforme dans
    $\left[-\sqrt{\frac{6}{m^{(l-1)}+m^{(l)}}} ;\sqrt{\frac{6}{m^{(l-1)}+m^{(l)}}} \right]$.

Pour notre exemple, on obtient l&#39;initialisation suivante : $$\left\{
        \begin{array}{r c l}
            w_1 \ ...\ w_6 &amp;=&amp; UD \ dans \ \left[-\sqrt{\frac{6}{2+3}} ;\sqrt{\frac{6}{2+3}} \right] = \left[-1,09;1,09 \right]\\
            w_7 \ ... \ w_9 &amp;=&amp; UD \ dans \ \left[-\sqrt{\frac{6}{3+1}} ;\sqrt{\frac{6}{3+1}} \right] = \left[-1,23;1,23 \right]
        \end{array}
    \right.$$

## Partie pratique

### Perceptron

Le notebook perceptron fournit le squelette d&#39;un programme de calcul des
résultats d&#39;un perceptron linéaire sur trois types de données (figure
[1.8](#F:simdata){reference-type=&quot;ref&quot; reference=&quot;F:simdata&quot;}) :

1.  un jeu de données linéairement séparable (figure
    [\[F:ld\]](#F:ld){reference-type=&quot;ref&quot; reference=&quot;F:ld&quot;})

2.  un jeu de données non linéairement séparable moon (figure
    [\[F:md\]](#F:md){reference-type=&quot;ref&quot; reference=&quot;F:md&quot;})

3.  un jeu de données non linéairement séparable composé de deux cercles
    concentriques (figure [\[F:cd\]](#F:cd){reference-type=&quot;ref&quot;
    reference=&quot;F:cd&quot;})

&lt;figure id=&quot;F:simdata&quot;&gt;
&lt;figure&gt;

&lt;/figure&gt;
&lt;figure&gt;

&lt;/figure&gt;
&lt;figure&gt;

&lt;/figure&gt;
&lt;figcaption&gt;Données d’entraînement du perceptron&lt;/figcaption&gt;
&lt;/figure&gt;

Vous devez compléter ce notebook pour :

-   définir la structure du réseau : $y=softmax(w^Tx+b)$

-   spécifier la fonction de coût et l&#39;algorithme d&#39;optimisation à
    utiliser.

Le résultat sur les trois jeux de données sont présentés en figure
[1.9](#F:resperceptron){reference-type=&quot;ref&quot;
reference=&quot;F:resperceptron&quot;}.

&lt;figure id=&quot;F:resperceptron&quot;&gt;
&lt;figure&gt;

&lt;/figure&gt;
&lt;figure&gt;

&lt;/figure&gt;
&lt;figure&gt;

&lt;/figure&gt;
&lt;p&gt;.&lt;/p&gt;
&lt;figcaption&gt;Frontières de décision du perceptron sur les trois jeux de
données simulées&lt;/figcaption&gt;
&lt;/figure&gt;

### Perceptron multicouches

#### Une couche cachée

A partir de ce code, il vous est demandé de réaliser un perceptron
multicouches, à une couche cachée, permettant de séparer avec une
précision de presque 100% les données des jeux `moon` et `twocircles`
(figure [1.10](#F:resPMC){reference-type=&quot;ref&quot; reference=&quot;F:resPMC&quot;}).
Un notebook vous est proposé, à compléter. Vous devez implémenter :

-   le réseau à une couche cachée. Le calcul des activations de la
    couche cachée, à `num_hidden` neurones se fait à l&#39;aide de la
    fonction tangente hyperbolique. Le calcul de la sortie du réseau
    sera effectué à l&#39;aide de la fonction softmax

-   la compilation de ce réseau, en spécifiant une fonction de perte
    idoine et un optimiseur adapté

&lt;figure id=&quot;F:resPMC&quot;&gt;
&lt;figure&gt;

&lt;/figure&gt;
&lt;figure&gt;

&lt;/figure&gt;
&lt;figure&gt;

&lt;/figure&gt;
&lt;p&gt;.&lt;/p&gt;
&lt;figcaption&gt;Frontières de décision du PMC sur les trois jeux de données
simulées&lt;/figcaption&gt;
&lt;/figure&gt;

#### Deux couches cachées

Il vous est enfin demandé de compléter le notebook qui vous est fourni,
et dont l&#39;objectif est de construire un perceptron multicouches à deux
couches cachées pour la classification des images MNIST.
</pre></div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "vbarra/dlbook.git",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="intro.html" title="précédent page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">précédent</p>
            <p class="prev-next-title">Apprentissage profond</p>
        </div>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Vincent BARRA<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>