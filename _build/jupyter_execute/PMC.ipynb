{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88626165",
   "metadata": {},
   "source": [
    "# Perceptrons multicouches \n",
    "\n",
    "````{prf:definition} Perceptron multicouches\n",
    "Un perceptron à $(L+1)$ couches ({numref}`mlp`) est un réseau constitué d'une\n",
    "rétine à $D$ neurones (auxquels on rajoute l'entrée $x_0$), $C$ neurones\n",
    "de sortie, et des neurones dits **cachés**, organisés dans $L$ couches\n",
    "cachées intermédiaires. De fait, un tel réseau comporte $(L+2)$ couches\n",
    "mais on compte rarement la rétine, puisque cette dernière n'effectue pas\n",
    "de calculs. Le $i^{\\text{e}}$ neurone dans la couche cachée $l$ calcule\n",
    "la sortie \n",
    "\n",
    "$$\\begin{aligned}\n",
    "    y_i^{(l)} &= f\\left(z_i^{(l)}\\right) \\quad\\text{ avec }\\quad z_i^{(l)} = \\sum _{k = 1} ^{m^{(l-1)}} w_{i,k}^{(l)} y_k^{(l-1)} + w_{i,0}^{(l)}\n",
    "\\end{aligned}$$ \n",
    "\n",
    "où $w_{i,k}^{(l)}$ est le poids de la connexion entre le\n",
    "$k^{\\text{e}}$ neurone de la couche $(l-1)$ et le $i^{\\text{e}}$ neurone\n",
    "de la couche $l$, et $w_{i,0}^{(l)}$ est le biais. De plus, $m^{(l)}$\n",
    "est le nombre de neurones de la couche $l$, de sorte que $D = m^{(0)}$\n",
    "et $C = m^{(L+1)}$. Enfin, $f$ est la fonction d'activation du neurone\n",
    "(supposée identique pour tous les neurones).\n",
    "````\n",
    "\n",
    "En introduisant dans chaque couche un neurone supplémentaire\n",
    "$y_0^{(l)} = 1$ pour gérer le biais, on a : \n",
    "\n",
    "$$\\begin{aligned}\n",
    "    {\\mathbf z_i^{(l)}} = \\displaystyle\\sum _{k = 0} ^{m^{(l-1)}} {\\mathbf w_{i,k}^{(l)}} {\\mathbf y_k^{(l-1)}}\\quad \\text{ où }\\quad {\\mathbf z^{(l)}} = {\\mathbf w^{(l)} y^{(l-1)}}\n",
    "\\end{aligned}$$ \n",
    "\n",
    "avec ${\\mathbf z^{(l)}}$, $\\mathbf{w^{(l)}}$ et $\\mathbf{y^{(l-1)}}$ les\n",
    "représentations vectorielle et matricielle des entrées $z_i^{(l)}$, des\n",
    "poids $w_{i,k}^{(l)}$ et des sorties $y_k^{(l-1)}$.\n",
    "\n",
    "\n",
    "```{figure} ./images/mlp.png\n",
    ":name: mlp\n",
    "Perceptron multicouches à $(L + 1)$ couches, $D$ entrées et $C$ sorties.\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Un tel réseau représente une fonction \n",
    "\n",
    "$$\\begin{aligned}\n",
    "    {\\mathbf y}(\\cdot,{\\mathbf w}) &:& \\mathbb{R}^D \\rightarrow \\mathbb{R}^C\\\\\n",
    "    {\\mathbf x} &\\mapsto& {\\mathbf y(x,w)}\n",
    "\\end{aligned}$$ \n",
    "\n",
    "où ${\\mathbf y(x,w)}$ est tel que ${\\mathbf y_i}({\\mathbf x},{\\mathbf w}) = {\\mathbf y_i^{(L+1)}}$ et ${\\mathbf w}$\n",
    "est la matrice de tous les poids du réseau.\n",
    "\n",
    "On parlera de **réseau profond (Deep network)** lorsque le nombre de\n",
    "couches cachées est \"suffisamment important\" (supérieur à 3 par exemple).\n",
    "\n",
    "## Fonctions d'activation \n",
    "\n",
    "Trois grandes classes de fonction d'activation $f$ sont généralement\n",
    "utilisées : les fonctions de seuils (comme dans le perceptron linéaire à\n",
    "seuil), les fonctions linéaires par morceau et les fonctions de type\n",
    "sigmoïde. Dans les deux premiers cas, de nombreux problèmes se\n",
    "présentent, notamment en raison de la non différentiabilité de ces\n",
    "fonctions (qui est nécessaire dans les algorithmes d'apprentissage du\n",
    "type descente de gradient), ou encore en raison de la faiblesse de leur\n",
    "pouvoir d'expression. Ainsi, il est préférable d'utiliser des fonctions\n",
    "de type sigmoïde, et par exemple la sigmoïde logistique est donnée par :\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\sigma(z) = \\frac{1}{1 + \\exp(-z)}.\n",
    "\\end{aligned}$$\n",
    "\n",
    "La tangente hyperbolique $\\tanh(z)$, également utilisée pour ses bonnes\n",
    "propriétés de dérivabilité ($(\\tanh)'=1-\\tanh^2$), peut être vue comme\n",
    "une transformation linéaire de la sigmoïde dans l'intervalle $[-1,1]$.\n",
    "\n",
    "Ces réseaux peuvent être utilisés en régression (sortie à valeurs dans\n",
    "$\\mathbb{R}^C$) ou en classification. Dans ce dernier cas, la fonction\n",
    "d'activation softmax est utilisée à la sortie du réseau pour interpréter\n",
    "les sorties comme des valeurs de probabilité a posteriori. S'il s'agit\n",
    "de classer un exemple $x$ à la classe $c$, la probabilité conditionnelle\n",
    "$p(c|x)$ peut être calculée en utilisant la règle de Bayes :\n",
    "\n",
    "$$\\begin{aligned}\n",
    "p(c|x) = \\frac{p(x|c)p(c)}{p(x)}\n",
    "\\end{aligned}$$ \n",
    "\n",
    "$p(c|x)$ est alors interprétée comme une probabilité a\n",
    "posteriori. Disposant de ces probabilités pour tout $c=1,\\ldots,C$, la\n",
    "règle de décision de Bayes donne :\n",
    "\n",
    "$$\\begin{aligned}\n",
    "c: \\mathbb{R}^D \\rightarrow \\{1,\\ldots,C\\}, x \\mapsto  argmax_{c}\\left(p(c|x)\\right).\n",
    "\\end{aligned}$$ \n",
    "\n",
    "L'utilisation de la fonction d'activation softmax en\n",
    "sortie permet d'interpréter les sorties du réseau comme de telles\n",
    "probabilités :la sortie du $i^{\\text{e}}$ neurone de la couche de sortie\n",
    "est\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\sigma(z^{(L+1)},i) = \\frac{\\exp(z_i^{(L+1)})}{\\displaystyle\\sum_{k = 1} ^C \\exp(z_k^{(L+1)})}.\n",
    "\\end{aligned}$$\n",
    "\n",
    "En apprentissage profond, il a été reporté que la sigmoïde et la\n",
    "tangente hyperbolique avaient des performances moindres que la fonction\n",
    "d'activation softsign : \n",
    "\n",
    "$$\\begin{aligned}\n",
    "    s(z) = \\frac{1}{1+ |z|}.\n",
    "\\end{aligned}$$ \n",
    "\n",
    "En effet, les valeurs de $z$ arrivant près des paliers\n",
    "de saturation de ces fonctions donnent des gradients faibles, qui ont\n",
    "tendance à s'annuler lors de la phase d'apprentissage détaillée plus\n",
    "loin (rétropropagation du gradient). Une autre fonction, non saturante\n",
    "elle, peut être utilisée : \n",
    "\n",
    "$$\\begin{aligned}\n",
    "    r(z) = \\max (0,z).\n",
    "\\end{aligned}$$ \n",
    "\n",
    "Les neurones cachés utilisant la fonction décrite dans\n",
    "l'équation précédente sont appelés neurones linéaires rectifiés\n",
    "(**Rectified Linear Units, ReLUs**), et sont en pratique très utilisés.\n",
    "\n",
    "Quelques fonctions d'activation sont présentées dans la ({numref}`tabact`).\n",
    "\n",
    "```{figure} ./images/tabactivation.pdf\n",
    ":name: tabact\n",
    "Quelques fonctions d'activation\n",
    "```\n",
    "\n",
    "Les fonctions d'activation sous Pytorch sont résumées [ici](https://pytorch.org/docs/stable/nn.functional.html).\n",
    "\n",
    "## Entraînement des réseaux multicouches \n",
    "\n",
    "Pour pouvoir utiliser les réseaux multicouches en apprentissage, deux\n",
    "ingrédients sont indispensables :\n",
    "\n",
    "-   une méthode indiquant comment choisir une architecture de réseau\n",
    "    pour résoudre un problème donné. C'est-à-dire, pouvoir répondre aux\n",
    "    questions suivantes : combien de couches cachées ? combien de\n",
    "    neurones par couche cachée ?\n",
    "\n",
    "-   une fois l'architecture choisie, un algorithme d'apprentissage qui\n",
    "    calcule, à partir d'un l'échantillon d'apprentissage\n",
    "    ${\\cal E}_a = \\left \\{({\\mathbf x_n}, \\mathbf t_n),n\\in[\\![1,N]\\!] \\right \\}$ , les\n",
    "    valeurs des poids synaptiques pour construire un réseau adapté au\n",
    "    problème (c'est à dire approchant une fonction $g$ désirée mais\n",
    "    inconnue, telle qu'en particulier $\\mathbf t_n \\approx {\\mathbf g(x_n)}$) .\n",
    "\n",
    "Sur le premier point, quelques algorithmes d'apprentissage\n",
    "auto-constructifs ont été proposés. Leur rôle est double :\n",
    "\n",
    "-   apprentissage de l'échantillon avec un réseau courant,\n",
    "\n",
    "-   modification du réseau courant, en ajoutant de nouvelles cellules ou\n",
    "    une nouvelle couche, en cas d'échec de l'apprentissage.\n",
    "\n",
    "Il semble assez facile de concevoir des algorithmes auto-constructifs\n",
    "qui classent correctement l'échantillon, mais beaucoup plus difficile\n",
    "d'en obtenir qui aient un bon pouvoir de généralisation.\\\n",
    "Il a fallu attendre le milieu des années 1980 pour que le deuxième\n",
    "problème trouve une solution : l'algorithme de **rétropropagation du\n",
    "gradient**.\n",
    "\n",
    "L'entraînement, comme dans le cas de l'algorithme\n",
    "de descentre de gradient, consiste à trouver les poids qui minimisent une\n",
    "fonction d'erreur, mesurant l'écart entre la sortie du réseau $y({\\mathbf x_n})$\n",
    "et $\\mathbf t_n$, pour tous les exemples de ${\\cal E}_a$. Les fonctions\n",
    "couramment choisies sont les sommes des fonctions de perte sur chaque\n",
    "exemple, et incluent l'erreur quadratique \n",
    "\n",
    "$$\\begin{aligned}\n",
    "    E(\\mathbf w) = \\displaystyle\\sum_{n = 1}^N E_n(\\mathbf w) = \\displaystyle\\sum_{n = 1}^N \\sum_{i = 1}^C (y_i(\\mathbf x_n,\\mathbf w) - t^i_{n})^2\n",
    "\\end{aligned}$$ \n",
    "\n",
    "ou l'erreur d'entropie croisée \n",
    "\n",
    "$$\\begin{aligned}\n",
    "    E(\\mathbf w) = \\displaystyle\\sum_{n = 1}^N E_n(\\mathbf w) = \\displaystyle\\sum_{n = 1}^N \\sum_{i = 1}^C t^i_{n} \\log(y_i(\\mathbf x_n,\\mathbf w)),\n",
    "\\end{aligned}$$ \n",
    "\n",
    "où $t^i_{n}$ est la $i^{\\text{e}}$ composante de $\\mathbf t_n$.\n",
    "\n",
    "## Stratégies d'entraînement\n",
    "\n",
    "Parmi les stratégies d'entraînement qui peuvent être retenues, trois\n",
    "sont classiquement utilisées\n",
    "\n",
    "-   entraînement sur ${\\cal E}_a$, les poids étant mis à jour après\n",
    "    présentation, en fonction de l'erreur totale\n",
    "    $E(\\mathbf w) = \\displaystyle\\sum_{n=1}^N E_n(\\mathbf w)$.\n",
    "\n",
    "-   entraînement stochastique : un exemple est présenté et les poids\n",
    "    sont mis à jour sur l'erreur $E_n(\\mathbf w)$ calculée sur cet exemple\n",
    "    (règle Adaline)\n",
    "\n",
    "-   entraînement par batch sur un sous-ensemble\n",
    "    $M \\subseteq \\{1,\\ldots,N\\}$ de ${\\cal E}_a$, les poids étant mis à\n",
    "    jour en fonction de l'erreur cumulée\n",
    "    $E_M(\\mathbf w) = \\displaystyle\\sum_{n \\in M} E_n(\\mathbf w)$.\n",
    "\n",
    "## Optimisation des paramètres \n",
    "\n",
    "Considérons le cas de l'entraînement stochastique. La condition\n",
    "nécessaire d'optimalité d'ordre 1 donne \n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\frac{\\partial E_n}{\\partial \\mathbf w} = \\nabla E_n(\\mathbf w) = 0\n",
    "\\end{aligned}$$\n",
    "\n",
    "Une méthode itérative est utilisée pour trouver une solution approchée.\n",
    "Si $\\mathbf w[t]$ est le vecteur de poids à la $t^{\\text{e}}$ itération, une\n",
    "mise à jour des poids $\\Delta \\mathbf w[t]$ est calculée et propagée à\n",
    "l'itération suivante : $\\mathbf w[t+1] = \\mathbf w[t] + \\Delta \\mathbf w[t]$. Comme dans le cas du perceptron, on peut utiliser une méthode de type descente de gradient\n",
    "(ordre 1), ou une méthode type Newton (ordre 2, qui nécessite alors le\n",
    "calcul ou l'estimation du Hessien $H_n$ de $E_n$ à chaque itération).\n",
    "\n",
    "-   pour la méthode de descente du gradient, la mise à jour est effectuée\n",
    "    par \n",
    "\n",
    "    $$\\begin{aligned}\n",
    "                \\Delta \\mathbf w[t] = - \\gamma \\frac{\\partial E_n}{\\partial \\mathbf w[t]} = - \\gamma \\nabla E_n (\\mathbf w[t])\n",
    "            \n",
    "    \\end{aligned}$$ \n",
    "    \n",
    "    où $\\gamma$ est le taux d'apprentissage.\n",
    "\n",
    "-   pour les méthodes d'ordre 2, type Newton, la mise à jour s'effectue\n",
    "    selon le schéma \n",
    "    \n",
    "    $$\\begin{aligned}\n",
    "            \\Delta \\mathbf w[t] = - \\gamma \\left(\\frac{\\partial^2 E_n}{\\partial \\mathbf w[t]^2}\\right)^{-1} \\frac{\\partial E_n}{\\partial \\mathbf w[t]} = - \\gamma \\left(\\mathbf H_n\\mathbf (\\mathbf w[t])\\right)^{-1} \\nabla E_n(\\mathbf w[t])  \n",
    "    \\end{aligned}$$ \n",
    "    \n",
    "    où $\\gamma$ est le taux d'apprentissage. L'ordre 2 assure une convergence plus rapide, mais requiert le calcul et l'inversion du Hessien $\\mathbf H_n(\\mathbf w[t])$ de $E_n$, ce qui est coûteux.\n",
    "\n",
    "## Initialisation des poids {#sububsec:weight-initialization}\n",
    "\n",
    "Une méthode itérative d'optimisation étant utilisée, l'initialisation\n",
    "des poids requiert une attention toute particulière. En faisant\n",
    "l'hypothèse que les entrées de chaque cellule de la rétine sont\n",
    "distribuées selon une loi gaussienne, il est courant de choisir les\n",
    "poids aléatoirement dans \n",
    "\n",
    "$$\\begin{aligned}\n",
    "    - \\frac{1}{\\sqrt{m^{(l-1)}}} < w_{i,j}^{(l)} < \\frac{1}{\\sqrt{m^{(l-1)}}}.\n",
    "\\end{aligned}$$\n",
    "\n",
    "En utilisant des fonctions d'activation sigmoïde, il a été prouvé que\n",
    "l'apprentissage était alors optimal, en le sens que l'apprentissage est\n",
    "rapide et que les poids atteignent une valeur stable quasiment tous en\n",
    "même temps.\n",
    "\n",
    "Un autre schéma d'initialisation est possible (initialisation\n",
    "normalisée, ou initialisation de Xavier) en choisissant\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    - \\frac{\\sqrt{6}}{\\sqrt{m^{(l-1)} + m^{(l)}}} < w_{i,j}^{(l)} < \\frac{\\sqrt{6}}{\\sqrt{m^{(l-1)} + m^{(l)}}}.\n",
    "\\end{aligned}$$\n",
    "\n",
    "## Rétropropagation de l'erreur \n",
    "\n",
    "L'algorithme\n",
    "[\\[alg:error-backpropagation\\]](#alg:error-backpropagation){reference-type=\"ref\"\n",
    "reference=\"alg:error-backpropagation\"}, dit algorithme de\n",
    "rétropropagation du gradient, est utilisé pour évaluer le gradient\n",
    "$\\nabla E_n (w[t])$ de l'erreur $E_n$ à chaque itération, ceci pour tous\n",
    "les poids\n",
    "\n",
    "::: algorithm\n",
    "1.  Propager un exemple $x_n$ dans le réseau.\n",
    "\n",
    "2.  Calculer les erreurs $\\delta_i^{(L+1)}$ des neurones de sortie :\n",
    "    $$\\begin{aligned}\n",
    "                (\\forall i\\in\\{1\\cdots C\\})\\quad\\delta_i^{(L+1)} = \\frac{\\partial E_n}{\\partial y_i^{(L+1)}} f'(z_i^{(L+1)}).\n",
    "            \n",
    "    \\end{aligned}$$\n",
    "\n",
    "3.  Déterminer $\\delta _i ^{(l)}$ pour toutes les couches cachées :\n",
    "    $$\\begin{aligned}\n",
    "                (\\forall l\\in\\{1\\cdots L\\})(\\forall i\\in\\{1\\cdots m^l\\})\\quad\\delta _i ^{(l)} = f' (z_i^{(l)}) \\sum _{k = 1} ^{m^{(l+1)}} w_{i,k}^{(l+1)} \\delta _k ^{(l+1)}.\n",
    "            \n",
    "    \\end{aligned}$$\n",
    "\n",
    "4.  Calculer les composantes du gradient : $$\\begin{aligned}\n",
    "                \\label{eq:backprop-derivative}\n",
    "                \\frac{\\partial E_n}{\\partial w_{j,i}^{(l)}} = \\delta _j ^{(l)} y_i^{(l-1)}.\n",
    "            \n",
    "    \\end{aligned}$$\n",
    "\n",
    "[]{#alg:error-backpropagation label=\"alg:error-backpropagation\"}\n",
    ":::\n",
    "\n",
    "Dans le cas d'un apprentissage stochastique, cet algorithme est appliqué\n",
    "jusqu'à convergence, pour estimer les poids du réseau de neurones.\n",
    "\n",
    "## Critères d'arrêt\n",
    "\n",
    "Plusieurs critères d'arrêt peuvent être utilisés avec l'algorithme de\n",
    "rétropropagation du gradient. Le plus commun consiste à fixer un nombre\n",
    "maximum de périodes d'entraînement (sur ${\\cal E}_a$), ce qui fixe\n",
    "effectivement une limite supérieure sur la durée de l'apprentissage. Ce\n",
    "critère est important car la rétropropagation n'offre aucune garantie\n",
    "quant à la convergence de l'algorithme. Il peut arriver, par exemple,\n",
    "que le processus d'optimisation reste pris dans un minimum local. Sans\n",
    "un tel critère, l'algorithme pourrait ne jamais se terminer. Un deuxième\n",
    "critère commun consiste à fixer une borne inférieure sur l'erreur\n",
    "quadratique moyenne. Dépendant de l'application, il est parfois possible\n",
    "de fixer *a priori* un objectif à atteindre. Lorsque l'indice de\n",
    "performance choisi diminue en dessous de cet objectif, on considère\n",
    "simplement que le réseau a suffisamment bien appris ses données et on\n",
    "arrête l'apprentissage.\\\n",
    "Les deux critères précédents sont utiles mais ils comportent aussi des\n",
    "limitations. Le critère relatif au nombre maximum de périodes\n",
    "d'entraînement n'est aucunement lié à la performance du réseau. Le\n",
    "critère relatif à l'erreur minimale obtenue mesure quant à lui un indice\n",
    "de performance mais ce dernier peut engendrer un phénomène dit de\n",
    "sur-apprentissage qui n'est pas désirable dans la pratique, surtout si\n",
    "l'on ne possède pas une grande quantité de données d'apprentissage, ou\n",
    "si ces dernières ne sont pas de bonne qualité.\\\n",
    "Un processus d'apprentissage comme celui de la rétropropagation, vise à\n",
    "réduire autant que possible l'erreur que commet le réseau. Mais cette\n",
    "erreur est mesurée sur un ensemble de données d'apprentissage\n",
    "${\\cal E}_a$. Si les données sont bonnes, c'est-à-dire quelles\n",
    "représentent bien le processus physique sous-jacent que l'on tente\n",
    "d'apprendre ou de modéliser, et que l'algorithme a convergé sur un\n",
    "optimum global, alors il devrait bien se comporter sur d'autres données\n",
    "issues du même processus physique. Cependant, si les données\n",
    "d'apprentissage sont partiellement corrompues par du bruit ou par des\n",
    "erreurs de mesure, alors il n'est pas évident que la performance\n",
    "optimale du réseau soit atteinte en minimisant l'erreur, lorsqu'on la\n",
    "testera sur un jeu de données différent de celui qui a servi à\n",
    "l'entraînement. On parle alors de la capacité de généralisation du\n",
    "réseau, c'est-à-dire sa capacité à bien se comporter avec des données\n",
    "qu'il n'a jamais vu auparavant.\n",
    "\n",
    "Une solution à ce problème consiste à faire appel à un autre critère\n",
    "d'arrêt basé sur une technique de validation croisée. Cette technique\n",
    "consiste à utiliser deux ensembles indépendants de données. En pratique,\n",
    "il s'agit de partitionner ${\\cal E}_a$ pour entraîner le réseau en un\n",
    "ensemble d'apprentissage (ajustement des poids) un ensemble de\n",
    "validation (calcul d'un indice de performance). Le critère d'arrêt\n",
    "consiste alors à stopper l'apprentissage lorsque l'indice de performance\n",
    "calculé sur les données de validation cesse de s'améliorer pendant\n",
    "plusieurs périodes d'entraînement. Lors de deux périodes successives\n",
    "d'entraînement, des exemples peuvent être échangés entre ensembles\n",
    "d'apprentissage et de validation.\n",
    "\n",
    "## Propriété fondamentale\n",
    "\n",
    "Terminons par une dernière remarque sur la puissance de représentation\n",
    "des réseaux multicouches. La plupart des fonctions numériques peuvent\n",
    "être approximées avec une précision arbitraire par des réseaux à une\n",
    "seule couche cachée. Mais cette couche cachée peut être démesurément\n",
    "grande et le théorème de Hornik, qui affirme cette propriété\n",
    "d'approximateurs universels des réseaux multicouches, est\n",
    "essentiellement un résultat théorique sur l'expressivité des réseaux.\n",
    "\n",
    "Plus formellement, la propriété fondamentale des réseaux de neurones est\n",
    "l'approximation parcimonieuse, qui traduit deux propriétés distinctes :\n",
    "d'une part les réseaux de neurones sont des approximateurs universels,\n",
    "et d'autre part, une approximation à l'aide d'un réseau de neurones\n",
    "nécessite, en général, moins de paramètres ajustables que les\n",
    "approximateurs usuels.\n",
    "\n",
    "-   Approximateurs universels : Cybenko a énoncé en 1989 la propriété\n",
    "    suivante : toute fonction bornée, suffisamment régulière, peut être\n",
    "    approchée uniformément, avec une précision arbitraire, dans un\n",
    "    domaine fini de l'espace de ses variables, par un réseau de neurones\n",
    "    comportant une couche de neurones cachés en nombre fini, possédant\n",
    "    tous la même fonction d'activation, et un neurone de sortie\n",
    "    linéaire.\\\n",
    "\n",
    "-   Parcimonie : Hornik a montré en 1994 que si la sortie d'un réseau de\n",
    "    neurones est une fonction non linéaire des paramètres ajustables,\n",
    "    elle est plus parcimonieuse que si elle était une fonction linéaire\n",
    "    de ces paramètres. De plus, pour les réseaux dont la fonction\n",
    "    d'activation des neurones est une sigmoïde, l'erreur commise dans\n",
    "    l'approximation varie comme l'inverse du nombre de neurones cachés,\n",
    "    et elle est indépendante du nombre de variables de la fonction à\n",
    "    approcher. Ainsi, pour une précision donnée (*i.e.* étant donné un\n",
    "    nombre de neurones cachés) le nombre de paramètres du réseau est\n",
    "    proportionnel au nombre de variables de la fonction à approcher.\\\n",
    "\n",
    "Dans la plupart des cas d'utilisation des réseaux de neurones, il va\n",
    "s'agir d'établir un modèle d'une fonction inconnue à partir de mesures\n",
    "bruitées de l'ensemble d'apprentissage, permettant de reproduire les\n",
    "sorties à partir des entrées, et de proposer une généralisation à des\n",
    "données test. On cherche alors la **fonction de régression** du\n",
    "processus considéré, *i.e.* la fonction obtenue en calculant la moyenne\n",
    "d'une infinité de mesures effectuées en chaque point du domaine de\n",
    "validité du modèle. Le nombre de points de ce domaine étant lui-même\n",
    "infini, la connaissance de la fonction de régression nécessiterait donc\n",
    "une infinité de mesures en un nombre infini de points.\\\n",
    "Les réseaux de neurones, en raison de leur propriété fondamentale, sont\n",
    "de bons candidats pour réaliser une approximation de la fonction de\n",
    "régression à partir d'un nombre fini de mesures. Ils entrent donc dans\n",
    "le cadre des méthodes statistiques d'apprentissage, et élargissent ce\n",
    "domaine déjà bien exploré pour des fonctions de régression linéaire au\n",
    "cas non linéaire.\\\n",
    "\n",
    "## Régularisation\n",
    "\n",
    "La notion d'approximateur universel peut induire également un problème\n",
    "de surapprentissage (overfitting) de ${\\cal E}_a$. Les techniques de\n",
    "régularisation permettent d'éviter ce problème, et permettent aux\n",
    "réseaux de neurones (et à d'autres algorithmes d'ailleurs, comme les\n",
    "autoencodeurs ou les SVM par exemple) d'avoir une bonne capacité de\n",
    "généralisation.\\\n",
    "Il existe plusieurs techniques permettant d'introduire de la\n",
    "régularisation dans les réseaux. Parmi elles, on note :\n",
    "\n",
    "-   ${\\cal E}_a$ est enrichi pour introduire certaines invariances que\n",
    "    le réseau est supposé apprendre.\n",
    "\n",
    "-   à chaque exemple présenté, chaque neurone caché est supprimé du\n",
    "    calcul de la sortie avec probabilité $\\frac{1}{2}$. Cette technique\n",
    "    peut être vue comme la construction d'un modèle moyen\n",
    "    d'apprentissage de plusieurs réseaux distincts.\n",
    "\n",
    "-   lorsque ${\\cal E}_a$ est séparé en un ensemble d'apprentissage\n",
    "    ${\\cal E}^1_a$ et un ensemble de validation ${\\cal E}^2_a$, il est\n",
    "    courant de voir que l'erreur baisse sur ${\\cal E}^1_a$ au fil des\n",
    "    itérations, alors que l'erreur sur ${\\cal E}^2_a$ tend à augmenter\n",
    "    lorsque le réseau commence à sur-apprendre sur ${\\cal E}^1_a$.\n",
    "    L'entraînement est alors stoppé dès que l'erreur sur ${\\cal E}^2_a$\n",
    "    atteint un minimum. Cette technique est appelée early stopping\n",
    "    (arrêt précoce).\n",
    "\n",
    "-   le partage de poids : plusieurs neurones d'une même couche partagent\n",
    "    des mêmes valeurs de poids. La complexité du réseau est réduite et\n",
    "    des informations *a priori* peuvent être introduites par ce biais\n",
    "    dans l'architecture du réseau. L'algorithme de rétropropagation du\n",
    "    gradient s'en trouve modifié et l'équation\n",
    "    [\\[eq:backprop-derivative\\]](#eq:backprop-derivative){reference-type=\"eqref\"\n",
    "    reference=\"eq:backprop-derivative\"} devient $$\\begin{aligned}\n",
    "        \\frac{\\partial E_n}{\\partial w_{j,i}^{(l)}} = \\sum _{k = 1} ^{m^{(l)}} \\delta_k^{(l)} y_i^{(l-1)}\n",
    "    \\end{aligned}$$ en supposant que tous les neurones de la couche $l$\n",
    "    sont tels que $w_{j,i}^{(l)} = w_{k,i}^{(l)}$ pour\n",
    "    $1 \\leq j,k \\leq m^{(l)}$\n",
    "\n",
    "-   un terme de régularisation est ajouté à la fonctionnelle à minimiser\n",
    "    pour contrôler la complexité et le forme de la solution et, par\n",
    "    exemple $$\\begin{aligned}\n",
    "        \\hat{E}_n (w) = E_n (w) + \\eta P(w)\n",
    "    \\end{aligned}$$ où $P(w)$ influence la forme de la solution et\n",
    "    $\\eta$ contrôle l'influence du terme de régularisation. $P(w)$ peut\n",
    "    prendre la forme d'une fonction de la norme $L_p$ de $w$. Deux\n",
    "    exemples classiques sont :\n",
    "\n",
    "    -   la régularisation $L_2$ : $$\\begin{aligned}\n",
    "            P(w) = \\|w\\|_2^2 = w^Tw.\n",
    "        \\end{aligned}$$ où le principe est de pénaliser les poids de\n",
    "        fortes valeurs, qui tendent à amplifier le problème de\n",
    "        surapprentissage.\n",
    "\n",
    "    -   la régularisation $L_1$ : $$\\begin{aligned}\n",
    "            P(w) = \\|w\\|_1 = \\displaystyle\\sum_{k = 1} ^W |w_k|.\n",
    "        \\end{aligned}$$ où $W$ est la dimension de $w$, qui tend à\n",
    "        rendre épars le vecteur de poids (beaucoup de valeurs de poids\n",
    "        deviennent nulles).\n",
    "\n",
    "## Exemple\n",
    "\n",
    "On va considérer le réseau décrit sur la figure\n",
    "[1.5](#F:XOR_BackPropagation){reference-type=\"ref\"\n",
    "reference=\"F:XOR_BackPropagation\"} pour apprendre la fonction du OU\n",
    "exclusif (aussi appelé XOR). L'opérateur XOR est défini par sa table de\n",
    "vérité donnée par le tableau [1.2](#T:XOR){reference-type=\"ref\"\n",
    "reference=\"T:XOR\"}.\\\n",
    "\n",
    "::: {#T:XOR}\n",
    "   $x_1 \\backslash x_2$   0   1\n",
    "  ---------------------- --- ---\n",
    "            0             0   1\n",
    "            1             1   0\n",
    "\n",
    "  : Table de vérité du XOR\n",
    ":::\n",
    "\n",
    "### Réseau\n",
    "\n",
    "Sur le réseau de la figure\n",
    "[1.5](#F:XOR_BackPropagation){reference-type=\"ref\"\n",
    "reference=\"F:XOR_BackPropagation\"} les différentes relations sont\n",
    "données par l'équation [\\[E:XOR\\]](#E:XOR){reference-type=\"ref\"\n",
    "reference=\"E:XOR\"} où les paramètres en rouge correspondent aux poids à\n",
    "calculer durant la phase d'apprentissage.\n",
    "\n",
    "$$\\left\\{\n",
    "        \\begin{array}{r c l}\n",
    "            z_1 &=& {\\color{red}w_1}~x_1+{\\color{red}w_2}~x_2+{\\color{red}b_1}\\\\\n",
    "            z_2 &=& {\\color{red}w_3}~x_1+{\\color{red}w_4}~x_2+{\\color{red}b_2}\\\\\n",
    "            z_3 &=& {\\color{red}w_5}~x_1+{\\color{red}w_6}~x_2+{\\color{red}b_3}\\\\\n",
    "            z_4 &=& {\\color{red}w_7}~h_1\\left(z_1\\right)+{\\color{red}w_8}~h_2\\left(z_2\\right)+{\\color{red}w_9}~h_3\\left(z_3\\right)+{\\color{red}b_4}\\\\\n",
    "            y &=& h_4\\left(z_4\\right) \\\\\n",
    "            h_i\\left(z_i\\right) &=& \\frac{1}{1+e^{-z_i}} \\ \\ \\ \\ (sigmoide)\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "    \\label{E:XOR}$$\n",
    "\n",
    "<figure id=\"F:XOR_BackPropagation\">\n",
    "\n",
    "<figcaption>Exemple d’un réseau pour apprendre la relation\n",
    "XOR.</figcaption>\n",
    "</figure>\n",
    "\n",
    "### Phase d'apprentissage\n",
    "\n",
    "Durant la phase d'apprentissage, on minimise un risque empirique par une\n",
    "fonction de coût. Dans cet exemple, nous allons choisir la minimisation\n",
    "de l'écart quadratique avec la base d'apprentissage labelisée\n",
    "${\\cal E}_a =\\left( \\textbf{x}, \\textbf{y}_{lab} \\right)$ ou une partie\n",
    "de cette base d'apprentissage $\\mathcal{E}_a^\\prime$ :\n",
    "$$E\\left({\\cal E}_a\\right)=E_{tot}=\\displaystyle\\frac{1}{2}\\sum_k \\left(y[k]_{lab} - y \\right)^2 = \\displaystyle\\frac{1}{2}\\sum_k\\left(y[k]_{lab} - h_4\\left(z_4\\right)  \\right)^2.$$\n",
    "On peut utiliser qu'une partie de la base, voire que le $k^{ieme}$\n",
    "échantillon de la base (cf. gradient stochastique) :\n",
    "\n",
    "$$E\\left(x_k\\right)=E_{k}=\\displaystyle\\frac{1}{2}\\left(y[k]_{lab} - y \\right)^2 = \\displaystyle\\frac{1}{2}\\left(y[k]_{lab} - h_4\\left(z_4\\right)  \\right)^2 .\n",
    "    $$\n",
    "\n",
    "L'objectif de la phase d'apprentissage est de mettre à jour les poids du\n",
    "réseau par une approche de descente du gradient. Si l'on considère un\n",
    "poids quelconque du réseau que l'on note $\\theta$, sa mise à jour durant\n",
    "l'itération $n+1$ se fait pas l'équation suivante:\n",
    "$$\\theta^{\\left(n+1\\right)} = \\theta^{\\left(n\\right)} + \\gamma_n\\times \\Delta \\theta$$\n",
    "où $$\\Delta \\theta = -\\nabla_\\theta E.$$ On peut choisir $E=E_{tot}$ ou\n",
    "$E=E_k$ et pour cet exemple nous choisirons le deuxième cas.\n",
    "\n",
    "#### Couche de sortie\n",
    "\n",
    "Pour la couche de sortie, prenons par exemple le paramètre $w_7$, sa\n",
    "mise à jour est donnée par la relation suivante :\n",
    "$$w_7^{\\left(n+1\\right)} = w_7^{\\left(n\\right)} - \\eta \\times \\frac{\\partial E_k}{\\partial w_7}.$$\n",
    "\n",
    "Le problème consiste à calculer $\\frac{\\partial E_k}{\\partial w_7}$,\n",
    "pour cela nous allons utiliser le théorème de dérivation des fonctions\n",
    "composées, d'où:\n",
    "\n",
    "$$\\frac{\\partial E_k}{\\partial w_7} = \\frac{\\partial E_k}{\\partial h_4} \\times  \\frac{\\partial h_4}{\\partial z_4} \\times  \\frac{\\partial z_4}{\\partial w_7}$$\n",
    "\n",
    "Cette relation est représentée graphiquement sur la figure\n",
    "[1.6](#F:CoucheSortie){reference-type=\"ref\"\n",
    "reference=\"F:CoucheSortie\"}.\\\n",
    "Utilisant l'expression de A $E_k$ on a alors :\n",
    "$$\\left\\{\n",
    "        \\begin{array}{r c l}\n",
    "            \\displaystyle\\frac{\\partial E_k}{\\partial h_4} &=& \\frac{\\partial }{\\partial h_4}\\left( \\frac{1}{2}\\left(y[k]_{lab} - h_4\\left(z_4\\right)  \\right)^2 \\right) = -\\left(y[k]_{lab} - h_4\\left(z_4\\right)  \\right)\\\\\n",
    "            \\displaystyle\\frac{\\partial h_4}{\\partial z_4}  &=& \\frac{\\partial }{\\partial z_4}\\left( \\frac{1}{1+e^{-z_4}}\\right) = \\frac{e^{-z_4}}{\\left(1+e^{-z_4}\\right)^2} = h_4\\left(z_4\\right)\\left( 1 - h_4\\left(z_4\\right)\\right) \\\\\n",
    "            \\displaystyle\\frac{\\partial z_4}{\\partial w_7} &=& h_1\\left(z_1\\right)\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "    $$ \n",
    "    \n",
    "    d'où\n",
    "\n",
    "$$w_7^{(n+1)} = w_7^{(n) }+ (y[k]_{lab} - h_4(z_4)) h_4(z_4)( 1 - h_4(z_4))\n",
    "h_1(z_1)$$\n",
    "\n",
    "On peut réaliser la même démarche pour les poids $w_8$, $w_9$ et $b_4$,\n",
    "pour obtenir les relations suivantes :\n",
    "\n",
    "$$\\left\\{\n",
    "        \\begin{array}{r c l}\n",
    "            w_8^{\\left(n+1\\right)} &=& w_8^{\\left(n\\right)} + \\eta \\times \\left(y[k]_{lab} - h_4\\left(z_4\\right)\\right) h_4\\left(z_4\\right)\\left( 1 - h_4\\left(z_4\\right)\\right) h_2\\left(z_2\\right) \\\\\n",
    "            w_9^{\\left(n+1\\right)} &=& w_9^{\\left(n\\right)} + \\eta \\times \\left(y[k]_{lab} - h_4\\left(z_4\\right)\\right) h_4\\left(z_4\\right)\\left( 1 - h_4\\left(z_4\\right)\\right) h_3\\left(z_3\\right) \\\\\n",
    "            b_4^{\\left(n+1\\right)} &=& b_4^{\\left(n\\right)} + \\eta \\times \\left(y[k]_{lab} - h_4\\left(z_4\\right)\\right) h_4\\left(z_4\\right)\\left( 1 - h_4\\left(z_4\\right)\\right) \n",
    "        \\end{array}\n",
    "    \\right.\n",
    "    $$\n",
    "\n",
    "<figure id=\"F:CoucheSortie\">\n",
    "\n",
    "<figcaption>Rétropropagation du gradient sur la couche de\n",
    "sortie.</figcaption>\n",
    "</figure>\n",
    "\n",
    "#### Couche cachée\n",
    "\n",
    "Pour la couche cachée du réseau, c'est exactement le même raisonnement.\n",
    "Prenons par exemple, le paramètre $w_1$ pour le calcul :\n",
    "$$w_1^{\\left(n+1\\right)} = w_1^{\\left(n\\right)} - \\eta \\times \\frac{\\partial E_k}{\\partial w_1}.$$\n",
    "Le problème maintenant consiste à calculer\n",
    "$\\frac{\\partial E_k}{\\partial w_1}$, pour cela nous allons utiliser le\n",
    "théorème de dérivation des fonctions composées, d'où:\n",
    "$$\\frac{\\partial E_k}{\\partial w_1} = \\frac{\\partial E_k}{\\partial z_4} \\times  \\frac{\\partial z_4}{\\partial h_1}  \\times  \\frac{\\partial h_1}{\\partial z_1} \\times  \\frac{\\partial z_1}{\\partial w_1}$$\n",
    "Cette relation est représentée graphiquement sur la figure\n",
    "[1.7](#F:CoucheCachee){reference-type=\"ref\"\n",
    "reference=\"F:CoucheCachee\"}.\\\n",
    "A l'aide de l'équation [\\[E:XOR\\]](#E:XOR){reference-type=\"ref\"\n",
    "reference=\"E:XOR\"}, de l'équation [\\[E:Ek\\]](#E:Ek){reference-type=\"ref\"\n",
    "reference=\"E:Ek\"} et de l'équation\n",
    "[\\[E:CompOutLayer\\]](#E:CompOutLayer){reference-type=\"ref\"\n",
    "reference=\"E:CompOutLayer\"} on obtient: \n",
    "\n",
    "$$\\left\\{\n",
    "        \\begin{array}{r c l}\n",
    "            \\displaystyle\\frac{\\partial E_k}{\\partial z_4} &=& -\\left(y[k]_{lab} - h_4\\left(z_4\\right)\\right) h_4\\left(z_4\\right)\\left( 1 - h_4\\left(z_4\\right)\\right)\\\\\n",
    "            \\displaystyle\\frac{\\partial z_4}{\\partial h_1}  &=& w_7 \\\\\n",
    "            \\displaystyle\\frac{\\partial h_1}{\\partial z_1} &=& h_1\\left(z_1\\right)\\left( 1 - h_1\\left(z_1\\right)\\right)\\\\\n",
    "            \\displaystyle\\frac{\\partial z_1}{\\partial w_1} &=& x_1\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "    $$ \n",
    "    \n",
    "    d'où\n",
    "\n",
    "$$\n",
    "w_1^{(n+1)} = w_1^{(n)} + (y[k]{_lab} - h_4(z_4)) h_4(z_4)( 1 - h_4(z_4))h_1(z_1)( 1 - h_1(z_1)) w_7 x_1\n",
    "$$\n",
    "\n",
    "On peut réaliser la même démarche pour les poids $w_2$ et $b_1$, pour\n",
    "obtenir les relations suivantes :\n",
    "\n",
    "$$\\left\\{\n",
    "        \\begin{array}{r c l}\n",
    "            w_2^{\\left(n+1\\right)} &=& w_2^{\\left(n\\right)} + \\eta \\left(y[k]_{lab} - h_4\\left(z_4\\right)\\right) h_4\\left(z_4\\right)\\left( 1 - h_4\\left(z_4\\right)\\right) h_1\\left(z_1\\right)\\left( 1 - h_1\\left(z_1\\right)\\right) w_7 x_2\\\\\n",
    "            b_1^{\\left(n+1\\right)} &=& b_1^{\\left(n\\right)} + \\eta \\left(y[k]_{lab} - h_4\\left(z_4\\right)\\right) h_4\\left(z_4\\right)\\left( 1 - h_4\\left(z_4\\right)\\right) h_1\\left(z_1\\right)\\left( 1 - h_1\\left(z_1\\right)\\right) w_7\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "    $$\n",
    "\n",
    "<figure id=\"F:CoucheCachee\">\n",
    "\n",
    "<figcaption>Rétropropagation du gradient sur la couche\n",
    "cachée.</figcaption>\n",
    "</figure>\n",
    "\n",
    "Il suffit de réaliser des calculs identiques pour les autres neurones et\n",
    "on obtient les relations suivantes : $$\\left\\{\n",
    "            \\begin{array}{r c l}\n",
    "                w_3^{\\left(n+1\\right)} &=& w_3^{\\left(n\\right)} + \\eta \\left(y[k]_{lab} - h_4\\left(z_4\\right)\\right) h_4\\left(z_4\\right)\\left( 1 - h_4\\left(z_4\\right)\\right) h_2\\left(z_2\\right)\\left( 1 - h_2\\left(z_2\\right)\\right) w_8 x_1\\\\                \n",
    "                w_4^{\\left(n+1\\right)} &=& w_4^{\\left(n\\right)} + \\eta \\left(y[k]_{lab} - h_4\\left(z_4\\right)\\right) h_4\\left(z_4\\right)\\left( 1 - h_4\\left(z_4\\right)\\right) h_2\\left(z_2\\right)\\left( 1 - h_2\\left(z_2\\right)\\right) w_8 x_2\\\\\n",
    "                w_5^{\\left(n+1\\right)} &=& w_5^{\\left(n\\right)} + \\eta \\left(y[k]_{lab} - h_4\\left(z_4\\right)\\right) h_4\\left(z_4\\right)\\left( 1 - h_4\\left(z_4\\right)\\right) h_3\\left(z_3\\right)\\left( 1 - h_3\\left(z_3\\right)\\right) w_9 x_1\\\\                \n",
    "                w_6^{\\left(n+1\\right)} &=& w_6^{\\left(n\\right)} + \\eta \\left(y[k]_{lab} - h_4\\left(z_4\\right)\\right) h_4\\left(z_4\\right)\\left( 1 - h_4\\left(z_4\\right)\\right) h_3\\left(z_3\\right)\\left( 1 - h_3\\left(z_3\\right)\\right) w_9 x_2\\\\\n",
    "                b_2^{\\left(n+1\\right)} &=& b_2^{\\left(n\\right)} + \\eta \\left(y[k]_{lab} - h_4\\left(z_4\\right)\\right) h_4\\left(z_4\\right)\\left( 1 - h_4\\left(z_4\\right)\\right) h_2\\left(z_2\\right)\\left( 1 - h_2\\left(z_2\\right)\\right) w_8 \\\\\n",
    "                b_3^{\\left(n+1\\right)} &=& b_3^{\\left(n\\right)} + \\eta \\left(y[k]_{lab} - h_4\\left(z_4\\right)\\right) h_4\\left(z_4\\right)\\left( 1 - h_4\\left(z_4\\right)\\right) h_3\\left(z_3\\right)\\left( 1 - h_3\\left(z_3\\right)\\right) w_9               \n",
    "            \\end{array}\n",
    "        \\right.$$\n",
    "\n",
    "#### Initialisation des poids {#initialisation-des-poids}\n",
    "\n",
    "-   les biais sont initialisés à zéro\n",
    "    $( b_1, b_2, b_3, b_4 ) = \\mathbf{0}_4$ ;\n",
    "\n",
    "-   pour les poids $w_i$, ils sont initialisées de façon aléatoire\n",
    "    dépendant de la taille de la couche d'avant $m^{(l-1)}$ et d'après\n",
    "    $m^{(l)}$.\\\n",
    "    L'initialisation de Xavier propose un tirage uniforme dans\n",
    "    $\\left[-\\sqrt{\\frac{6}{m^{(l-1)}+m^{(l)}}} ;\\sqrt{\\frac{6}{m^{(l-1)}+m^{(l)}}} \\right]$.\n",
    "\n",
    "Pour notre exemple, on obtient l'initialisation suivante : $$\\left\\{\n",
    "        \\begin{array}{r c l}\n",
    "            w_1 \\ ...\\ w_6 &=& UD \\ dans \\ \\left[-\\sqrt{\\frac{6}{2+3}} ;\\sqrt{\\frac{6}{2+3}} \\right] = \\left[-1,09;1,09 \\right]\\\\\n",
    "            w_7 \\ ... \\ w_9 &=& UD \\ dans \\ \\left[-\\sqrt{\\frac{6}{3+1}} ;\\sqrt{\\frac{6}{3+1}} \\right] = \\left[-1,23;1,23 \\right]\n",
    "        \\end{array}\n",
    "    \\right.$$"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "source_map": [
   11
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}