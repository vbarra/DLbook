---
jupytext:
  formats: md:myst
  text_representation:
    extension: .md
    format_name: myst
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---
# Mod√®les de diffusion

## Introduction

Un mod√®le de diffusion (de d√©bruitage) transforme du bruit √† partir d'une distribution simple en un √©chantillon de donn√©es. Lorsque les donn√©es sont des images, le mod√®le se compose de deux processus ({numref}`diffusion`): 
- un processus de diffusion vers l'avant $q$, choisi, qui ajoute progressivement du bruit gaussien √† une image, jusqu'√† aboutir √† du bruit pur
- un processus de diffusion inverse de d√©bruitage $p_{\boldsymbol\theta}$ , mod√©lis√© par un r√©seau de neurones, entra√Æn√© √† d√©bruiter progressivement une image √† partir d'un bruit pur, jusqu'√† obtenir une image r√©elle.

Les processus sont temporels, index√©s par le temps $t\in[\![0,T]\!]$. A $t=0$, on  √©chantillonne une image r√©elle $\boldsymbol ùê±_0$ de la distribution de donn√©es. Le processus $q$ √©chantillonne un bruit provenant d'une distribution gaussienne √† chaque pas de temps $t$ ,  ajout√© √† l'image du pas de temps pr√©c√©dent. Si $T$ est suffisamment et que les processus d'ajout de bruit est correct, on obtient une distribution gaussienne isotrope √† $t=T$.

```{prf:remark}
:class: dropdown
 Une distribution gaussienne isotrope $\mathcal N(\boldsymbol \mu,\boldsymbol \Sigma)$ est telle que $\boldsymbol \Sigma = \sigma^2\boldsymbol I$.
 ```


```{figure} ./images/diffusion.png
:name: diffusion
Illustration du mod√®le de diffusion (source : [{cite:p}`Ho20`](https://proceedings.neurips.cc/paper_files/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf))
```


## Mod√®le de diffusion

Soit $(q(\mathbf{x}_0)$) la distribution des donn√©es r√©elles. On √©chantillonne $(\mathbf{x}_0 \sim q(\mathbf{x}_0)$) et on d√©finit un processus de diffusion avant $(q(\mathbf{x}_t | \mathbf{x}_{t-1})$) qui ajoute un bruit gaussien √† chaque pas de temps $t$, selon une mise √† jour de la variance connue  $0 < \beta_1 < \beta_2 < ... < \beta_T < 1$ : 

$$
q(\mathbf{x}_t | \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t \mathbf{I})
$$

Chaque donn√©e $\boldsymbol x_t$ est ainsi tir√©e selon une distribution conditionnelle gaussienne  $\mathbf{\mu}_t = \sqrt{1 - \beta_t} \mathbf{x}_{t-1}$ et  $\sigma^2_t = \beta_t$,ce qui peut √™tre r√©alis√© en √©chantillonnant selon  $\mathbf{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ et en posant  $\mathbf{x}_t = \sqrt{1 - \beta_t} \mathbf{x}_{t-1} +  \sqrt{\beta_t} \mathbf{\epsilon}$. 

Note that the $(\beta_t$) aren't constant at each time step $(t$) (hence the subscript) --- in fact one defines a so-called **"variance schedule"**, which can be linear, quadratic, cosine, etc. as we will see further (a bit like a learning rate schedule). 

So starting from $(\mathbf{x}_0$), we end up with $(\mathbf{x}_1,  ..., \mathbf{x}_t, ..., \mathbf{x}_T$), where $(\mathbf{x}_T$) is pure Gaussian noise if we set the schedule appropriately.

Now, if we knew the conditional distribution $(p(\mathbf{x}_{t-1} | \mathbf{x}_t)$), then we could run the process in reverse: by sampling some random Gaussian noise $(\mathbf{x}_T$), and then gradually "denoise" it so that we end up with a sample from the real distribution $(\mathbf{x}_0$).

However, we don't know $(p(\mathbf{x}_{t-1} | \mathbf{x}_t)$). It's intractable since it requires knowing the distribution of all possible images in order to calculate this conditional probability. Hence, we're going to leverage a neural network to **approximate (learn) this conditional probability distribution**, let's call it $(p_\theta (\mathbf{x}_{t-1} | \mathbf{x}_t)$), with $(\theta$) being the parameters of the neural network, updated by gradient descent. 

Ok, so we need a neural network to represent a (conditional) probability distribution of the backward process. If we assume this reverse process is Gaussian as well, then recall that any Gaussian distribution is defined by 2 parameters:
- a mean parametrized by $\mu_\theta$;
- a variance parametrized by $\Sigma_\theta$;

so we can parametrize the process as 

$$ p_\theta (\mathbf{x}_{t-1} | \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \mu_\theta(\mathbf{x}_{t},t), \Sigma_\theta (\mathbf{x}_{t},t))$$

where the mean and variance are also conditioned on the noise level $(t$).